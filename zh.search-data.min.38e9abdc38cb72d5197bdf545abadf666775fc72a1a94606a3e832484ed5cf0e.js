'use strict';(function(){const indexCfg={encode:false,tokenize:function(str){return str.replace(/[\x00-\x7F]/g,'').split('');}};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/zh/docs/01-what-why-and-how/','title':"是什么，为什么，如何使用",'section':"Docs",'content':"WebRTC是什么？ #  WebRTC是Web实时通信（Real-Time Communication）的缩写，它既是API也是协议。WebRTC协议是两个WebRTC Agent协商双向安全实时通信的一组规则。开发人员可以通过WebRTC API使用WebRTC协议。目前WebRTC API仅有JavaScript版本。\n可以用HTTP和Fetch API之间的关系作为类比。WebRTC协议就是HTTP，而WebRTC API就是Fetch API。\n除了JavaScript语言，WebRTC协议也可以在其他API和语言中使用。你还可以找到WebRTC的服务器和特定领域的工具。所有这些实现都使用WebRTC协议，以便它们可以彼此交互。\nWebRTC协议由IETF工作组在rtcweb中维护。WebRTC API的W3C文档在webrtc-pc。\n为什么我应该学习WebRTC？ #  下面这些是WebRTC可以带给你的东西。这并不是一份详尽的清单，只是列举一些你在学习中可能感兴趣的点。如果你还不了解所有这些术语，请不要担心，本书将陆续将这些概念教给你。\n 开放标准 多种实现 在浏览器中可用 强制加密 NAT穿透 复用现有技术 拥塞控制 亚秒级延迟  WebRTC协议是一组其他技术的集合体 #  这个主题需要整本书来解释。但是，首先，我们将其分为四个步骤。\n 信令（Signaling） 连接（Connecting） 安全加密（Securing） 通信（Communicating）  这四个步骤依次发生。上一个步骤必须100％成功，随后的步骤才能开始。\n关于WebRTC的一个特殊事实是，每个步骤实际上都是由许多其他协议组成的！为了让WebRTC工作起来，我们将许多现有技术结合在一起。从这个意义上讲，WebRTC更像是2000年代早期以来就已经存在的一些易于理解的技术的组合和配置。\n每个步骤都有专门的章节，但是首先从较高的层次上理解它们会有所帮助。由于它们彼此依赖，因此理解这些在进一步解释每个步骤的目的时会有所帮助。\n信令：peer如何在WebRTC中找到彼此 #  当WebRTC Agent启动时，它不知道与谁通信以及他们将要通信的内容。信令解决了这个问题！信令用于引导呼叫，以便两个WebRTC Agent可以开始通信。\n信令使用现有的协议SDP（会话描述协议）。SDP是一种纯文本协议。每个SDP消息均由键/值对组成，并包含“media sections（媒体部分）”列表。两个WebRTC Agent交换的SDP所包含一些详细信息，如：\n Agent可供外部访问的（候选的）IP和端口。 Agent希望发送多少路音频和视频流。 Agent支持哪些音频和视频编解码器。 连接时需要用到的值（uFrag/uPwd）。 加密传输时需要用到的值（证书指纹）。  注意，信令通常发生在“out-of-band”。也就是说，应用通常不使用WebRTC本身来交换信令消息。在连接的peer中，任何适合发送消息的架构均可被用于传递SDP信息，许多应用程序都使用其现有的基础设施（例如REST端点，WebSocket连接或身份验证代理）来解决适当客户端之间的SDP传递问题。\n使用STUN/TURN进行连接和NAT穿透 #  现在，两个WebRTC Agent知道足够的详细信息以尝试相互连接。接下来，WebRTC将使用另一种成熟的技术，称为ICE。\nICE（交互式连接建立）是WebRTC之前的协议。ICE允许在两个Agent之间建立连接。这些Agent可以在同一网络上，也可以在世界的另一端。ICE是无需中央服务器即可建立直接连接的解决方案。\n这里真正的魔法是“ NAT穿透”和STUN/TURN服务器。这两个概念是与另一个子网中的ICE Agent进行通信所需的全部。稍后我们将深入探讨这些主题。\nICE成功连接后，WebRTC继续建立加密的传输。此传输用于音频，视频和数据。\n使用DTLS和SRTP加密传输层 #  现在我们有了双向通信（通过ICE），我们需要建立安全的通信。这是通过WebRTC之前的两种协议完成的。第一个协议是DTLS（数据报传输层安全性），它只是基于UDP的TLS。TLS是用于保护通过HTTPS进行通信的加密协议。第二种协议是SRTP（安全实时传输协议）。\n首先，WebRTC通过在ICE建立的连接上进行DTLS握手来进行连接。与HTTPS不同，WebRTC不使用中央授权来颁发证书。相反，WebRTC只是判断通过DTLS交换的证书是否与通过信令共享的签名相符。然后，此DTLS连接可以被用于传输DataChannel消息。\n接下来，WebRTC使用RTP协议进行音频/视频的传输。我们使用SRTP来保护我们的RTP数据包。我们从协商的DTLS会话中提取密钥，用来初始化SRTP会话。在下一章中，我们讨论为什么媒体传输拥有其自己的协议。\n现在我们完成了！你现在可以进行安全的双向通信。如果你的WebRTC Agent之间具有稳定的连接，上面这就是你可能需要解决的所有复杂问题。不幸的是，现实世界中存在着数据包丢失和带宽限制，下一章节将介绍我们如何处理它们。\n通过RTP和SCTP进行点对点通信 #  现在，我们有了两个具有安全的双向通信功能的WebRTC Agent。让我们开始通信！跟前面一样，我们使用两个预先存在的协议：RTP（实时传输协议）和SCTP（流控制传输协议）。我们使用RTP来交换用SRTP加密过的媒体数据，使用SCTP发送和接收那些用DTLS加密过的DataChannel消息。\nRTP很小，但是提供了实现实时流式传输所需的功能。重要的是，RTP为开发人员提供了灵活性，因此他们可以根据需要处理延迟，丢失和拥塞。我们将在媒体章节中对此进行进一步讨论。\n堆栈中的最终协议是SCTP。SCTP支持许多不同的消息传送选项。你可以选择不可靠的无序交付，以便获得实时系统所需的延迟。\nWebRTC是一系列协议的集合 #  WebRTC解决了许多问题。初看起来，这似乎是过度设计的。实际上，WebRTC非常克制。它并未认为它可以更好的解决所有问题。相反，它采纳了许多现有的单一目的技术，并将它们捆绑在一起。\n这使得我们可以独立的检查和学习每个部分，而不会毫无头绪。实际上，从另一个角度去看“ WebRTC Agent”，它只是许多不同协议的协调器。\nWebRTC（API）如何工作 #  本部分显示JavaScript API是如何跟协议相对应的。这不只是WebRTC API的一个粗略演示，更像是创建了一个思维模型，以此将所有部分联系在一起。如果你对各部分都不熟悉，那也不要紧。当你了解更多信息时，再回头看看这一部分，可能会很有趣！\nnew RTCPeerConnection #  RTCPeerConnection是最顶层的\u0026quot;WebRTC会话\u0026rdquo;。它包含上述所有协议。所有子系统都已就位，但是什么都还没有发生。\naddTrack #  addTrack创建一个新的RTP流。并将为这个流生成一个随机的SSRC（Synchronization Source/同步源）。然后，createOffer将生成会话描述符，这个流将被加入其中的媒体部分。每次调用addTrack都会创建一个新的SSRC和对应的媒体部分。\n在建立SRTP会话后，这些媒体数据包将被SRTP加密，然后立即通过ICE开始发送。\ncreateDataChannel #  如果没有SCTP关联存在，createDataChannel将创建一个新的SCTP流。默认情况下，SCTP是不启用的，只有在一方请求数据通道时才启动。\n在DTLS会话建立之后，SCTP关联将立即通过ICE发送数据包，并使用DTLS加密。\ncreateOffer #  createOffer生成本地状态的会话描述，以与远端Peer共享。\n调用createOffer的行为对于本地Peer没有任何改变。\nsetLocalDescription #  setLocalDescription提交所有请求的更改。 在此调用之前，addTrack，createDataChannel和类似调用都是临时的。 调用setLocalDescription时，使用由createOffer生成的值。\n通常，在此调用之后，你会将offer发送给远端Peer，他们将调用setRemoteDescription，将此offer设入。\nsetRemoteDescription #  收到远端Peer发来的offer之后，我们通过setRemoteDescription通知本地Agent。这就是使用JavaScript API传递“信令”的方式。\n双方都调用过setRemoteDescription后，WebRTC Agent现在拥有足够的信息来开始进行点对点（P2P）通信！\naddIceCandidate #  addIceCandidate允许WebRTC Agent随时添加更多的远程ICE候选对象。该API将ICE候选对象发送到ICE子系统，并且对更大的WebRTC连接没有其他影响。\nontrack #  ontrack是从远端Peer收到RTP数据包时触发的回调。传入的RTP数据包应该已在传递给setRemoteDescription的会话描述中声明。\nWebRTC使用SSRC并查找关联的MediaStream和MediaStreamTrack，并使用填充的这些详细信息触发此回调。\noniceconnectionstatechange #  oniceconnectionstatechange是ICE Agent的状态变化时触发的回调。当网络连接或断开时，你将得到此通知。\nonstatechange #  onstatechange是ICE Agent和DTLS Agent状态的组合。当ICE和DTLS都成功完成时，你将得到此通知。\n"});index.add({'id':1,'href':'/zh/docs/02-signaling/','title':"信令",'section':"Docs",'content':"什么是WebRTC信令？ #  当一个WebRTC Agent被创建时，它对其他peer一无所知。它不知道它将与谁联系，也不知道它们将发送些什么！ 信令是使呼叫成为可能的初始引导程序。交换信令消息后，WebRTC Agent才可以直接相互通信。\n信令消息只是文本。WebRTC Agent并不关心它们的传递方式。信令通常使用Websockets分享，但这不是必需的。\nWebRTC信令如何工作？ #  WebRTC使用到一种现有的协议，称为会话描述协议（Session Description Protocol，简称SDP）。两个WebRTC Agent会将建立连接所需的所有状态通过此协议来分享。该协议本身亦易于阅读和理解。 但要理解WebRTC填充于协议中的所有值，将有一定复杂性。\n该协议不是WebRTC特有的。我们将首先学习会话描述协议，这里甚至不用提及WebRTC。WebRTC实际上仅是利用了SDP协议的子集，因此我们将仅介绍我们所需的内容。 理解协议后，我们将继续结合WebRTC来说明其在实际中的应用方法。\n什么是 会话描述协议（SDP）？ #  会话描述协议定义于 RFC 4566 中。它是一个key/value协议，每一行是一个值。看起来类似于INI文件。 一个会话描述包含零个或多个媒体描述。对此模型，可以理解为会话描述包含了一个媒体描述的数组。\n一个媒体描述通常映射到单个媒体流。因此，如果你想描述一个包含三个视频流和两个音轨的呼叫，需要五个媒体描述。\n如何阅读SDP信息 #  会话描述中的每一行都将以一个单字符开始，这是你的key。单字符后面将跟随一个等号。等号后的所有内容都是value。value结束的地方将有一个换行符。\n会话描述协议定义了所有有效的key。对于协议中定义的key，你只能使用字母。这些key都有重要的意义，稍后将对此进行解释。\n作为参考，下面是一个会话描述的部分内容：\na=my-sdp-value a=second-value 这里有两行。每行的key都是a。第一行的value为my-sdp-value，第二行的value为second-value。\nWebRTC仅使用了部分SDP的key #  WebRTC并未使用会话描述协议定义的所有key，只有那些在 JavaScript Session Establishment Protocol (JSEP，协议定义在RFC 8829)中被使用到的key 是重要的。你当前只需要理解下面的7个key。\n v - Version，版本，版本，应等于0。 o - Origin，源，包含一个唯一ID，用于重新协商。 s - Session Name，会话名称，应等于-。 t - Timing，时间，应等于0 0。 m - Media Description(m=\u0026lt;media\u0026gt; \u0026lt;port\u0026gt; \u0026lt;proto\u0026gt; \u0026lt;fmt\u0026gt; ...)，媒体描述，下面有详细说明。 a - Attribute，属性，一个自由文本字段，这是WebRTC中最常见的行。 c - Connection Data，连接数据，应等于IN IP4 0.0.0.0。  会话描述中的媒体描述 #  一个会话描述中，可以包含无限数量的媒体描述。\n一个媒体描述定义中，包含一个格式列表。这些格式映射到RTP有效负载类型。然后，实际的编解码器由媒体描述中的rtpmap属性定义。 RTP和RTP有效负载类型的重要性将在后面的媒体章节中讨论。每个媒体描述可以包含无限数量的属性。\n作为参考例子，下面是一个会话描述的部分内容：\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value 这里面有两个媒体描述，第一个是音频，格式为111，另一个是视频，格式为96。第一个媒体描述只有一个属性。该属性将有效载荷类型111映射到Opus编解码器。 第二个媒体描述具有两个属性。第一个属性将有效负载类型96映射到VP8编解码器，第二个属性只是my-sdp-value。\n译注：参照前面key的定义，第1行的v=0表示版本为0，第2/3行是第一个媒体描述，第4/5/6行是第二个媒体描述  完整示例 #  以下内容将我们讨论过的所有概念整合在一起。这些是WebRTC所使用的会话描述协议的所有特性。 如果你可以读懂这个例子，那么你可以读懂任何WebRTC会话描述！\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000  v, o, s, c, t 虽然被定义，但他们不对WebRTC会话产生影响。 这里有两个媒体描述。一个是audio即音频类型，一个是video即视频类型。 每个媒体描述都有一个属性。这个属性配置了RTP管道的详细信息，这部分将在\u0026quot;媒体通信\u0026quot;章节详细讨论  会话描述协议 和WebRTC如何协同工作 #  下一块拼图是理解WebRTC 如何 使用会话描述协议。\n什么是Offer和Answer？ #  WebRTC使用Offer/Answer模型。这指的是，一个WebRTC Agent发出\u0026quot;Offer\u0026quot;以开始呼叫，如果另一个WebRTC Agent愿意接受\u0026quot;Offer\u0026quot;的内容，它会响应\u0026quot;Answer\u0026rdquo;。\n这使得应答者有机会拒绝媒体描述中的某些不支持的编解码器，也是两个peer互相理解他们希望交换何种格式的方式。\n用于发送和接收的收发器（Transceivers） #  收发器是WebRTC中特有的概念，你将在API中看到它。它的作用是将\u0026quot;媒体描述\u0026quot;暴露给JavaScript API。每个媒体描述都将成为一个收发器。每次创建收发器时，都会将新的媒体描述添加到本地会话描述中。\nWebRTC中的每个媒体描述都包含一个direction属性。这样，WebRTC Agent可以声明\u0026quot;我将向你发送此编解码器，但我不打算接受任何返回的内容\u0026rdquo;。direction属性有四个有效值：\n send recv sendrecv inactive  WebRTC用到的SDP值 #  这个列表包含了你将在WebRTC Agent的会话描述中看到的一些常见属性。这些值控制着我们尚未讨论到的子系统。\ngroup:BUNDLE #  BUNDLE是一种在单个连接上传输多种类型流量的行为。一些WebRTC实现对每个媒体流会使用专用的连接。但BUNDLE方式应该是首选。\nfingerprint:sha-256 #  该属性是peer用于DTLS证书的哈希值。DTLS握手完成后，你可以将其与实际证书进行比较，以确认你正在与预期的对象进行通信。\n译注：下面是RFC 4572中的一个例子\na=fingerprint:SHA-1 \\ 4A:AD:B9:B1:3F:82:18:3B:54:02:12:DF:3E:5D:49:6B:19:E5:7C:AB   setup: #  该属性控制了DTLS Agent的行为。在ICE连接后，该属性将确定DTLS Agent是作为客户端还是服务器来运行。有以下几个可能的值：\n setup:active - 作为DTLS客户端运行。 setup:passive - 作为DTLS服务器运行。 setup:actpass - 要求另一个WebRTC Agent选择。  ice-ufrag #  该属性是ICE Agent的用户片段值。用于ICE流量的身份验证。\nice-pwd #  该属性是ICE Agent的密码。用于ICE流量的身份验证。\nrtpmap #  该属性用于将特定的编解码器映射到RTP有效负载类型。有效负载类型不是静态的，因此对于每次呼叫，发起者都需要确定每个编解码器的有效负载类型。\nfmtp #  该属性为一种有效负载类型定义附加的值。要传递特定的视频配置文件或编码器设置时，这很有用。\ncandidate #  该属性是来自ICE Agent的ICE候选地址。这是一个可能被WebRTC Agent使用的地址。这些将在下一章中详细说明。\nssrc #  一个同步源（SSRC）定义了一个单独的媒体流。\nlabel是此媒体流的ID。mslabel是容器的ID，该容器中可以有多个流。\nWebRTC会话描述示例 #  下面是一个WebRTC客户端生成的一套完整会话描述：\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv 从这个会话描述中，我们可以知道以下内容：\n 我们有两个媒体描述，一个是音频，一个是视频 这两个媒体描述都是 sendrecv 收发器。我们将得到两个流，也可以发送两个流回去。 我们有ICE候选地址和身份验证的详细信息，因此我们可以尝试连接 我们有一个证书指纹，因此我们可以进行安全的呼叫  译注：对照以上4点\n 两个媒体描述即是两个m=段 两个m段中都有a=sendrecv，即是说可以收也可以发 ICE候选地址对应a=candidate:foundation到a=end-of-candidates之间的部分，身份验证信息参考前面的ice-ufrag和ice-pwd等 指的是fingerprint:sha-256属性   进一步的话题 #  在本书的后续版本中，还将讨论以下主题：\n 重新协商（Renegotiation） 同步广播（Simulcast）  "});index.add({'id':2,'href':'/zh/docs/03-connecting/','title':"连接",'section':"Docs",'content':"为什么WebRTC需要专用的子系统进行连接？ #  目前，大多数部署的应用程序都通过客户端/服务器方式进行连接。客户端/服务器方式连接要求服务器具有稳定且公开可用的传输地址。客户端与服务器联系，然后服务器做出响应。\nWebRTC不使用客户端/服务器模型，它建立点对点（P2P）连接。 在P2P连接中，创建连接的任务被平均分配给两个对等方。这是因为无法猜测WebRTC中的传输地址（IP和端口），而且，在会话过程中，传输地址甚至可能会变更。WebRTC将收集所有可能收集的信息，并将尽力实现两个WebRTC Agent之间的双向通信。\n听起来简单，建立点对点连接实际上可能会非常困难。这些Agent可能位于没有直接连接的不同网络中。即使在两个Agent可以直接连接的情况下，你可能还会遇到其他问题。比如在某些情况下，两个客户端使用不同的网络协议（UDP \u0026lt;-\u0026gt; TCP）或使用不同的IP版本（IPv4 \u0026lt;-\u0026gt; IPv6）。\n尽管在建立点对点连接方面存在一些困难，在WebRTC提供的下面这些属性的帮助下，你仍然可以获得相对于传统客户端/服务器技术的一些优势。\n降低带宽成本 #  由于媒体通信直接发生在peer之间，因此你无需为之付费，也无需托管一个单独的服务器来转发媒体。\n更低延迟 #  直接通信时速度更快！当用户必须通过你的服务器运行所有内容时，这会使传输速度变慢。\n安全的端到端通信 #  直接通信更安全。由于用户数据根本没有通过你的服务器，因此用户压根不需要考虑你的服务器会不会解密其数据。\n它是如何工作的？ #  上面描述的连接过程是通过Interactive Connectivity Establishment（交互式连接建立/ICE） 实现的。这是另一个在WebRTC之前就已经出现的协议。\nICE是一种用来寻找两个ICE Agent之间通信的最佳方式的协议。每个ICE Agent都会发布如何访问自己的方式，这些路径被称为候选地址（candidates）。候选地址本质上是一个传输地址，ICE Agent认为这个传输地址可能可以被对端访问到。接下来ICE将确定候选地址的最佳搭配。\n本章稍后将详细介绍实际的ICE过程。要了解ICE为什么存在，最好先了解我们要面临的网络特性。\n现实世界的网络限制 #  ICE就是克服现实世界网络限制的方法。在我们开始讨论ICE如何解决问题之前，先讨论一下有哪些实际问题。\n不在同一个网络中 #  在大多数情况下，两个WebRTC Agent不在同一个网络中。典型的呼叫通常是在没有直接连接的不同网络中的两个WebRTC Agent之间进行的。\n下面是通过公共互联网连接的两个不同网络的示意图。在每个网络中，你拥有两个主机。\n对于同一网络中的主机来说，互相连接非常容易。例如在192.168.0.1 -\u0026gt; 192.168.0.2之间通讯就很容易！这两个主机无需任何外部帮助即可相互连接。\n但是，使用Router B的主机无法直接访问Router A背后的任何主机。你如何区分Router A后面的191.168.0.1主机和Router B后面相同IP的主机之间的区别呢？它们都使用内网IP！使用Router B的主机可以将数据直接发送到Router A，但是请求在那里就结束了。Router A怎么知道它应该将消息转发给哪台主机呢？\n协议限制 #  有些网络不允许UDP通信，或者也有可能不允许TCP。有些网络的MTU（Maximum Transmission Unit/最大传输单元）可能非常低。网络管理员可以更改许多变量，这些修改可能会使通信变得困难。\n防火墙/IDS规则 #  另一个问题是深度数据包检查和其他智能过滤方式。某些网络管理员将运行一些软件，这些软件会试图处理每个数据包。很多时候，这些软件无法识别WebRTC的数据包，由于它们不知道如何处理，它们可能会阻拦这些数据包，例如，它们可能将WebRTC数据包视为不在端口白名单上的可疑UDP数据包。\nNAT映射 #  NAT（网络地址转换）映射是使得WebRTC连接成为可能的魔法。WebRTC就是使用NAT让处于完全不同的子网中的两个peer进行通信，从而解决了上述\u0026quot;不在同一网络中\u0026quot;的问题。尽管它带来了新的挑战，但让我们先来解释一下NAT映射是如何工作的。\nNAT映射不使用中继，代理或服务器。跟上一个例子一样，我们有Agent 1和Agent 2，它们位于不同的网络中。然而，流量穿透了路由器。看起来就像这样：\n想要这样通信的话，你需要创建一个NAT映射。Agent 1使用端口7000与Agent 2建立WebRTC连接。这将创建一个192.168.0.1:7000到5.0.0.1:7000的绑定。然后，Agent 2将数据包发送到5.0.0.1:7000时，数据包会被转发给Agent 1。在这个例子中，创建一个NAT映射，就像是在路由器中做了一次自动化的端口转发。\nNAT映射的缺点是：映射的形式不止一种（例如静态端口转发），并且映射的实现方式在不同的网络中也是不一样的。ISP和硬件制造商可能会以不同的方式来实现NAT映射。在某些情况下，网络管理员甚至可能禁用它。\n好消息是，NAT映射的所有行为都是可以理解和观察到的，因此ICE Agent能够确认其创建了NAT映射，并确认该映射的属性。\n描述这些行为的文档是 RFC 4787。\n创建映射 #  创建映射是最简单的部分。当你将数据包发送到网络外部的地址时，一个映射就被创建出来了！NAT映射只是由NAT分配的一个临时的公共IP和端口。出站的消息将被重写，使得其源地址变为新创建的映射地址。如果有消息被成功发到映射地址，消息会被自动路由返回给NAT网络中创建这个映射地址的主机。说到映射相关的细节，这就开始变得复杂了。\n映射创建的行为 #  映射创建分为三类：\n端点无关的映射 #  这种创建方式为NAT网络中的所有发送者只创建一个映射。如果你将两个数据包发送到两个不同的远程地址，这个NAT映射将被重用。两个远程主机将看到相同的源IP和端口。如果远程主机响应，它将被发送回相同的本地侦听器。\n这是最好的情况。要使得呼叫能够建立起来，至少一侧必须是这种类型。\n地址相关的映射 #  每次将数据包发送到新地址时，都会创建一个新的映射。如果你将两个数据包发送到不同的主机，则会创建两个映射。如果将两个数据包发送到同一远程主机，但目标端口不同，则不会创建新的映射。\n地址和端口相关的映射 #  如果远程IP或端口不同，则会创建一个新的映射。如果将两个数据包发送到同一远程主机，但目标端口不同，则将创建一个新的映射。\n映射过滤行为 #  映射过滤是关于允许谁使用映射的规则。它们分为三个类似的类别：\n端点无关的过滤 #  任何人都可以使用该映射。你可以与其他多个peer共享该映射，他们都可以向该映射发送流量。\n地址相关的过滤 #  只有为其创建映射的主机才能使用该映射。如果你将数据包发送到主机A，则它可以根据需要响应任意数量的数据包。如果主机B尝试将数据包发送到该映射，将被忽略。\n地址和端口相关的过滤 #  仅有创建映射的主机和端口可以使用该映射。如果你将数据包发送到主机A:5000，则它可以根据需要响应任意数量的数据包。如果主机A：5001尝试将数据包发送到该映射，将被忽略。\n映射的刷新 #  通常的建议是，如果5分钟未使用映射，则应将其销毁。但这完全取决于ISP或硬件制造商。\n译注：换个说法，NAT映射的创建即是NAT网络中的主机发送数据时，路由器的处理方式；而过滤即是接收数据时，路由器的处理方式。映射的刷新即是路由器释放映射的处理方式。不同网络情况不同，因此某些特定的搭配会导致两个网络间无法建立P2P连接。在穿透相关的技术中，将不同的情况称为不同的锥形。  STUN #  STUN（NAT会话传输实用程序）是一种用来配合NAT使用的协议。这是WebRTC（和ICE！）之前的另一项技术。它由RFC 5389定义，该文件还定义了STUN数据包结构。STUN协议也在ICE/TURN中被使用。\nSTUN很有用，因为它允许以编程方式创建NAT映射。在STUN之前，我们能够创建NAT映射，但是我们不知道映射的IP和端口是什么！STUN不仅使你能够创建映射，还可以让你获取映射的详细信息，你可以他人分享这些详细信息，然后他们便可以通过你刚刚创建的映射向你传回数据。\n让我们从对STUN的基本描述开始。稍后，我们再将话题扩展到TURN和ICE的用法。现在，我们只打算描述请求/响应流程来创建映射。然后，我们将讨论如何获取该映射的详细信息以便与他人共享。当你在ICE URLs中有一个用于WebRTC PeerConnection的stun:服务器时，此过程就会发生。简而言之，STUN向NAT外部的STUN服务器发送请求，服务器返回其在请求中观察到的内容，STUN根据这些内容来帮助NAT后面的端点找出已创建的映射。\n协议结构 #  每个STUN数据包都具有以下结构：\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN 消息类型 #  每个STUN数据包都有一个类型。目前，我们仅关心以下几种：\n Binding Request - 0x0001 Binding Response - 0x0101  为了创建一个NAT映射，我们发出一个Binding Request。然后服务器回应一个Binding Response。\n消息长度 #  这就是Data段的长度。这一段中包含由消息类型所定义的任意数据。\nMagic Cookie #  指的是固定值0x2112A442，以网络字节顺序发送。这个值有助于将STUN流量与其他协议区分开。\n交互（Transaction）ID #  一个96-bit的标识符，用于唯一标识一个请求/响应对。这可以帮助你配对请求和响应。\n数据 #  数据将包含一个STUN属性的列表。一个STUN属性具有以下结构：\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN Binding Request不使用任何属性。这意味着一个STUN Binding Request仅包含header。\nSTUN Binding Response使用一个XOR-MAPPED-ADDRESS (0x0020)。此属性包含一个IP和一个端口。这正是所创建的NAT映射的IP和端口！\n创建NAT映射 #  使用STUN创建NAT映射只需要发送一个请求！你向STUN服务器发送一个STUN Binding Request。然后，STUN服务器回应一个STUN Binding Response。 该STUN Binding Response将包含映射地址。映射地址是STUN服务器看到你的方式，也是你的NAT映射。 如果你希望某人向你发送数据包，那么你应该共享该映射地址。\n人们还会将映射地址称为公网IP或Server Reflexive Candidate。\n确定NAT类型 #  不幸的是，映射地址可能并非在所有情况下都可用。如果是地址相关的映射，则只有STUN服务器才能将流量发送回给你。如果你共享它，那么另一个peer尝试向该地址发送的消息将被丢弃。这使得该peer无法与别的peer交流。如果STUN服务器还可以为你将数据包转发给对端peer，你可能会发现地址相关的映射问题实际上是可以解决的！这也就是下面将要说到的TURN解决方案。\nRFC 5780定义了一种方法，可以运行一个测试来确定你的NAT类型。这很有用，因为你可能会提前知道是否可以进行直接连接。\nTURN #  在无法建立直接连接的情况下，RFC 5766中定义了TURN（使用中继穿透NAT）。当你的两个peer的NAT类型不兼容，或者双方使用不同协议时，就需要使用TURN！TURN也可以被用于保护隐私的目的。如果通过TURN运行所有通讯，客户的真实地址在对端是被隐藏的。\nTURN使用专用服务器。该服务器充当客户端的代理。客户端连接到TURN服务器并创建一个对应的Allocation。通过创建该Allocation，客户端将获得一个临时IP/端口/协议三元组，其他peer可以使用该IP/端口/协议将数据发送给该客户端。这个新的监听地址被称为中继传输地址。你可将其视为转发地址并分享给他人，以便其他人可以通过TURN向你发送流量！对于每个将获得该中继传输地址的peer，你必须为其创建一个新的Permission，以允许它与你进行通信。\n当你通过TURN发送出站流量时，它会通过中继传输地址发送。当远程peer获得该出站流量时，他们会看到数据来自TURN服务器。\nTURN生命周期 #  下面就是一个客户端创建TURN allocation时必须做的所有事情。对于其他peer而言，与使用TURN服务器的客户端进行通信和其他客户端没有任何区别，先获得IP和端口，然后像跟其他任何主机一样通信。\nAllocations #  Allocations是TURN的核心。本质上，一个allocation就是一个\u0026quot;TURN会话\u0026rdquo;。要创建一个TURN allocation，你需要与TURN Server Transport Address（服务器传输地址，通常在3478端口）进行通信。\n创建allocation时，你需要提供/确定以下内容：\n 用户名/密码 - 创建TURN allocation时需要身份验证。 Allocation传输方式 - 中继传输地址可以是UDP或TCP方式。 连续端口 - 你可以为多个allocation请求顺序排列的一系列端口，这点与WebRTC无关。  如果请求成功，你将在TURN服务器上获得响应，在响应的数据部分，包含以下的STUN属性：\n XOR-MAPPED-ADDRESS - TURN Client的Mapped Address。当有人将数据发送到中继传输地址时，数据将被转发到该地址。 RELAYED-ADDRESS - 这是你提供给其他客户端的地址。如果有人将数据包发送到该地址，数据包会被转发到TURN客户端。 LIFETIME - Allocation被销毁的时间。你可以通过发送Refresh请求来延长这一时间。  译注：上面两个地址很拗口，但实际上理解起来并不复杂。Mapped Address是Turn Client的实际地址，也就是Turn Server收到数据包时的目标地址。而Relayed Address是Turn Client的名义地址，也就是其他WebRTC Agent要发送数据给这个Turn Client时，所使用的地址。  权限 #  在你为远程主机创建权限之前，远程主机是无法通过你的中继传输地址发送数据的。所谓创建权限，即是告知TURN服务器一个\u0026quot;可以用来发送入站流量\u0026quot;的IP和端口。\n远程主机需要先为你提供TURN服务器上使用的IP和端口。这意味着它应该先向TURN服务器发送一个STUN绑定请求。 有时会发生这样一个常见的错误情况，即是远程主机发送STUN绑定请求到另外一台服务器，然后再要求TURN服务器为此IP创建权限。\n对于上面那种错误情况，假设你要为一个使用地址相关的映射的NAT网络的主机创建权限，如果你从其他TURN服务器生成映射地址，则所有入站流量都将被丢弃。因为每次他们与其他主机通信时，它都会生成一个新的映射。如果未被刷新，权限将在5分钟后过期。\n译注：对于这个常见的错误情况，实际指的是被连接的主机从TURN服务器以外的STUN/TURN服务器获取本机IP，再告知发起连接的主机这样的情况。当被连接的主机使用地址相关的映射类型的NAT时，它获取的IP在当前的TURN服务器上是无效的。  SendIndication/ChannelData #  这是TURN客户端将消息发送到远端peer时所使用的两个消息。\nSendIndication是一个自包含的消息。它包含你希望发送的数据，以及你希望发送的目标。如果你要向远端peer发送大量消息的话，这种方式很昂贵。因为如果要发送1,000条消息，目标IP地址就被重复了1,000次！\nChannelData允许你发送数据，但不需要重复IP地址。你需要先创建一个具有IP和端口的通道（Channel）。然后使用ChannelId发送，IP和端口将在服务器端被填充进去。如果你要发送大量消息，这是更好的选择。\n刷新 #  Allocations将自动销毁。要避免其过早销毁，TURN客户端必须在创建allocation时指定的LIFETIME到来之前，及时刷新它们。\nTURN 使用方法 #  TURN有两种用法。通常情况下，一个peer会作为\u0026quot;TURN客户端\u0026quot;连接，而另一方则直接进行通信。在某些情况下，你可能在两侧都需要使用TURN服务。举例来说，当两个客户端都位于在禁用UDP的网络中时，只能通过TCP连接到各自的TURN服务器来建立连接。\n下面这些图有助于说明TURN的用法。\n单个 TURN Allocation 通信 #  双重 TURN Allocation 通信 #  译注：单个TURN Allocation的情况，指的是一个TURN Client和另一个可访问的UDP Client的通信。双重TURN Allocation的情况，指的是两个TURN Client之间通信。  ICE #  ICE（交互式连接建立）是WebRTC连接两个Agent的方式。这也是一项WebRTC前就有的技术，在RFC 8445中定义！ICE是用于建立连接的协议。它会确定两个peer之间所有可能的路由，然后确保你保持连接状态。\n这些路由被称为Candidate Pair（候选地址对），也就是本地地址和远程地址的配对。这就是STUN和TURN在ICE中发挥作用的地方。这些地址可以是你的本地IP地址，NAT映射或中继传输地址。通信双方需要收集它们要使用的所有地址，交换这些地址，然后尝试连接！\n两个ICE Agent使用ICE ping数据包（正式名称为连通性检查）通信以建立连接。一旦建立连接后，他们就可以发送任何数据。感觉就像使用普通socket一样。连通性检查使用STUN协议。\n创建ICE Agent #  ICE Agent要么处于控制中，要么处于受控中。控制中的 Agent是决定选择候选对的 Agent。通常来说，发送offer的peer是控制中的一方。\n每一方都必须有一个用户片段和一个密码。必须先交换这两个值，接下来才能进行连接性检查。用户片段以纯文本形式发送，用于多个ICE会话的解复用（demux）。 密码用于生成MESSAGE-INTEGRITY属性。在每个STUN数据包的末尾，都有这个属性，该属性是使用密码作为密钥的整个数据包的哈希值。这用于验证数据包并确保它未被篡改。\n对于WebRTC，所有这些值都通过上一章中所述的会话描述进行分发。\n候选地址收集 #  现在，我们需要收集所有可能联通的地址。这些地址被称为候选地址(Candidate)。\n主机 #  主机候选地址直接在本地接口上侦听。可以是UDP或TCP方式。\nmDNS #  mDNS候选地址类似于主机候选地址，但是其IP地址是隐藏的。你不必给对方提供你的IP地址，只需要给他们提供一个UUID作为主机名。然后设置一个多播监听器，并在有人请求你发布的UUID时进行响应。\n如果你与Agent位于同一网络中，则可以通过多播找到彼此。如果不在同一网络中，则将无法连接（除非网络管理员明确配置网络以允许多播数据包通过）。\n这对于保护隐私很有用。以前，用户可以通过WebRTC使用主机候选地址（甚至无需尝试与你连接）来找出你的本地IP地址。而使用mDNS候选地址的话，他们只能获得随机的UUID。\n服务器自反（Server Reflextive） #  服务器自反候选地址是通过对STUN服务器执行STUN绑定请求时生成的。\n当你收到STUN绑定响应时，XOR-MAPPED-ADDRESS就是你的服务器自反候选地址。\nPeer自反 #  Peer自反候选地址是指，当你从你不知道的地址收到入站请求时，由于ICE是经过身份验证的协议，因此你知道这些传输是合法的，这只是意味着远端Peer是通过它也不知道的地址与你通信。\n这通常会发生在这样的情况下，当主机候选地址与服务器自反候选地址进行通信时，由于你是在子网外部进行通信，因此创建了一个新的NAT映射。还记得我们说过的连通性检查实际上是STUN数据包吗？STUN响应的格式自然允许peer报告Peer自反地址。\n中继 #  中继候选地址是通过使用TURN服务器生成的。\n在与TURN服务器进行初始握手之后，你将获得RELAYED-ADDRESS，这就是你的中继候选地址。\n连通性检查 #  现在我们知道了远程Agent的用户片段，密码和候选地址。我们可以尝试连接了！ 候选地址可以相互配对。因此，如果每边有3个候选地址，那么现在就有9个候选地址对。\n看起来像这样\n候选地址选择 #  控制中的Agent和受控中的Agent都开始在每个候选地址对上发送流量数据。这样是必须的，因为如果一个Agent位于一个地址相关映射的网络中，这样会创建Peer自反候选地址。\n每个收到流量数据的候选地址对，会被提升为有效候选地址对。接下来，控制中的Agent将指定一个有效候选地址对。这就是提名候选地址对。然后，控制中的Agent和受控中的Agent再尝试进行一轮双向通信。如果成功，则提名候选地址对将成为选定的候选地址对！它将被用于后面的会话中。\n重新启动 #  如果选定的候选地址对由于任何原因停止工作（如：NAT映射到期，TURN服务器崩溃等），则ICEAgent将进入失败状态。此时可以重新启动两个Agent，然后重新完整执行整个过程。\n"});index.add({'id':3,'href':'/zh/docs/04-securing/','title':"安全性",'section':"Docs",'content':"WebRTC具有哪些安全性保障？ #  每个WebRTC连接都经过身份验证和加密。你可以确信第三方看不到你发送的内容，也无法插入虚假消息。你还可以确保与你进行通信的WebRTC Agent正是生成会话描述的Agent。\n没有人能够篡改消息这一点非常重要。如果第三方在传输中读取了会话描述，这不会产生什么影响。然而，WebRTC无法防止会话描述被修改。攻击者可以通过更改ICE候选地址和证书指纹来对你进行中间人攻击（man-in-the-middle）。\n译注：这里指的是，P2P连接建立之后，双方之间的通信安全是有保障的。但在连接建立的过程中，攻击者可以通过man-in-the-middle方式伪装中间人同时与通信双方建立连接并通信。  它是如何做到的？ #  WebRTC使用两个预先存在的协议，数据报传输层安全（Datagram Transport Layer Security / DTLS）和 安全实时传输协议（Secure Real-time Transport Protocol / SRTP）。\nDTLS使你可以协商会话，然后在两个peer之间安全地交换数据。它是TLS的同类产品，TLS是HTTPS所使用的技术，而DTLS与TLS的区别仅在与其使用UDP而不是TCP作为其传输层。这也意味着DTLS协议必须处理不可靠的数据传输。SRTP是专为安全的交换媒体数据而设计的。相对于DTLS而言，使用SRTP对传输媒体数据有一些优化。\nDTLS先被使用。它通过ICE提供的连接进行一次握手。DTLS是一种客户端/服务器协议，因此其中一侧需要开始握手。客户端/服务器的角色是在信令中被确定的。在DTLS握手期间，双方都会提供证书。 握手完成后，需要将收到的证书与会话描述中的证书哈希进行比较。这是为了确定握手的目标就是你所期望的WebRTC Agent。接下来，可以将DTLS连接用于DataChannel通信。\n要创建SRTP会话，我们使用DTLS生成的密钥对其进行初始化。SRTP没有握手机制，因此必须使用外部密钥进行引导。一旦完成此操作，媒体数据即可以用SRTP加密并进行交换！\n安全性101 #  要了解本章介绍的技术，你首先需要了解这些术语。密码学是一个棘手的主题，因此其他资源也是值得参考的！\n明文和密文 #  明文是cipher的输入。密文是cipher的输出。\nCipher #  Cipher是将明文转换为密文的一系列步骤。Cipher可以反过来运行，因此你可以将密文恢复为明文。一个cipher通常拥有一个更改其行为的密钥。还有一个术语是加密和解密。\n举例来说，一个简单的cipher是ROT13。也就是每个字母向前移动13个字符。要解密这个cipher，需要每个字母向后移动13个字符。明文HELLO将成为密文URYYB。 在这种情况下，Cipher是ROT，密钥是13。\n明文/密文 #  明文是cipher的输入。密文是cipher的输出。\n哈希函数 #  哈希函数是一种生成摘要的单向过程。给定一个输入，它每次都会生成相同的输出。其重要特点是输出不可逆。也就是说，根据输出的摘要，无法确定其输入。当你要确认消息未被篡改时，哈希函数很有用。\n举例来说，一个简单的哈希函数的作用仅仅是将所有其他字母HELLO变成HLO。你不能认为HELLO就是输入，但可以确认如果输入的是HELLO，那么结果是匹配的。\n公钥/私钥加密 #  公钥/私钥加密描述了DTLS和SRTP使用的cipher类型。在此系统中，你有两个密钥，即公钥和私钥。公钥用于加密消息，可以安全共享。 私钥用于解密消息，永远不应共享。当解密那些使用对应的公钥加密的消息时，它是唯一的密钥。\nDiffie-Hellman交换 #  Diffie-Hellman交换允许两个以前从未见过的用户通过Internet安全的创建一个共享的秘密信息。用户A可以将秘密信息发送给用户B，而不必担心被窃听。破解该信息的难度将取决于破解离散对数问题的难度。 你不必完全理解该算法是如何工作的，但这可以帮助你了解是什么使得DTLS握手变得可行的。\nWikipedia在此处中有一个实际的例子。\n伪随机函数（PRF） #  伪随机函数是一个预定义函数，用于生成随机出现的值。它可能需要多个输入并生成一个输出。\n密钥派生（KDF） #  密钥派生是一类伪随机函数。是一种用于增强密钥的安全性的方法。一种常见的模式是密钥扩展。\n假设你获得的密钥为8字节。你可以使用KDF使其更坚固。\nNonce #  Nonce是cipher的附加输入。这样，即使你多次加密同一条消息，也可以从cipher中获得不同的输出。\n如果将同一条消息加密10次，cipher将为你提供10次相同的密文。通过使用nonce，在使用同一个密钥的情况下，你将得到不同的输入。需要注意的是，每条消息都要使用不同的nonce！ 否则就没有太大意义了。\n消息身份验证代码（Message Authentication Code） #  消息身份验证代码（MAC）是放在消息末尾的哈希值。MAC能证明该消息来自你期望的用户。\n如果你不使用MAC，攻击者可能会插入无效的消息。因为他们不知道密钥，所以这些消息解密后是无意义的垃圾内容。\n密钥轮换 #  密钥轮换是一种间隔一段时间便更改密钥的做法。这种做法会使得被窃取的密钥影响较小。如果密钥被窃取或泄漏，那么只有很少的数据可以被解密。\nDTLS #  DTLS（数据报传输层安全协议）允许两个peer在没有预先存在的配置的情况下建立安全的通信。即使有人窃听了通信，他们也将无法解密消息。\n为了使DTLS客户端和服务器进行通信，他们需要就cipher和密钥达成一致。他们通过进行DTLS握手来确定这些值。在握手期间，消息为纯文本格式。 当DTLS客户端/服务器交换了足够的详细信息以开始加密时，它会发送Change Cipher Spec（更改Cipher规格）消息。在此消息之后，后续的每个消息都将会被加密！\n数据包格式 #  每个DTLS数据包开头都包含一个头部信息。\n内容类型 #  你可以看到数据包包括以下几种类型：\n 20 - Change Cipher Spec（更改Cipher规格） 22 - Handshake（握手） 23 - Application Data（应用程序数据）  握手用于交换详细信息以开始会话。 更改Cipher规格用于通知另一端所有内容都将被加密。应用程序数据是加密的消息。\n版本 #  版本可以是0x0000feff（DTLS v1.0）或0x0000fefd（DTLS v1.2），没有v1.1。\nEpoch（时段） #  时段从0开始，但在更改Cipher规格之后变为1。在非零时段的任何消息都将被加密。\n序列号 #  序列号用于保持消息顺序。每条消息都会增加序列号。当Epoch（时段）增加时，序列号重新开始。\n长度和有效载荷 #  有效载荷是特定于内容类型的。对于应用程序数据而言，有效载荷是加密的数据。对于握手，它会根据消息而有所不同。长度是指有效载荷的大小。\n握手状态机 #  在握手期间，客户端/服务器交换一系列消息。这些消息被分为多个Flight。每个Flight中可能有多个消息（或只有一个）。 直到收到Flight中的所有消息，该Flight才算完成。我们将在下面更详细地描述每条消息的目的。\nClientHello #  ClientHello是客户端发送的初始消息。它包含一个属性列表。这些属性告诉服务器客户端支持的cipher和功能。对于WebRTC，这也是我们选择SRTP cipher方式的原因。它还包含将用于生成会话密钥的随机数据。\nHelloVerifyRequest #  服务器将HelloVerifyRequest发送到客户端。这是为了确认客户端准备继续发送请求。然后，客户端重新发送ClientHello，但这一次需要携带HelloVerifyRequest中提供的令牌。\nServerHello #  ServerHello是服务器响应消息，是此次会话的配置信息。它包含此会话直到结束时将使用的cipher。它还包含服务器端的随机数据。\nCertificate #  Certificate包含客户端或服务器的证书。它被用来唯一识别我们与之通信的对方。握手结束后，我们将确保这个证书的哈希与SessionDescription中的指纹相匹配。\nServerKeyExchange/ClientKeyExchange #  这些消息用于传输公共密钥。在启动时，客户端和服务器都会生成密钥对。握手后，这些值将被用来生成Pre-Master Secret。\nCertificateRequest #  CertificateRequest由服务端发送，用来通知客户端需要一个证书。服务端既可以请求一个证书，也可以要求必须提供证书。\nServerHelloDone #  ServerHelloDone通知客户端此时服务器已完成握手动作。\nCertificateVerify #  发送者用CertificateVerify消息来证明他已经获得了Certificate消息中发送的私钥。\nChangeCipherSpec #  ChangeCipherSpec通知接收者在此消息之后发送的所有内容都将被加密。\nFinished #  Finished消息是加密的，它包含所有消息的哈希。用来断言握手过程未被篡改。\n密钥的生成 #  握手完成后，你可以开始发送加密数据。Cipher是由服务器选择的，位于ServerHello消息中。但接下来如何生成密钥呢？\n首先，我们需要生成Pre-Master Secret。为了获得该值，我们通过ServerKeyExchange和ClientKeyExchange消息，使用Diffie-Hellman算法来交换密钥。细节因选定的Cipher而异。\n接下来，生成Master Secret。每个版本的DTLS都有一个定义的Pseudorandom function（伪随机函数）。对于DTLS 1.2，伪随机函数会在ClientHello和ServerHello中获取Pre-Master Secret和随机值。 运行Pseudorandom function后，获得的输出是Master Secret。Master Secret是用于Cipher的值。\n交换ApplicationData #  DTLS的主要内容是ApplicationData。现在我们有了一个初始化好的Cipher，我们可以开始加密和发送数据了。\n如前所述，ApplicationData消息使用一个DTLS标头。Payload中填充了密文。你现在可以正常使用DTLS会话，并且可以安全地进行通信。\nDTLS具有更多有趣的功能，例如重新协商等。WebRTC中不使用这些功能，因此此处不作介绍。\nSRTP #  SRTP是针对加密RTP数据包专门涉及的协议。要启动SRTP会话，需要指定密钥和cipher。与DTLS不同，它没有握手机制。所有的配置和密钥都是在DTLS握手期间生成的。\nDTLS提供了专用的API，用来导出密钥以供另一个进程使用。这是在RFC 5705中定义的\n会话创建 #  SRTP定义了一个密钥派生函数，用于处理输入。在创建SRTP会话时，密钥派生函数将被执行，用输入数据生成SRTP Cipher的密钥。之后，你可以继续处理媒体。\n交换媒体数据 #  每个RTP数据包都有一个16位的SequenceNumber（序列号）。这些序列号用于使数据包保持顺序，就像主键一样。在通话期间，这些序列号将滚动累加。SRTP会对其进行跟踪，并将其称为滚动计数器。\n加密数据包时，SRTP使用滚动计数器和序列号作为nonce。这是为了确保即使两次发送相同的数据，密文也会有所不同。这样做很重要，可以阻止攻击者识别模式或尝试重播攻击。\n"});index.add({'id':4,'href':'/zh/docs/05-real-time-networking/','title':"搭建实时网络",'section':"Docs",'content':"为什么网络在实时通信中如此重要？ #  网络是实时通信中的限制因素。在理想的世界中，我们将拥有无限的带宽，并且数据包会即时到达。但事实并非如此。网络是受限的，且其限定条件随时可能更改。测量和观察网络状况也是一个难题。根据你所使用的硬件，软件及其配置，你可能看到不同的表现。\n实时通信也带来了其他大多数领域中不存在的问题。对于网站开发人员来说，如果你的网站在某些网络上运行速度较慢，那不是致命问题。只要所有数据到达，用户都会感到满意。但对于WebRTC，如果你的数据延迟了，那就没用了。没有人在乎5秒钟前的电话会议中所说过的话。因此，在开发一个实时通信系统时，必须作出权衡。我的时间限制是多少，可以发送多少数据？\n本章介绍了适用于数据和媒体通信的概念。在后面的章节中，我们将超出理论范围，讨论一下WebRTC的媒体和数据子系统如何解决这些问题。\n使网络变得困难的有哪些属性？ #  在所有网络上都能有效工作的代码很复杂。你会面对许多不同的因素，它们都可以相互影响。这些是开发人员将遇到的最常见问题。\n带宽 #  带宽是可以在给定路径上传输的最大数据速率。请记住，这也不是一个静态数字，这一点很重要。随着越来越多（或更少）的人使用带宽，带宽将沿路由变化。\n传输时间和往返时间 #  传输时间指的是一个数据包需要多长时间到达。像带宽一样，这不是恒定的。传输时间随时可能波动。\n传输时间 = 接收时间 - 发送时间\n要计算传输时间，你需要将发送方和接收方的时钟以毫秒级精度同步。 即使一个很小的偏差也会导致传输时间的测量结果不可靠。 由于WebRTC在高度异构的环境中运行，因此依靠主机之间完美的时间同步（来测量传输时间）几乎是不可能的。\n往返时间测量是对不完美的时钟同步的一种解决方法。\n（要测量往返时间，）WebRTC peer不使用分布式时钟，而是发送一个特殊数据包，携带名为sendertime1的自己的时间戳。 合作的peer接收到这个特殊数据包后，会将时间戳返还给发送方。 当原始发送方获得返还的时间戳时，它会用当前时间sendertime2减去sendertime1时间戳。 得到的时间差称为\u0026quot;往返传播延迟（round-trip propagation delay）\u0026quot;，或者就使用更常见的\u0026quot;往返时间\u0026rdquo;。\nrtt（往返时间） = sendertime2 - sendertime1\n通常认为，往返时间的一半是传输时间足够好的近似值。 但此解决方法并非没有缺点。 它假设发送和接收数据包花费的时间是相等的。 但是，在蜂窝网络上，发送和接收操作可能不是时间对称的。 你可能已经注意到了，手机上的上传速度几乎总是低于下载速度。\n传输时间 = rtt（往返时间）/2\n关于往返时间测量的技术，在RTCP的发送方和接收方报告章节中有更详细的描述。\n抖动 #  抖动是每个数据包的传输时间可能会有所不同的现实表现。你的数据包可能会延迟，但随后会突然大量集中到达。\n数据包丢失 #  数据包丢失是指消息在传输中丢失。数据损失率可能是稳定的，也可能出现波峰和波谷。 这可能是由于网络类型的原因造成的，例如卫星或Wi-Fi等。或者也可能是传输路径上的软件导致的。\n最大传输单位（MTU） #  最大传输单位指的是单个数据包大小的限制。网络不允许你发送一个巨大的消息。在协议级别，消息可能必须被拆分为多个较小的数据包。\n根据你采用的网络路径，MTU也将有所不同。你可以使用MTU路径发现之类的协议来确定可以发送的最大数据包大小。\n拥塞 #  拥塞是指网络达到极限时的情况。这通常是因为你已达到当前路由可以处理的峰值带宽。或者可能是运营商对你的ISP配置导致，比如限制了每小时的流量。\n拥塞会以多种不同的方式展现出来。没有标准化的表现。在大多数情况下，当拥塞发生时，网络将丢弃多余的数据包。在其他一些情况下，网络将缓存数据包。这将导致数据包的传输时间增加。随着网络的拥塞，你还会看到更多的抖动。这是一个快速变化的领域，并且还有其他用于拥塞检测的新算法目前仍在编写中。\n动态变化 #  网络是动态的，各种状况可能会迅速变化。在通话过程中，你可能会发送和接收数十万个数据包。 这些数据包可能经过多个跃点。这些跃点可能由数百万其他用户共享。即使在你的本地网络中，你也可能正在下载高清电影，或者可能有设备正要下载软件更新。\n保证通话质量不能仅仅是在启动时简单的度量你的网络。你需要持续不断的评估。还需要处理来自于多种网络硬件和软件的所有不同表现。\n解决数据包丢失问题 #  处理数据包损失是需要解决的首要问题。有多种解决方法，每种方法都有自己的优势。这取决于你要发送的内容以及对延迟的容忍度。同样重要的一点是，并非所有数据包丢失都是致命的。丢失一些视频可能不是什么问题，人眼甚至可能无法感觉到。但丢掉用户的短信就是不可接受的了。\n假设你发送了10个数据包，而数据包5和6丢失了。下面是一些解决问题的方法。\n确认（Acknowledgments） #  确认是指接收方收到每个数据包时，都去通知发送方。如果发送方收到一个数据包的两次确认消息，且该数据包不是最终数据包时，发送方就会意识到有数据包已经丢失。例如，当发送方两次收到数据包4的ACK消息时，它就知道接收方没有收到数据包5。\n选择性确认（Selective Acknowledgments） #  选择性确认是对确认的改进。接收方可以发送一个SACK消息来确认多个数据包已经收到，并通知发送者间隔时间。 例如，发送方可能收到一个包含数据包4和7的SACK消息。这样它就知道需要重新发送数据包5和6。\n否定应答（Negative Acknowledgments） #  否定应答以相反的方式解决了问题。接收方并不通知发送方自己已经收到了什么，而是通知发送方丢失了什么。在我们的例子里，将为数据包5和6发送一个NACK。发送方仅知道接收方希望再次发送的数据包。\n前向纠错（FEC） #  前向纠错可以抢先解决丢包问题。发送方将发送冗余数据，这意味着部分数据包丢失不会影响最终流。一种流行的算法是Reed–Solomon纠错算法。\n这减少了发送和处理确认的延迟/复杂度。如果你所在的网络的损耗为零，则前向纠错会浪费带宽。\n解决抖动问题 #  大多数网络都存在抖动。即使在局域网内部，你也有许多设备以变化的速率发送数据。你可以通过运行ping命令对其他设备执行ping操作，并注意往返延迟的波动，从而轻松地观察到抖动。\n要解决抖动问题，客户端使用JitterBuffer。JitterBuffer确保数据包的稳定传递时间。不利的一面是，JitterBuffer为提前到达的数据包增加了一些延迟。好处是延迟的数据包不会引起抖动。想象一下，在通话期间，你可能会看到类似下面这样的数据包到达时间。\n* time=1.46 ms * time=1.93 ms * time=1.57 ms * time=1.55 ms * time=1.54 ms * time=1.72 ms * time=1.45 ms * time=1.73 ms * time=1.80 ms 在这个例子里，1.8ms左右将是一个不错的选择。较晚到达的数据包将使用我们的延迟窗口。较早到达的数据包将被延后一点，并可以填充由较晚的数据包耗尽的延迟窗口。这意味着我们不会再陷入无数据包可用的困境，从而为客户提供顺畅的传输率。\nJitterBuffer（抖动缓冲区）操作 #  每个数据包到达时，将立即被添加到抖动缓冲区。 一旦有了足够的数据包来重建帧，组成该帧的数据包将被从缓冲区中释放出来，并发给解码器进行解码。 解码器按顺序进行解码，并在用户屏幕上绘制视频帧。 由于抖动缓冲区的容量是有限的，因此在缓冲区中停放时间过长的数据包将被丢弃。\n关于视频帧是如何转换为RTP数据包，以及为何需要重建视频帧的知识，你可以在媒体通信章节中读到更多。\njitterBufferDelay（抖动缓冲延迟）为了解你的网络性能及其对播放平滑度的影响提供了一个很好的视角。 它是WebRTC统计API中的一部分，与接收方的入站流有关。 该延迟定义了视频帧在被发给解码器之前在JitterBuffer中所花费的时间。 较长的抖动缓冲延迟，意味着你的网络处于高度拥塞状态。\n检测拥塞问题 #  在我们解决拥塞问题之前，我们需要先检测到拥塞。为了检测到它，我们使用拥塞控制器。这是一个复杂的主题，并且仍在迅速变化中。 一些新算法仍在持续被发布和测试。总的来看，它们都以相同的方式运行。即是说，拥塞控制器在给定某些输入的情况下提供带宽估计值。 这里是一些可能的输入：\n 数据包丢失 - 随着网络逐渐变得拥塞，数据包开始被丢弃。 抖动 - 随着网络设备变得越来越过载，将导致数据包排队时间变得不稳定。 封包往返时间（RTT） - 拥塞时，数据包将需要更长的时间才能到达。与抖动不同的是，往返时间是持续增加的。 显式拥塞通知（ECN） - 较新的网络可能会将数据包标记为有拥塞造成丢失的风险，这样可以缓解拥塞。  这些值需要在通话期间持续不断的测量。网络的利用率可能会增加或减少，因此可用带宽可能会不断变化。\n解决拥塞问题 #  现在我们有了一个估计的带宽值，我们需要调整发送的内容。如何调整取决于我们要发送的数据类型。\n降低发送速度 #  限制发送数据的速度是防止拥塞的第一个解决方案。拥塞控制器为你提供了带宽的估计值，发送方有责任对发送速率进行限制。\n这是适用于大多数数据通信的方法。对于像TCP这样的协议，这全部由操作系统完成，并且对用户和开发人员都是完全透明的。\n减少发送的数据 #  在某些情况下，我们可以发送更少的信息来满足我们的限制。对于数据的到达时间，我们可能有严格的限制，因此我们发送速度不能太慢。这些是实时媒体所受的限制。\n如果我们没有足够的可用带宽，我们可以降低发送的视频质量。这要求你的视频编码器和拥塞控制器之间存在紧密的反馈回路。\n"});index.add({'id':5,'href':'/zh/docs/06-media-communication/','title':"媒体通信",'section':"Docs",'content':"我可以从WebRTC的媒体通信中得到什么？ #  WebRTC允许你发送和接收无限多条音频和视频流。你可以在通话期间随时添加和删除这些流。这些流可以全部独立，也可以捆绑在一起！你甚至可以将网络摄像头的音频和视频放到你桌面的视频中，然后将此视频以feed的形式发送出去。\nWebRTC协议与编解码器无关。底层传输支持所有格式的内容，即使是还不存在的格式！ 但是，你正与之通信的WebRTC Agent可能没有必要的工具来接受它。\nWebRTC针对动态网络状况也有对应的处理方案。在通话过程中，带宽可能会增加或减少。甚至可能突然间大量丢包。该协议对所有这类问题的处理都做了相应的设计。WebRTC根据网络状况作出响应，并尝试利用可用资源为你提供最佳体验。\n它是如何工作的？ #  WebRTC使用RFC 1889中定义的两个既有协议RTP和RTCP。\nRTP（实时传输协议/Real-time Transport Protocol）是承载媒体的协议。它为视频的实时传输而设计。它没有规定有关延迟或可靠性的任何规则，但是为你提供了实现这些规则的工具。RTP提供了流的设计，因此你可以通过一个连接发布多个媒体源。它还为你提供了完善媒体传递途径所需的计时和排序信息。\nRTCP（RTP控制协议/RTP Control Protocol）是用于传达有关呼叫的元数据的协议。其格式非常灵活，并允许你可以添加所需的任何元数据。这点被用来传达有关呼叫的统计信息。也是处理分组丢失和实现拥塞控制的必备特性。它为你提供了响应变化的网络状况所必需的双向通信能力。\n延迟与质量 #  实时媒体就是要在延迟和质量之间进行权衡。你愿意忍受的延迟时间越长，可以预期的视频质量就越高。\n现实世界的局限性 #  下面这些限制都是由现实世界的局限性引起的。它们都是你需要考虑的网络特性。\n视频是复杂的 #  传输视频并不容易。要存储30分钟未经压缩的720p的8-bit视频，你需要大约110GB。按照这个数据，4人电话会议就开不成了。我们需要一种缩小容量的方法，而答案就是视频压缩。但是，这并非没有缺点。\n视频101 #  我们不会深入介绍视频压缩，只需要让大家足以理解为什么RTP是这么设计的。视频压缩会将视频编码为一种新格式，这样可以需要较少的bit数来表示同一视频。\n有损和无损压缩 #  你可以将视频编码为无损（无信息丢失）或有损（信息可能丢失）压缩。由于无损编码需要将更多的数据发送到对端，这样会导致更高的流延迟和更多的丢包，因此RTP通常使用有损压缩，即使这样可能会导致视频质量不佳。\n帧内和帧间压缩 #  视频压缩有两种类型。首先是帧内压缩。帧内压缩减少了用于描述单个视频帧的bit数。相同的技术被用来压缩静态图片，例如JPEG压缩方法。\n第二种类型是帧间压缩。由于视频是由许多图片组成的，因此我们需要寻找无需将相同信息发送两次的方式。\n帧间压缩 #  帧有三种类型：\n I帧 - 一张完整的图片，无需任何其他内容即可解码。 P帧 - 一张图片的一部分，仅包含对之前图片的修改。 B帧 - 一张图片的一部分，包含对之前图片和将来图片的修改。  以下是对这三种类型帧的图解。\n视频很脆弱 #  压缩后的视频是有状态的，（视频解码）非常依赖其上下文，这使得视频很难通过Internet进行传输。想像一下，如果I帧的一部分丢失了会怎样？这样P帧如何知道要修改的内容？ 随着视频压缩变得越来越复杂，这成为一个更大的问题。幸运的是，RTP和RTCP对此都有解决方案。\nRTP #  Packet Format（包格式） #  每个RTP数据包都具有以下结构：\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P|X| CC |M| PT | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Synchronization Source (SSRC) identifier | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | Contributing Source (CSRC) identifiers | | .... | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version (V) #  Version总是2。\nPadding (P) #  Padding是控制有效载荷是否具有填充值的布尔值。\n有效负载的最后一个字节包含添加了多少填充字节的计数。\nExtension (X) #  如果设置的话，RTP报头将有扩展段（可选）。这点将在下面更详细地描述。\nCSRC count (CC) #  在SSRC之后，有效负载之前的CSRC标识符的数量。\nMarker (M) #  标记位没有预设含义，用户可以根据自己的需求随意使用它。\n在某些情况下，它是在用户讲话时设置的。它还通常用于标记关键帧。\nPayload Type (PT) #  Payload Type（负载类型）是此数据包所承载的编解码器的一个唯一标识符。\n对于WebRTC，Payload Type是动态的。一个呼叫中的VP8的PT可能与另一个呼叫中的不同。呼叫中的offerer确定Payload Type到Session Description（会话描述符）中的编解码器的映射。\nSequence Number #  Sequence Number（序列号）用于对流中的数据包进行排序。每次发送数据包时，Sequence Number都会增加1。\nRTP被设计为可以在有损网络上使用。这为接收器提供了一种检测数据包何时丢失的方法。\nTimestamp #  此数据包的采样时刻。这不是全局时钟，而是在当前媒体流中所经过的时间。举例来说，如果多个 RTP 包都属于同一视频帧，那么它们可能具有相同的时间戳。\nSynchronization Source (SSRC) #  SSRC是此流的唯一标识符。这使你可以在单个RTP流上传输多个媒体流。\nContributing Source (CSRC) #  一个列表，用于表示哪些SSRC参与到了这个数据包中。\n这通常用于语音指示器。假设在服务器端，你将多个音频源组合到一个单独的RTP流中。然后，你可以在此字段中表示\u0026quot;输入流A和C此时正在讲话\u0026rdquo;。\nPayload #  实际有效负载数据。如果设置了填充（padding）标记，则可能以添加的填充字节数结尾。\nExtensions（扩展） #  RTCP #  Packet Format #  每个RTCP数据包都具有以下结构：\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |V=2|P| RC | PT | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Version (V) #  Version总是2。\nPadding (P) #  Padding是控制有效载荷是否具有填充值的布尔值。\n有效负载的最后一个字节包含添加了多少填充字节的计数。\nReception Report Count (RC) #  此数据包中的报告数。单个RTCP数据包可以包含多个事件。\nPacket Type (PT) #  指示RTCP数据包类型的唯一标识符。WebRTC Agent不需要支持所有这些类型，并且Agent之间的支持能力可以是不同的。下面这些是你可能经常看到的类型：\n 192 - 完整的帧内请求（FIR）- 193 - 否定确认（NACK） 200 - 发送方报告 201 - 接收方报告 205 - 通用RTP反馈 206 - 有效负载特定反馈  这些分组类型的意义将在下面更详细地描述。\n完整的帧内请求（FIR）和图片丢失指示（PLI） #  FIR和PLI消息的目的是类似的。这些消息都是向发送方请求一个完整的关键帧。 PLI用于解码器得到了部分帧，但却无法解码的情况。 之所以会发生这种情况，是因为你有很多数据包丢失，或者解码器崩溃了。\n根据RFC 5104，当数据包或帧丢失时，不应使用FIR，那是PLI的任务。用FIR请求关键帧适用于丢包以外的其他原因（例如，当新成员进入视频会议时）。他们需要一个完整的关键帧才能开始对视频流进行解码，解码器将丢弃一些帧，直到关键帧到达为止。\n对于接收方来说，在连接建立后立即请求一个完整的关键帧是个好主意，这可以最大程度地减少连接建立和在用户屏幕上显示图像之间的延迟。\nPLI数据包是\u0026quot;有效负载特定反馈\u0026quot;消息的组成部分。\n在实践中，能够同时处理PLI和FIR数据包的软件在两种场景下的行为是相同的。它会向编码器发送信号以产生新的完整关键帧。\nNegative ACKnowledgements（否定确认） #  NACK请求发送方重新发送单个RTP数据包。这通常是由于RTP数据包丢失而引起的，但是也可能由于延迟而发生。\n与请求重新发送整个帧相比，NACK的带宽使用效率要高得多。由于RTP将数据包分解成很小的块，因此你实际上只是在请求丢失的一个很小的部分。接收方使用SSRC和序列号制作RTCP消息。如果发送方没有可用于重新发送的RTP数据包，那么它只会忽略该消息。\nSender and Receiver Reports（发送方和接收方报告） #  这些报告用于在Agent之间发送统计信息。它传达了实际接收到的和抖动的数据包数量。\n这些报告可用于诊断以及控制拥塞。\nRTP/RTCP是如何协作解决问题的 #  RTP和RTCP需要协同解决网络引起的所有问题。这些技术仍在不断进化中！\nForward Error Correction（前向纠错） #  简称为FEC。处理丢包的另一种方法。FEC指的是发送方多次重复发送相同的数据，甚至是在接收方没有要求的情况下发送。这是在RTP协议层级完成的，甚至也可以在编解码器以下的层级完成。\n在呼叫的数据丢包率比较稳定的情况下，作为延迟处理方案，FEC比NACK好的多。对于NACK，必须先请求，然后重新传输丢失的数据包，数据往返的时间对性能的影响可能是很明显的。\n自适应比特率和带宽估计 #  正如搭建实时网络章节中讨论的那样，网络是不可预测且不可靠的。带宽的可用性在整个会话中可能会多次变化。 在一秒钟之内看到可用的带宽急剧变化（差别达到数量级），这样的情况并不少见。\n这里的主要思路是根据预测的，当前的和将来的可用网络带宽来调整编码比特率。 这样可以确保传输质量最佳的视频和音频信号，并且不会因为网络拥塞而断开连接。 对网络行为建模并尝试对其进行预测的启发式方法称为带宽估计。\n这里有很多细微的差别，因此，让我们来探索一下更多细节。\n传递网络状态 #  实施拥塞控制的第一个路障是UDP和RTP不会传递网络状态。作为发送方，我不知道我的数据包在什么时候到达，甚至根本不知道它们到达了没有！\n针对此问题，RTP/RTCP有三种不同的解决方案。每种都有自己的优点和缺点。使用什么方案取决于你面向的客户类型、使用的网络拓扑类型、甚至是你有多少开发时间。\n接收方报告 #  接收方报告是一些RTCP消息，这是传递网络状态的最原始的方法。你可以在RFC 3550中找到它们。按照时间计划，它们会被发送给每个SSRC，并包含以下字段：\n 丢包率 - 自上次接收者报告以来丢失了数据包的百分比。 累计丢包数 - 在整个通话过程中丢了多少包。 接收到的最高序列号扩展 - 接收到的最后一个序列号，以及它滚动的次数。 到达间隔抖动（Interarrival Jitter） - 整个通话过程中的抖动滚动。（译注：RTP数据包到达时间的统计方差的估计值，以时间戳为单位进行度量，并表示为无符号整数。） 上次发送方报告时间戳（Last Sender Report Timestamp） - 已知的最后一次的发送方报告的时间戳，用于往返时间的计算。  发送方和接收方报告（SR和RR）配合，可以计算往返时间。\n发送方在SR中包含其本地时间sendertime1。 当接收方获得SR数据包时，发回RR。 除了其他一些信息，RR还要包括刚从发送方接收到的sendertime1。 在接收SR和发送RR之间，会有一个延迟。因此，RR还包括\u0026quot;自上次发送方报告以来的延迟\u0026quot;时间 - DLSR（delay since last sender report）。 DLSR用于在该过程的稍后阶段调整往返时间的估计。 一旦发送者接收到RR，它就从当前时间sendertime2中减去sendertime1和DLSR。 该时间差称为往返传播延迟或往返时间。\nrtt（往返时间） = sendertime2 - sendertime1 - DLSR\n换个简单的说法来解释，就是这样：\n 我看了看表，向你发送了一条消息，说这是下午4点20分42秒420毫秒。 你再将相同的时间戳发回给我。 （返回的消息中）还包括了从阅读我的消息到发回消息所花费的时间，例如5毫秒。 收到时间后，我会再次看时钟。 现在我的表是下午4点20分42秒690毫秒。 这意味着消息需要265毫秒（690-420-5）才能到达你，并返回到我。 因此，往返时间为265毫秒。  TMMBR，TMMBN和REMB #  下一代的网络状态消息都是接收方通过带有显式比特率请求的RTCP消息传递给发送方。\n TMMBR（临时最大媒体码率请求） - 单个SSRC请求码率的尾数/指数。（译注：接收端当前带宽受限，告诉发送端控制码率。） TMMBN（临时最大媒体码率通知） - （发送端）通知（接收端）已经收到TMMBR的消息。 REMB（接收方估计的最大码率） - 整个会话中请求码率的尾数/指数。  TMMBR和TMMBN是先出现的，它们在RFC 5104中定义。REMB是后来出现的，是在draft-alvestrand-rmcat-remb中提交的一个草案，但从未被标准化。\n使用REMB的会话如下图所示：\n浏览器使用简单的经验法则来估计传入带宽：\n 如果当前丢包小于2％，则告知编码器去提高比特率。 如果丢包高于10％，则降低比特率，减少的值为当前丢包率的一半。  if (packetLoss \u0026lt; 2%) video_bitrate *= 1.08 if (packetLoss \u0026gt; 10%) video_bitrate *= (1 - 0.5*lossRate) 这个方法在纸面上看起来效果很好。发送方从接收方接收估计值，然后将编码器比特率设置为接收到的值。啊哈！我们已经根据网络条件作出了调节。\n然而，在实践中，REMB方法有几个缺点。\n其中一个缺点是编码器的能力限制。当你为编码器设置比特率时，它不一定能准确的按照你要求的比特率进行输出。根据编码器的设置和正在被编码的帧的情况，它的输出可能会更少或更多。\n举例来说，x264编码器，配置为tune=zerolatency，跟指定的目标比特率相比，其输出可能会产生明显的偏离。下面是一种可能的场景：\n 假设我们一开始将比特率设置为1000kbps。 由于没有很多高频特征值需要编码，编码器只能输出700kbps。（亦称为：\u0026ldquo;凝视一堵墙\u0026rdquo;。） 我们再假设接收方获得了700kbps的视频，没有发生数据包丢失，然后它将应用REMB的规则1，把输入比特率提升8％。 接收方向发送方发送了一个REMB包，建议将输入比特率提高到756kbps（700kbps * 1.08）。 发送方将编码器的比特率设置为756kbps。 编码器输出更低的比特率。 这个过程会继续重复进行，这样，比特率会被降低到绝对最小值。  你可以看到，这会导致多次编码器参数调整；同时用户会惊讶的发现，虽然连接状况良好，但视频质量看起来却让人难以接受。\n传输范围内的拥塞控制（TWCC） #  传输范围内的拥塞控制是RTCP网络状态通信技术的最新进展。\nTWCC使用一个非常简单的原则：\n与REMB不同，TWCC的接收方不会尝试估计自己的传入比特率。它只是让发送方知道哪些包被收到了，是在什么时间收到的。基于这些报告，发送方可以了解网络的最新的状况。\n 发送方创建带有特殊的TWCC标头扩展的RTP数据包，其中包含一个数据包序列号的列表。 接收方以特殊的RTCP反馈消息进行响应，以使发送方知道每个数据包是否以及何时被接收。  发送方跟踪已发送的数据包，包括它们的序列号，大小和时间戳。 当发送方从接收方收到RTCP消息时，它将发送数据包间的延迟与接收延迟进行比较。 如果接收延迟增加，则意味着网络正在发生拥塞，发送者必须对此采取行动。\n在下图中，数据包间延迟的中位数增长了+20毫秒，这清楚地表明网络正在发生拥塞。\nTWCC提供了原始数据和实时网络状况的绝佳视图：\n 几乎是即时的丢包统计信息，不仅包括丢失的百分比，还包括丢失的确切数据包。 准确的发送比特率。 准确的接收比特率。 抖动估计。 发送和接收数据包延迟之间的差异。  一种简单的，用于估计从发送方到接收方的传输比特率的拥塞控制算法是，将接收到的数据包大小相加，然后将其除以接收方一端经过的时间。\n生成带宽估计值 #  现在，我们掌握了有关网络状态的信息，可以针对可用带宽进行估算了。IETF在2012年成立了RMCAT（RTP媒体拥塞避免技术）工作组。 该工作组包含了已提交的多个拥塞控制算法的标准。在此之前，所有的拥塞控制算法都是专有的。\n部署最多的实现是\u0026quot;用于实时通信的Google拥塞控制算法（GCC）\u0026quot;，定义于draft-alvestrand-rmcat-congestion。 它可以分两次运行。第一次运行是\u0026quot;基于损失\u0026quot;的，仅使用接收方报告。如果TWCC是可用的，其数据也将纳入估计。 它通过使用Kalman过滤器预测当前和将来的网络带宽。\n还有几种GCC的替代品，例如：NADA：一种实时媒体的统一拥塞控制方案 和 SCReAM- 多媒体的自时钟速率自适应。\n"});index.add({'id':6,'href':'/zh/docs/07-data-communication/','title':"数据通信",'section':"Docs",'content':"我可以从WebRTC的数据通信中获得什么？ #  WebRTC提供用于数据通信的数据通道。在两个peer之间，你可以打开65,534个数据通道。 数据通道基于数据报，并且每个通道都有其自己的持久性设置。默认设置下，每个数据通道都能保证有序交付。\n如果你从传递媒体数据的角度开始接触WebRTC，可能数据通道看起来是一种浪费。当我只使用HTTP或WebSocket就能传递数据的时候，为什么需要整个数据通道子系统呢？\n数据通道的真正强大之处在于，你可以将它们配置为像UDP一样进行无序/有损传递。 对于低延迟和高性能的情况，这是必需的。你可以测量背压，并确保你仅发送网络支持的最大数据量。\n它是如何工作的？ #  WebRTC使用RFC 2960中定义的流控制传输协议（SCTP）。SCTP是一种传输层协议，旨在替代TCP或UDP。对于WebRTC，我们将SCTP用作在DTLS连接上运行的应用层协议。\nSCTP为你提供流，并且每个流都可以独立配置。WebRTC数据通道只是基于流的简单抽象。有关持久性和顺序的设置会被直接传递到SCTP Agent中。\n数据通道具有SCTP无法表达的某些功能，例如通道标签。为了解决该问题，WebRTC使用了RFC 8832中定义的数据通道建立协议（DCEP）。DCEP定义了一条消息，用于传递通道标签和协议。\nDCEP #  DCEP只有两个消息DATA_CHANNEL_OPEN和DATA_CHANNEL_ACK。对于打开的每个数据通道，远端必须以ack响应。\nDATA_CHANNEL_OPEN #  该消息由希望打开数据通道的WebRTC Agent发送。\n封包格式 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | Channel Type | Priority | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Reliability Parameter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Label Length | Protocol Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Label / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Protocol / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 消息类型（Message Type） #  消息类型是一个静态值0x03。\n通道类型（Channel Type） #  Channel Type controls durability/ordering attributes of the channel. It may have the following values: 通道类型控制通道的持久性/排序属性。它可能具有以下值：\n DATA_CHANNEL_RELIABLE (0x00) - 没有消息丢失，消息依序到达。 DATA_CHANNEL_RELIABLE_UNORDERED (0x80) - 没有消息丢失，但消息可能乱序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT (0x01) - 按照请求中的次数重试发送后，消息可能会丢失，但消息将依序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_REXMIT_UNORDERED (0x81) - 按照请求中的次数重试发送后，消息可能会丢失，且消息可能乱序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED (0x02) - 如果没有在请求的时间内到达，消息可能会丢失，但消息将依序到达。 DATA_CHANNEL_PARTIAL_RELIABLE_TIMED_UNORDERED (0x82) - 如果没有在请求的时间内到达，消息可能会丢失，且消息可能乱序到达。  优先级（Priority） #  数据通道的优先级。具有较高优先级的数据通道将首先被调度。较大的低优先级用户消息不会耽误高优先级用户消息的发送。\n可靠性参数 #  如果数据通道类型的前缀为DATA_CHANNEL_PARTIAL_RELIABLE，则不同的后缀对应的参数配置如下：\n REXMIT - 定义发送方重试发送消息的次数，超出此次数将放弃尝试。 TIMED - 定义发送方重试发送消息的时间（以毫秒为单位），超出此时间将放弃尝试。  标签（Label） #  一个包含数据通道名称的UTF-8编码的字符串。可能为空。\n协议（Protocol） #  如果这里为空字符串，则协议未指定。如果是非空字符串，则这里应指定一个协议，可指定的协议请参考RFC 6455中定义的\u0026quot;WebSocket子协议名称注册表\u0026quot;中的注册协议。\nDATA_CHANNEL_ACK #  WebRTC Agent发送此消息以确认此数据通道已打开。\n封包格式 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Message Type | +-+-+-+-+-+-+-+-+ 流控传输协议（SCTP） #  SCTP是WebRTC数据通道背后的真正动力。它提供了数据通道的以下所有功能：\n 多路复用 使用类似TCP的重传机制进行可靠传递 部分可靠性选项 避免拥塞 流量控制  为了理解SCTP，我们将分三个部分进行探讨。我们的目标是，在本章之后，你将拥有足够的知识来自行调试和学习SCTP的详细信息。\n概念 #  SCTP协议功能很多。本节仅涵盖WebRTC使用的SCTP部分。 SCTP中，WebRTC不使用的功能包括多宿主（multi-homing）和路径选择。\n经过20多年的发展，SCTP变得难以完全掌握。\n关联（Association） #  关联是用于SCTP会话的术语。这是两个SCTP Agent在通信时共享的状态。\n流 #  一个流是用户数据的一个双向序列。创建数据通道时，实际上只是在创建一个SCTP流。每个SCTP关联都包含一个流列表。可以为每个流配置不同的可靠性类型。\nWebRTC只允许你在创建流时进行配置，而SCTP实际上允许随时更改配置。\n基于数据报 #  SCTP将数据构造为数据报，而不是字节流。发送和接收数据就像是使用UDP而不是TCP。 你无需添加任何额外的代码即可通过一个流传输多个文件。\nSCTP消息没有像UDP这样的大小限制。单个SCTP消息的大小可以达到几个GB。\n块（Chunks） #  SCTP协议由块组成。有许多不同类型的块。这些块用于所有通信。 用户数据，连接初始化，拥塞控制等，全部通过块完成。\n每个SCTP数据包都包含一个块列表。因此，在一个UDP数据包中，你可以有多个块承载来自不同流的消息。\n传输序列号 #  传输序列号（TSN）是DATA块的全局唯一标识符。DATA块承载用户希望发送的所有消息。TSN很重要，因为它可以帮助接收方确定数据包是否丢失或乱序。\n如果接收方注意到缺少TSN，则在数据完整获取之前，它不应将数据提供给用户。\n流标识符 #  每个流都有一个唯一的标识符。当你创建带有显式ID的数据通道时，实际上是将其作为流标识符直接传递到SCTP中。如果你没有传递ID，则会为你自动选择流标识符。\n有效负载协议标识符 #  每个DATA块还具有一个有效负载协议标识符（PPID）。这用于唯一地标识正在交换的数据类型。 SCTP具有许多PPID，但是WebRTC仅使用以下五种：\n WebRTC DCEP (50) - DCEP消息。 WebRTC String (51) - Datachannel字符串消息。 WebRTC Binary (53) - Datachannel二进制消息。 WebRTC String Empty (56) - 长度为0的Datachannel字符串消息。 WebRTC Binary Empty (57) - 长度为0的Datachannel二进制消息。  协议 #  以下是SCTP协议使用的一些块。这不是一个详尽的演示。只提供了足够的结构让状态机运作起来。\n每个块均以type字段开头。在块列表之前，还有一个头字段。\nDATA块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 0 | Reserved|U|B|E| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream Identifier | Stream Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload Protocol Identifier | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / User Data / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ DATA块是交换所有用户数据的方式。下面是对DATA块更详细的说明，数据就是这样通过数据通道被发送的。\n如果是无序数据包，则将U位设置为1。我们可以忽略流序列号（Stream Sequence Number）。\nB和E是开始位和结束位。如果要发送的消息对于单个DATA块而言太大，则需要将其分片成多个DATA块发送。 SCTP使用 比特位B和E 以及序列号（TSN）来描述消息分包。\n B=1, E=0 - 用户消息的第一个分片。 B=0, E=0 - 用户消息的中间的分片。 B=0, E=1 - 用户消息的最后一个分片。 B=1, E=1 - 未分片的用户消息。  TSN是Transmission Sequence Number，一个 DATA chunk 的唯一标识符。它是一个递增的32-bit数，在达到最大值4,294,967,295 之后，继续从0开始递增。\nStream Identifier（流标识符）是该数据所属流的唯一标识符。\nStream Sequence Number , 标识一个用户消息。它是一个递增的16-bit数，在 达到最大值 65535 之后，继续从0开始递增。 比特位U设置为1时，表示无序消息包，Stream Sequence Number可以忽略。 比特位U设置为0时，表示有序消息包，该编号用于确定消息包的顺序。 与TSN类似，但是 Stream Sequence Number 以一个用户消息的粒度递增，TSN以一个Chunk的粒度递增。\nPayload Protocol Identifier（有效负载协议标识符）是流过此流的数据类型。对于WebRTC而言，它可能是DCEP，String或Binary。\nUser Data（用户数据）就是你要发送的内容。通过WebRTC Data Channel发送的所有数据均通过DATA块传输。\nINIT块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 1 | Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initiate Tag | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Outbound Streams | Number of Inbound Streams | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Initial TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Optional/Variable-Length Parameters / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ INIT块开始创建一个关联（association）的过程。\nInitiate Tag（启动标签）用于生成Cookie。Cookies技术在中间人攻击和DoS保护中可能会被用到。在状态机章节中对它们进行了更详细的描述。\nAdvertised Receiver Window Credit（广播接收者窗口信用值）用于SCTP的拥塞控制。它传达了接收方已为此关联分配了多大的缓冲区。\nNumber of Outbound/Inbound Streams（出站/入站流的数量）通知该Agent支持多少个流。\nInitial TSN（初始TSN）是随机的uint32，本地TSN以这个值开始计数。\nOptional Parameters（可选参数）允许SCTP向协议引入新功能。\nSACK块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 3 |Chunk Flags | Chunk Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Advertised Receiver Window Credit (a_rwnd) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Number of Gap Ack Blocks = N | Number of Duplicate TSNs = X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #1 Start | Gap Ack Block #1 End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Gap Ack Block #N Start | Gap Ack Block #N End | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN 1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ ... \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Duplicate TSN X | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ SACK（选择性确认）块是接收方通知发送方它已收到数据包信息的方式。在发送方获得针对TSN的SACK之前，它将重新发送有问题的DATA块。然而，SACK的作用不只是更新TSN信息。\nCumulative TSN ACK（累积TSN ACK）是已收到的最高TSN。\nAdvertised Receiver Window Credit（广播接收者窗口信用值）是接收方的缓冲区大小。如果可用内存增加，接收方可以在会话期间更改此设置。\n在Cumulative TSN ACK（累积TSN ACK）后面，是Ack Blocks的TSN。 这个方法用来解决传送的数据包中有缺口的问题。假设我们收到了带有TSN100,102,103和104的DATA块。Cumulative TSN ACK应该是100，但可以使用Ack Blocks来告诉发送方不需要重新发送102,103或104。\nDuplicate TSN（重复TSN）会通知发送方，它已经不止一次的接收了哪些DATA数据块。\nHEARTBEAT块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 4 | Chunk Flags | Heartbeat Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / Heartbeat Information TLV (Variable-Length) / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ HEARTBEAT块用于断言远端仍能响应。 当你不发送任何DATA数据块，且需要保持NAT映射打开时，这很有用。\nABORT块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 6 |Reserved |T| Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ / / \\ Zero or more Error Causes \\ / / +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ABORT块用于关联的突然关闭。当一侧进入错误状态时使用。正常结束连接使用SHUTDOWN块。\nSHUTDOWN块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 7 | Chunk Flags | Length = 8 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Cumulative TSN Ack | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ SHUTDOWN块将正常关闭SCTP关联。 每个Agent将其发送的最后一个TSN通知给远端。这样可以确保不会丢失任何数据包。（如果有资源仍在使用中的话，）WebRTC不能正常关闭SCTP关联。你需要自行关闭所有数据通道。\nCumulative TSN ACK（累积TSN ACK）是发送的最后一个TSN。双方都知道在接收到此TSN对应的DATA块之前不要终止。\nERROR块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 9 | Chunk Flags | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ \\ / One or more Error Causes / \\ \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ERROR块用于通知远端SCTP Agent：本端发生了非致命错误。\nFORWARD TSN块 #   0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type = 192 | Flags = 0x00 | Length = Variable | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | New Cumulative TSN | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-1 | Stream Sequence-1 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ \\ / / \\ +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Stream-N | Stream Sequence-N | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ FORWARD TSN块将全局TSN向前移动。SCTP这样做是为了允许跳过一些你不再关心的数据包。假设你发送了10 11 12 13 14 15，这些数据包只有在它们全部到达后才有意义。而这些数据又对实时性很敏感，在这种情况下，如果数据收晚了，它们就没有用了。\n如果你丢失了12和13，则不需要再发送14和15！ SCTP使用FORWARD TSN块来实现这一点。它告诉接收方，14和15将不再传递。\nNew Cumulative TSN（新的累积TSN），是连接的新TSN。此TSN之前的任何数据包都不会被保留。\nStream（流）和Stream Sequence（流序列）用于将Stream Sequence Number的编号向前跳转。请参阅前面的DATA块以了解该字段的重要性。\n状态机 #  这里是SCTP状态机中一些有趣的部分。WebRTC并未使用SCTP状态机的所有功能，因此我们将没有用到的部分排除在外。我们还简化了一些组件，使它们更易于理解。\n连接建立流程 #  INIT和INIT ACK块用于交换peer的能力和配置。SCTP在握手期间使用cookie来验证与之通信的peer。 这是为了确保握手不会被拦截并防止DoS攻击。\nINIT ACK块包含cookie。然后，使用COOKIE ECHO将cookie返回给其创建者。如果cookie验证成功，则发送COOKIE ACK，并且准备交换DATA块。\n连接关闭流程 #  SCTP使用SHUTDOWN块。当Agent收到SHUTDOWN块时，它将等待直到收到请求的Cumulative TSN ACK。这样，即使连接有损，用户也可以确保传送了所有数据。\nKeep-Alive（保持活动）机制 #  SCTP使用HEARTBEAT REQUEST和HEARTBEAT ACK块使连接保持活动状态。它们以固定间隔发送，间隔时间可配置。如果数据包尚未到达，SCTP还会将指数回退。\nHEARTBEAT块还包含一个时间值。两个关联可以用此来计算两个Agent之间的数据传递时间。\n"});index.add({'id':7,'href':'/zh/docs/08-applied-webrtc/','title':"WebRTC应用场景",'section':"Docs",'content':"WebRTC应用场景 #  现在你已经知道WebRTC的工作原理，到了使用它的时候了！本章探讨人们使用WebRTC构建什么以及他们是如何实现的。你将学到基于WebRTC发生的所有有趣的事情。WebRTC的功能是有代价的。建立产品级的WebRTC服务相当有挑战性。本章将尝试解释这些挑战性的根源，这样你遇到问题时就能有所准备。\n用例 #  许多人认为WebRTC只是一种在web浏览器中实现电话会议的技术。实际上，它能做的不仅如此！ WebRTC被广泛用于各种用例。新的用例一直在出现。在本章中，我们将列出一些常见的用例，并探讨一下WebRTC是如何对它们进行革新的。\n电话会议 #  电话会议是WebRTC的原始用例。该协议包含浏览器中几个必要功能，这些功能没有其他协议提供支持。你可以使用WebSockets构建会议系统，在各种条件都满足的情况下，它可能可以工作。但如果你希望在现实世界的网络条件下部署一些服务，那么WebRTC是最佳选择。\nWebRTC为媒体提供拥塞控制和自适应比特率。随着网络条件的变化，用户仍将获得最佳体验。开发人员不必编写任何其他代码来处理这些情况。\n参与者可以发送和接收多个流。在呼叫过程中，他们还可以随时添加和删除这些流。编解码器也经过协商。所有这些功能都是由浏览器提供的，开发人员无需编写任何自定义代码。\n数据通道也对电话会议有所助益。用户可以发送元数据或共享文档。如果更看重性能而不是可靠性，可以创建多个流并对其进行配置。\n广播 #  许多使用WebRTC的新项目开始出现在广播领域中。协议为媒体的发布者和消费者都提供了很多支持。\n浏览器中的WebRTC使得用户可以轻松发布视频。这样用户不需要下载新的客户端。 任何具有Web浏览器的平台都可以发布视频。发布者可以发送多个音轨/视频流，并可以随时对其进行修改或删除。传统协议中每个连接只允许一个音频或一个视频流，与之相比，这是一个巨大的改进。\nWebRTC使开发人员可以更好地控制延迟和质量之间的权衡。如果不允许延迟超过特定阈值更重要，那么为此你可能愿意容忍对解码质量做一些让步。你也可以将播放器配置为在媒体到达时立即播放。如果是使用在TCP之上的其他协议，要完成这一点并不是那么容易。但在浏览器中，你只需要请求数据，就这么简单。\n远程访问 #  远程访问是当你通过WebRTC访问远端的另一台计算机。你可以完全控制远程主机，也可以只控制一个应用程序。当本地硬件无法执行繁重的计算任务时，这非常有用。例如，运行新的视频游戏或CAD软件。WebRTC能够通过下面三种方式彻底改变对物理空间的需求。\nWebRTC可用于远程访问那些无法直接路由的主机。使用NAT遍历，你可以访问仅通过STUN可用的计算机。这对于安全性和隐私性非常有用。你的用户不必通过中转或所谓\u0026quot;跳转盒\u0026quot;来路由视频。NAT遍历还使得部署更加容易。你不必担心端口转发问题或提前设置静态IP。\n在这种场景下，数据通道也非常强大。可以对它们进行配置，以便仅接受最新数据。使用TCP运行时，可能会遇到队头阻塞的风险。旧式的鼠标点击或按键可能会迟到，并阻止后续的鼠标被接受。 WebRTC的数据通道的设计可以处理此问题，并且可以配置为不重试丢失的数据包。你还可以测量背压，并确保你不会发送更多的数据以至于网络无法支持。\n浏览器中提供的WebRTC极大地改善了生活质量。你无需下载专有客户端即可开始会话。捆绑了WebRTC的客户端越来越多，智能电视现在也开始拥有了完整的Web浏览器。\n文件共享和审查制度 #  文件共享和审查规避是截然不同的问题。然而，WebRTC同时解决了他们两者的相同问题。它使得文件既容易获得又更难以阻止。\nWebRTC解决的第一个问题是客户端的获取。如果要加入文件共享网络，需要下载客户端。即使网络是分布式的，你仍然需要首先获得客户端。在受限制的网络中，下载通常会被阻止。即使你可以下载它，用户也可能无法安装和运行客户端。而WebRTC在每个Web浏览器中都可用，这点使得它无处不在。\nWebRTC解决的第二个问题是流量被阻止的情况。如果你使用的协议仅用于文件共享或审查制度，那么阻止它会容易得多。由于WebRTC是通用协议，阻止它将影响所有人。阻止WebRTC可能会影响网络中的其他用户加入电话会议。\n分布式CDN #  物联网（IoT） #  物联网（IoT）部分涵盖了几种不同的用例。许多人都见过网络连接的安防摄像头。使用WebRTC，你可以将视频流式地传输到另一个WebRTC对等设备，例如电话或浏览器。另一个用例是让设备连接并交换传感器数据。你的局域网中可以有两个设备，互相交换天气，噪音或明亮度的读数。\n与传统的视频流协议相比，WebRTC具有巨大的隐私优势。由于WebRTC支持P2P连接，因此摄像头可以将视频直接发送到你的浏览器。没有必要将你的视频发送到第三方服务器。即使视频是经过加密的，攻击者也可以根据通话的元数据做出一些猜测。\n互操作性是物联网领域的另一个优势。WebRTC支持多种不同的语言，包括C＃，C ++，C，Go，Java，Python，Rust和TypeScript。这意味着你可以使用最适合你的语言。而且你无需求助于专有协议或格式就可以连接你的客户端。\n媒体协议桥接 #  如果你现有的硬件和软件已经在产生视频，但是你还不能对其进行升级。期望用户下载专有客户端来观看视频是一件令人沮丧的事。解决问题的答案是运行一个WebRTC桥接器。桥接器在两种协议之间进行转换，因此用户可以在浏览器中使用旧的设置。\n开发人员桥接使用的许多格式都使用与WebRTC一致的协议。SIP通常通过WebRTC暴露接口，并允许用户从其浏览器拨打电话。RTSP用于许多旧式安保摄像头。它们都使用相同的基础协议（RTP和SDP），因此其计算成本很低。只需要添加或删除WebRTC特定的内容即可完成桥接工作。\n数据协议桥接 #  Web浏览器只能通过一组受限制的协议通信。你可以使用HTTP，WebSockets，WebRTC和QUIC。如果要连接到其他设备，你需要使用协议桥。协议桥是将外部流量转换为浏览器可访问内容的服务器。一个流行的示例是从浏览器使用SSH访问服务器。使用WebRTC的数据通道构建协议桥的话，具有下面两个优势。\nWebRTC的数据通道允许不可靠且无序的交付。这在低延迟至关重要的情况下是必需的。你不会希望新数据被旧数据阻挡，这就是所谓的队头阻塞。假设你正在玩多人参与的第一人称射击游戏。你真的在乎玩家在两秒钟前的位置吗？如果这些数据没有及时到达，那么继续尝试发送就没有意义了。不可靠和无序的传送使你在一收到数据时就可以立即得到它。\n数据通道还提供压力反馈。这可以告诉你发送数据的速度是否超过了连接所能支持的速度。然后，当这种情况发生时，有两个选择。可以将数据通道配置为缓冲并延迟传送数据，也可以删除尚未实时到达的数据。\n远程操作 #  远程操作是指通过WebRTC数据通道控制远端设备，并通过RTP将视频数据发送回来。现在的开发人员已经可以通过WebRTC远程驾驶汽车了！这种技术可以用来控制施工现场和运送包裹的机器人。使用WebRTC解决这些问题很有意义，原因有两个。\nWebRTC的普及使用户可以轻松控制。用户所需的只是一个Web浏览器和一个输入设备。浏览器甚至支持从操纵杆和游戏手柄获取输入。WebRTC完全不需要在用户设备上安装其他客户端。\n分布式CDN #  分布式CDN是文件共享的子集。分发的文件由CDN操作员配置。当用户加入CDN网络时，他们可以下载和共享允许的文件。用户获得与文件共享相同的所有好处。\n当你在外部连接很差但LAN连接很好的办公室中时，这些CDN效果很好。你可以让一个用户下载视频，然后与其他人共享。由于不需要每个人都尝试通过外部网络获取相同的文件，因此传输将更快地完成。\nWebRTC拓扑 #  WebRTC是用于连接两个Agent的协议，那么开发人员如何能同时连接上百人呢？你可以通过下面几种不同的方式来做到这一点，它们各有利弊。这些解决方案大致分为两类；点对点或客户端/服务器。WebRTC的灵活性使我们能够同时创建两者。\n一对一 #  一对一是你使用WebRTC的第一种连接方式。将两个WebRTC Agent直接连接，它们可以双向发送媒体和数据。 连接看起来像这样。\n全网格 #  如果要建立电话会议或多人游戏，那么要使用全网格。在这种拓扑中，每一个用户都直接与其他各个用户建立连接。你可以这样构建应用，但是它有一些缺点。\n在全网格拓扑中，每个用户都直接连接（到其他用户）。这意味着你必须为参与通话的每个成员独立编码和上传视频。 由于各个连接的网络条件会有所不同，因此你无法重用同一视频。在这些部署中，错误处理也很困难。你需要仔细考虑连接是不是已经彻底断开了，还是只是丢掉了与单个远端peer的连接。\n由于这些问题，全网格最好用于小型群组。对于更大的群组，最好还是使用客户端/服务器拓扑。\n混合网格 #  混合网格是全网格的替代方案，可以减轻全网格的某些问题。在混合网格中，并不是所有每个用户之间都建立连接。作为替代，媒体是通过网络中的peer转发的。这意味着分发媒体时，创建者可以不必使用那么多的带宽。\n这种方案确实也有一些缺点。在这种配置下，就算是媒体最初的创建者也不知道视频是谁发送的，也不知道视频是否成功的到达了目标。在混合网格网络中，每增加一跳，延迟也会相应地增加。\n选择性转发单元（Selective Forwarding Unit） #  SFU（选择性转发单元）同样解决了全网格网络的问题，但它使用了一种完全不同的方案。SFU以客户端/服务器拓扑实现，而不是P2P网络。 每个WebRTC peer都连接到SFU并上传其媒体。然后，SFU将此媒体转发到其他每个连接的客户端。\n使用SFU，每个WebRTC Agent只需要执行一次视频的编码和上传。SFU负责将视频分发给所有观看者。 与SFU的连接也比P2P方式容易得多。你可以让SFU运行于一个全世界都可以访问的地址上，从而使得客户端连接更加容易。 你无需担心NAT映射。但你仍然需要确保SFU是可以通过TCP（ICE-TCP或TURN）使用的。\n要创建一个简单的SFU，一个周末就可以完成。但建立一个可以处理所有类型客户的高质量SFU，是永无止境的。因为，拥塞控制调优、纠错和提高性能，是一项永无止境的任务。\n多点会议单元（Multi-point Conferencing Unit） #  MCU（多点会议单元）与SFU的客户端/服务器拓扑类似，但它会对输出流进行组合。MCU将要出站的媒体重新编码为一个供稿，而不是直接分发未经修改的版本。 "});index.add({'id':8,'href':'/zh/docs/09-debugging/','title':"调试",'section':"Docs",'content':"调试 #  调试WebRTC可能是一项艰巨的任务。有很多部分都处于运行状态，每一个部分都可能出现问题。如果你不够细心，可能会浪费数周的时间来查看错误的模块。当你最终找到出错的部分时，你还需要学习一些知识才能理解问题的根源。\n本章将带你学习WebRTC的调试。它将向你展示如何分析并定位相关问题。确定问题后，我们将快速介绍一下流行的调试工具。\n分解问题 #  开始调试时，你需要先分解问题的源头。从以下题目开始：\n信令故障 #  网络故障 #  使用netcat测试你的STUN服务器：\n  准备20字节的绑定请求数据包：\necho -ne \u0026quot;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026quot; | hexdump -C 00000000 00 01 00 00 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 |TEST| 00000014 解释：\n 00 01 是消息类型。 00 00 是数据段的长度。 21 12 a4 42 是magic cookie。 54 45 53 54 54 45 53 54 54 45 53 54 （解码成ASCII就是TESTTESTTEST） 是12字节的transaction ID。    发送请求并等待32字节的响应：\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026quot;\\x00\\x01\\x00\\x00\\x21\\x12\\xA4\\x42TESTTESTTEST\u0026quot; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 21 12 a4 42 54 45 53 54 54 45 53 54 |....!..BTESTTEST| 00000010 54 45 53 54 00 20 00 08 00 01 6f 32 7f 36 de 89 |TEST. ....o2.6..| 00000020 解释：\n 01 01 是消息类型。 00 0c 是数据段的长度，解码后是十进制的12。 21 12 a4 42 是magic cookie。 54 45 53 54 54 45 53 54 54 45 53 54 （解码成ASCII就是TESTTESTTEST）是12字节的transaction ID。 00 20 00 08 00 01 6f 32 7f 36 de 89 是12字节的数据，解释：  00 20 是类型：XOR-MAPPED-ADDRESS。 00 08 是value段的长度，以十进制解码就是8。 00 01 6f 32 7f 36 de 89 是数据值，解释：  00 01 是地址类型（IPv4）。 6f 32 是经过XOR映射的端口。 7f 36 de 89 是经过XOR映射的IP地址。        解码XOR映射的部分很麻烦，但是我们可以通过提供设置为00 00 00 00的（无效）伪magic cookie来诱骗stun服务器执行伪XOR映射：\nstunserver=stun1.l.google.com;stunport=19302;listenport=20000;echo -ne \u0026quot;\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00TESTTESTTEST\u0026quot; | nc -u -p $listenport $stunserver $stunport -w 1 | hexdump -C 00000000 01 01 00 0c 00 00 00 00 54 45 53 54 54 45 53 54 |........TESTTEST| 00000010 54 45 53 54 00 01 00 08 00 01 4e 20 5e 24 7a cb |TEST......N ^$z.| 00000020 对伪magic cookie的XOR运算是幂等的，因此响应中的端口和地址将是清楚的。这并非在所有情况下都有效，因为某些路由器会操纵传递的数据包，伪装IP地址。如果我们查看返回的数据值（最后八个字节）：\n 00 01 4e 20 5e 24 7a cb 是数据值，解释：  00 01 是地址类型（IPv4）。 4e 20 是映射的端口，解码成十进制就是20000。 5e 24 7a cb 是IP地址，解码成点分十进制表示法就是94.36.122.203。    安全故障 #  媒体故障 #  数据故障 #  用到的工具 #  netcat (nc) #  netcat 是用于使用TCP或UDP读取和写入网络连接的命令行网络实用程序。通常它可以用nc命令来调用。\ntcpdump #  tcpdump是一个命令行数据网络数据包分析器。\n常用命令：\n  捕获与端口19302之间的UDP数据包，并打印数据包内容的十六进制转储：\nsudo tcpdump 'udp port 19302' -xx\n  与上一条相同，但将数据包保存在PCAP（数据包捕获）文件中以供以后检查\nsudo tcpdump 'udp port 19302' -w stun.pcap\n可以使用wireshark GUI打开PCAP文件：wireshark stun.pcap\n  wireshark #  webrtc-internals #  Chrome 内置了一个 WebRTC 指标数据页面 chrome://webrtc-internals 。\n延迟(Latency) #  我们该如何感知高延迟？你会注意到视频出现延迟了，但你知道它具体延迟了多少吗？ 想要降低延迟，你首先必须知道如何测量延迟。\n真正的延迟应该是端到端测量的。这不仅仅是指发送方和接收方之间网络路径的延迟，还包括相机拍摄、帧编码、传输、接收、解码和视频播放等一系列步骤延迟的综合，以及这些步骤之间可能存在的队列。\n端到端延迟不是各个组件延迟的简单叠加。\n虽然在理论上，你可以单独测量整个视频传输管线中各个模块的延迟，然后累加到一起；但是在实践中，至少有些组件没有方法去测量延迟，或者在外部测量延迟的结果存在明显的偏差。 各个步骤之间的队列大小，网络拓扑，乃至是相机的曝光度变化，都可能会对分步骤的测量结果产生影响，进而影响端到端延迟的测量结果。\n直播系统中每个组件内部的延迟都可能改变并影响下游组件。 甚至拍摄的内容也会影响延迟。 例如，与晴朗的蓝天这种低频图像相比，树枝等高频特征需要更多的比特数(译者注：编码的本质是压缩，压缩的本质是减少数据冗余，复杂的图像编码后需要更多的空间)。 开启自动曝光的相机拍摄一帧图像所花费的时间，可能比预期的33ms 多得多，即使拍摄速度设置为每秒30帧也是如此。 通过网络（特别是蜂窝网络）的传输，受需求变化的影响，也是动态变化的。 例如，更多的用户就意味着更多参与的通信者。 地理位置（特别是某些臭名昭著的低信号区）等其他因素也会增加丢包和延迟。 当你把数据包发送到网络接口（例如WiFi适配器或者LTE）并请求传送时，会发生些什么呢？ 如果数据包无法被立即传送，它将被加入网络接口的队列中，队列越大，网络接口引入的延迟就越大。\n端到端延迟——手动测量 #  当我们谈论 端到端延迟时，指的是从 事件发生 到 事件被看到(即视频帧播放在屏幕上) 的时间间隔。\nEndToEndLatency = T(observe) - T(happen) 一个想当然的方法是，记录事件发生的时间，再与事件被看到的时间相减即可得到。 但是，当精确度为毫秒级时，时间同步就成了难题。 想要在分布式系统中同步时钟基本是徒劳的，即使是时钟同步的一个小错误，也会让 延迟测量 不再可信。\n解决时间同步问题的一个简单方法，就是使用相同的时钟。 将发送方和接收方放在同一个参照系中。\n想象一下你有一个正常运行的毫秒级时钟（或者其他真实的可以表示时间的物体）。 你要测量一个系统的延迟，这个系统中，摄像头对准 时钟，采集的直播流显示到同一个地方的另一个屏幕上。 有一个直接的测量方式来 测量 时钟当前时间 (Thappen) 和这个时钟视频出现在屏幕上的时间 (Tobserve) 。步骤如下：\n 将你的摄像头对准这个时钟。 将视频帧发送给同一个地方的接收方，接收端在屏幕上进行播放。 （用你的手机）拍一张照片，将时钟和屏幕视频画面拍进同一个画面内。 将照片中的两个时间相减（时钟上的时间，和屏幕视频画面里时钟的时间）。  这是最真实的端到端延迟测量。 它考虑了所有组件（相机、编码器、网络、解码器）的延迟，并且不依赖任何时钟同步。\n. 在上面的照片中，测得的端到端延迟为 101 msec。事件发生的时间是 10:16:02.862 , 而 直播观看者看到的时间是 10:16:02.761。\n端到端延迟——自动测量 #  本文写作时（2021年5月），WebRTC标准中关于端到端延迟的话题正在被积极讨论中。 Firefox 实现了一套API，让用户可以在标准WebRTC API之上，创建对延迟的自动测量。 不过，在本段落中，我们将讨论进行端到端延迟自动测量的最通用的方法。\nRoundtrip，即往返时间，简而言之就是： 我向你发送我的时间 tR1, 当我接收到 tR1 回来时，时间是 tR2 ，可得往返时间是 tR2 - tR1 。\n在给定发送方和接收方之间的通信通道（比如，DataChannel）后，接收方可以通过以下步骤来对发送方的单一时钟建模：\n 在时间tR1，接收方发送一个消息，包含它本地单一时钟的时间戳tR1。 在发送方一端的时间tS1，发送方收到该消息，并发送响应消息，响应消息中包含三个时间：tR1和tS1，以及发送方的视频轨道时间tSV1。 在接收方一端的时间tR2，接收方收到消息，可以用消息的接收时间减去发送时间，计算出往返时间：RTT = tR2 - tR1。 有了往返时间RTT和发送方本地时间戳 tS1，就可以估算出发送方的单一时钟了。在tR2这个时间点，发送方的当前时间近似等于tS1加上往返时间RTT的一半。 根据发送方本地时钟的时间戳 tS1，以及视频轨道的时间戳tSV1，加上往返时间RTT，接收方就可以将自己这一端和发送方一端的视频轨道时间进行同步。  现在我们已经知道了从发送方发出最后一个视频帧时间tSV1之后所经过的时间，我们可以这样计算近似的时间延迟，即用 期待的视频时间（\u0026lsquo;expected_video_time\u0026rsquo;） 减去 当前播放的视频帧的时间（\u0026lsquo;actual_video_time\u0026rsquo;）：\nexpected_video_time = tSV1 + time_since(tSV1) latency = expected_video_time - actual_video_time 译者注：期待的视频时间指的是 没有时延的情况下应该播放到哪个时间，在Sender端，tSV1时间采集tSV1,之后，过了 time_since(tSV1)时间，Sender端当前应该采集的是 tSV1 + time_since(tSV1)，无延迟情况下，期待的视频时间也就是Sender当前应该采集的时间。\n这种方法的缺陷是没有包含相机内部的延迟。 大多数视频系统一般将相机的帧传送到主内存的时间作为这一帧的拍摄时间戳，但拍摄实际发生的时间会略早于此时间。\n延迟测量示例 #  一个简单实现是在接收方开启一个latency数据通道，并定期将接收方的单一时钟时间戳发送到发送方。发送方响应一个JSON消息（消息中包含上面提到的三个时间），然后接收方根据这个消息来计算延迟。\n{ \u0026#34;received_time\u0026#34;: 64714, // Timestamp sent by receiver, sender reflects the timestamp. \u0026#34;delay_since_received\u0026#34;: 46, // Time elapsed since last `received_time` received on sender. \u0026#34;local_clock\u0026#34;: 1597366470336, // The sender\u0026#39;s current monotonic clock time. \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [ 13100, // Video frame RTP timestamp (in milliseconds). 1597366470289 // Video frame monotonic clock timestamp. ] } } 在接收方开启这个latency数据通道：\ndataChannel = peerConnection.createDataChannel(\u0026#39;latency\u0026#39;); 定期发送接收方的时间tR1，示例中使用的周期是2秒：\nsetInterval(() =\u0026gt; { let tR1 = Math.trunc(performance.now()); dataChannel.send(\u0026#34;\u0026#34; + tR1); }, 2000); 发送方处理来自接收方的消息：\n// Assuming event.data is a string like \u0026#34;1234567\u0026#34;. tR1 = event.data now = Math.trunc(performance.now()); tSV1 = 42000; // Current frame RTP timestamp converted to millisecond timescale. tS1 = 1597366470289; // Current frame monotonic clock timestamp. msg = { \u0026#34;received_time\u0026#34;: tR1, \u0026#34;delay_since_received\u0026#34;: 0, \u0026#34;local_clock\u0026#34;: now, \u0026#34;track_times_msec\u0026#34;: { \u0026#34;myvideo_track1\u0026#34;: [tSV1, tS1] } } dataChannel.send(JSON.stringify(msg)); 接收方处理来自发送方的消息，并在控制台上打印估算的时延：\nlet tR2 = performance.now(); let fromSender = JSON.parse(event.data); let tR1 = fromSender[\u0026#39;received_time\u0026#39;]; let delay = fromSender[\u0026#39;delay_since_received\u0026#39;]; // How much time that has passed between the sender receiving and sending the response. let senderTimeFromResponse = fromSender[\u0026#39;local_clock\u0026#39;]; let rtt = tR2 - delay - tR1; let networkLatency = rtt / 2; let senderTime = (senderTimeFromResponse + delay + networkLatency); VIDEO.requestVideoFrameCallback((now, framemeta) =\u0026gt; { // Estimate current time of the sender.  let delaySinceVideoCallbackRequested = now - tR2; senderTime += delaySinceVideoCallbackRequested; let [tSV1, tS1] = Object.entries(fromSender[\u0026#39;track_times_msec\u0026#39;])[0][1] let timeSinceLastKnownFrame = senderTime - tS1; let expectedVideoTimeMsec = tSV1 + timeSinceLastKnownFrame; let actualVideoTimeMsec = Math.trunc(framemeta.rtpTimestamp / 90); // Convert RTP timebase (90000) to millisecond timebase.  let latency = expectedVideoTimeMsec - actualVideoTimeMsec; console.log(\u0026#39;latency\u0026#39;, latency, \u0026#39;msec\u0026#39;); }); 浏览器中的视频准确时间 #   \u0026lt;video\u0026gt;.requestVideoFrameCallback() 允许web开发者在视频帧可以被合成图像时收到通知。\n 直到最近（2020年5月），我们还基本没有一个可靠的方式在浏览器中获取视频当前播放帧的时间戳 。虽然存在一个基于video.currentTime 的变通方法，但得到的结果也不是特别精确。 Chrome 和 Mozilla 的浏览器开发者都支持引入新的W3C标准，HTMLVideoElement.requestVideoFrameCallback()，该标准添加了一个API回调来访问当前视频帧的时间。 尽管这个新API听起来微不足道，但它赋予了应用在Web上进行音视频同步的能力，并已经促进了多个Web上的高级的媒体应用的实现。 特别是对于WebRTC，回调中将包含rtpTimestamp字段，即与当前视频帧的关联的RTP时间戳。 这个接口理应出现在WebRTC应用中，可惜目前还没有。\n延迟的调试技巧 #  由于调试很可能会影响测量到的延迟值，所以大体原则是：将你设置简化到能复现问题的最小程度。 移除越多的组件，就越容易找到造成延迟问题的组件。\n相机延迟 #  根据相机设置，相机延迟可能会有所不同。 检查自动曝光、自动对焦和自动白平衡等设置。 网络摄像头的所有\u0026quot;自动\u0026quot;功能都需要一些额外的时间来分析捕获的图像，然后才能将其提供给WebRTC协议栈。\n在Linux上，你可以使用v4l2-ctl命令行工具来控制相机设置：\n# Disable autofocus: v4l2-ctl -d /dev/video0 -c focus_auto=0 # Set focus to infinity: v4l2-ctl -d /dev/video0 -c focus_absolute=0 你也可以使用图形界面工具guvcview来快速检测和调整相机设置。\n编码延迟 #  大多数现代编码器会在输出已编码的帧之前，先缓存一些帧。 它们的首要任务是在生成的图片质量和比特率之间取得平衡。 多次编码器就是编码器忽略输出时延的一个极端例子。 在第一次编码过程中，编码器需要获取到完整的视频数据，然后才会开始输出视频帧。\n不过，通过适当的调整，我们可以减少sub-frame的延迟（译者注：这里应该是指 subsequent-frame,避免对后续帧的依赖）。 请确保你的编码器不使用过多的参考帧或依赖于B帧。 每个编解码器的延迟调整设置都不同，但对于x264而言，我们建议使用tune=zerolatency和profile=baseline以获得最低的帧输出延迟。\n网络延迟 #  对于网络延迟，我们能做的不多，最好的方法就是升级到更好的网络连接。 网络延迟很像天气——你不能阻止下雨，但你可以查看天气预报然后打把雨伞。 WebRTC 以毫秒级精度测量网络状态。 重要的指标有：\n 往返时间 丢包与包重传  往返时间\nWebRTC协议栈有内建的网络往返时间（round trip time, RTT）测量机制 。 网络延迟的一个很不错的近似值是RTT/2。它假设发送和接收数据包需要同样长的时间，然而情况并非总是如此。 RTT界定了端到端的时延的下限。 不管如何优化相机到编码器的处理管道，视频帧都无法在RTT/2的时间以内到达接收方。\n内建的RTT机制，基于特殊的RTCP包，也就是发送方/接收方报告。 发送方发送自己的时间戳给接收方，接收方再将这个时间戳回传给发送方。 这样，发送方就知道这个数据包从发往接收方到返回一共花了多长时间。 RTT测量的更多内容，请参阅发送方和接收方报告章节。\n丢包与包重传\nRTP和RTCP协议都是基于UDP，对于数据的顺序、成功送达或者避免重复，UDP不提供任何保障。 而上面所有这些在现实世界的WebRTC应用中都会发生，也总是在发生。 一个简单的解码器实现会期望一个视频帧的所有数据包都被完整送达，以便解码器能重新生成图像。 出现丢包问题时，如果丢失的是P帧的数据包，则可能会解码出错误的图像。 如果丢失的是I帧的数据包，则所有依赖于此I帧的视频帧要么出现严重的解码错误，要么压根无法被解码。 这些都很可能会造成视频\u0026quot;卡住\u0026quot;一段时间。\n为了避免（当然只是尽量避免）视频卡住或者解码错误，WebRTC使用NACK（否定确认）。 当接收方没有收到一个期待的RTP包时，将返回NACK消息，让发送方再次发送这个丢失的包。 接收方 等待 数据包重传完成。 这样的重传会导致延迟增加。 NACK包的发送和接收的数量会被记录在WebRTC内建的统计数据中，对应的字段是outbound stream nackCount和inbound stream nackCount 。\n在webrtc internals页面中，你可以看到展示入站和出站的nackCount的漂亮的图表。 如果你看到nackCount正在增加，这意味着网络正处于大量丢包的状态，尽管如此，WebRTC协议栈仍在努力创建流畅的音视频体验。\n当丢包率太高，解码器已经无法解码图像或者后续关联帧（例如I帧完全丢失的情况）的时候，所有后续的P帧都将无法解码。 在这种情况下，接收方将通过发送图片丢失指示（PLI）消息来尝试缓解问题。 一旦发送方接收到一个PLI消息，它将生成一个新的I帧来帮助接收方的解码器生成图像。 I帧一般比P帧大，这也增加了需要传输的数据包数量。 和NACK消息一样，接收方需要等待新的I帧，这也引入了额外的延迟。\n你需要关注webrtc internals页面中的pliCount指标，如果它增加了，你需要调整编码器以减少数据包的输出；或者启用容错度更高的模式。\n接收方一侧的延迟 #  延迟会受到数据包乱序到达的影响。 比如一张图片下半部分的数据包先到达了，那么必须等待上半部分的数据包到达后，才能开始解码。 关于这个问题的更详细内容，请参考解决抖动问题章节。\n你也可以参考内建的jitterBufferDelay指标，看一下一帧需要在接收缓冲区中存放多久，才能等到所有的数据包接收完成，并被释放到解码器。\n"});index.add({'id':9,'href':'/zh/docs/10-history-of-webrtc/','title':"历史",'section':"Docs",'content':"历史 #  在学习WebRTC时，开发人员经常对其复杂性感到沮丧，他们认为一些WebRTC功能与他们当前的项目无关，并希望WebRTC能够更简单一些。但问题是不同的开发者有迥然不同的应用场景。实时通信有着一段丰富的历史，人们在这个领域创造过很多不同的东西。\nWebRTC是由一系列协议组成的，本章包含了对这些协议作者的采访。 这些采访可以让我们更深入的了解作者们在构建每个协议时所做的设计，并以关于WebRTC本身的采访结束。当你理解了软件的意图和设计，你可以用它构建出更有效率的系统。\nRTP #  RTP和RTCP是处理WebRTC的所有媒体传输的协议。它是在1996年1月的RFC 1889中定义的。 我们很幸运地邀请到其中一位作者Ron Frederick自己来谈论这个问题。Ron最近向GitHub上传了Network Video tool，这是一个展示了RTP的项目。\n用他自己的话讲 #  在1992年10月，我开始尝试使用Sun VideoPix帧采集卡，当时的想法是编写一个基于IP多播的网络视频会议工具。它是根据\u0026quot;vat\u0026quot;建模的，\u0026ldquo;vat\u0026quot;是LBL开发的一个音频会议工具，它为参加会议的用户使用了类似的轻量级会话协议，你可以简单地使用此工具将数据发送到特定的多播组，并监听来自该组中其他小组成员的任何流量。\n为了使程序真正成功，它需要先压缩视频数据，然后再将其发布到网络上。我的目标是在大约128 kbps或标准家庭ISDN线路的带宽上生成可接受的可视数据流。我还希望在一半带宽下生成仍能被观看到的东西。这意味着我需要将特定图像尺寸和帧率的视频压缩到大约20分之一的大小。我实现了这种压缩，并申请了专利，专利是 US5485212A：用于电话会议的软件视频压缩。\n1992年11月上旬，我向互联网社区发布了视频会议工具\u0026quot;nv\u0026rdquo;（二进制形式）。经过一些初步测试后，它被用于在全球范围内对11月Internet工程任务组的部分进行视频广播。在15个国家/地区中，大约有200个子网能够接收此广播，并且一周中的某个时候，大约有50-100人使用\u0026quot;nv\u0026quot;接收了视频。\n在接下来的几个月中，另外三个研讨会和一些较小的会议使用\u0026quot;nv\u0026quot;向整个Internet进行广播，包括澳大利亚NetWorkshop，MCNC分组音频和视频研讨会以及瑞典的分布式虚拟现实MultiG研讨会。\n随后，在1993年2月，我发布了\u0026quot;nv\u0026quot;的源代码，并在3月发布了该工具的一个版本，在其中引入了新的基于小波的压缩方案。在1993年5月，我增加了对彩色视频的支持。\n用于\u0026quot;nv\u0026quot;和其他Internet会议工具的网络协议成为了实时传输协议（RTP）的基础，该协议通过Internet工程任务组（IETF）进行了标准化，该工作组首先在RFCs 1889-1890中发布，后来又与其他各种RFC一起，在RFCs 3550-3551中进行了修订，它们涵盖了用于传递特定音频和视频格式的配置文件。\n在接下来的几年中，关于\u0026quot;nv\u0026quot;的工作继续进行，该工具被移植到了许多其他硬件平台和视频捕获设备上。它仍然被用作当时在Internet上广播会议的主要工具之一，包括被NASA选中以在线直播的方式进行航天飞机飞行任务的实时报道。\n1994年，我在\u0026quot;nv\u0026quot;中添加了对其他人开发的视频压缩算法的支持，其中包括一些硬件压缩方案，如SunVideo视频捕获卡支持的CellB格式。这也使得\u0026quot;nv\u0026quot;可以用CUSeeMe格式发送视频，并将视频发送给在Mac和PC上运行CUSeeMe的用户。\n最新的\u0026quot;nv\u0026quot;版本是1994年7月发布的3.3beta版本。当时我正在开发\u0026quot;4.0alpha\u0026quot;版本，该版本旨在将\u0026quot;nv\u0026quot;迁移到RTP协议v2，但因为我转到了其他项目上，这项工作从未被完成。为了保持完整性，Network Video tool归档文件中包含4.0 alpha代码的副本，但它是未完成的，并且存在已知问题，尤其是在RTPv2支持不完整的情况下。\n\u0026ldquo;nv\u0026quot;中提供的框架后来成为Xerox PARC的\u0026quot;Jupiter multi-media MOO\u0026quot;项目中视频会议的基础，该项目最终分拆为独立公司\u0026quot;PlaceWare\u0026rdquo;，后来该公司被Microsoft收购。它也被用作许多硬件视频会议项目的基础，这些项目允许通过高带宽以太网和ATM网络发送完整的NTSC广播质量的视频。后来我还使用了其中一些代码作为\u0026quot;Mediastore\u0026quot;的基础，\u0026ldquo;Mediastore\u0026quot;是基于网络的视频记录和回放服务。\n你还记得草案中其他人的动机/想法吗？ #  我们都是IP多播的研究人员，并且帮助创建了Internet多播主干网（又名MBONE）。MBONE由Steve Deering（IP多播的首位开发者），Van Jacobson和Steve Casner创建。 我和Steve Deering在斯坦福大学有同一位顾问，Steve离开斯坦福大学后就去了Xerox PARC工作，我作为IP多播相关项目的实习生在Xerox PARC呆了一个夏天，后来在斯坦福大学还继续为他们兼职工作，再后来转为全职。Van Jacobson和Steve Casner是最初的RTP RFC的四位作者中的两位，还有Henning Schulzrinne和我本人。我们所有人都使用MBONE工具进行各种形式的在线协作，并且试图提炼出所有这些工具可以使用的通用基本协议，RTP就是这样出现的。\n多播很棒，而WebRTC完全是单播的，可以说一下是为什么吗？ #  在前往斯坦福大学并学习IP多播之前，我花了很长时间致力于让计算机成为人们相互交流的方式。这是从80年代初期开始的，当时我运行了一个拨号公告板系统，人们可以登录并留下彼此的消息，既可以是私人的（相当于电子邮件），也可以是公共的（讨论小组）。大约在同一时间，我还了解了在线服务提供商CompuServe。 CompuServe的很酷的功能之一就是所谓的\u0026quot;CB Simulator\u0026rdquo;，人们可以在其中进行实时交谈。这些都是基于文本的，但是它具有\u0026quot;频道\u0026quot;的概念，就像真正的CB广播一样，只要他们在同一个频道中，大家就可以看到其他人键入的内容。我构建了自己的CB版本，该版本在我可以访问的分时共享系统上运行，该系统可以让该系统上的用户实时向彼此发送消息，然后在接下来的几年中，我与朋友一起开发了更复杂的各种版本的实时通信工具，可以在几个不同的计算机系统和网络上运行。事实上，其中一个系统仍在运行，我每天都会用它与30多年前上大学的人们进行交流！\n所有这些工具都是基于文本的，因为当时的计算机通常没有任何音频/视频功能，但是当我到达斯坦福大学并学习了IP多播时，我产生了一个想法。做一个真正的\u0026quot;收音机\u0026rdquo;，你可以将信号发送到网络上，该信号并不是特别发给任何人的，但是调谐到该\u0026quot;频道\u0026quot;的每个人都可以接收到它。碰巧的是，我正在为之移植IP多播代码的计算机是Sun的第一代SPARC-station，而它实际上内置了电话级别的音频硬件！你可以将麦克风中的声音数字化，然后通过内置扬声器（或通过耳机输出）播放。因此，我的第一个想法是弄清楚如何使用IP多播将音频实时发送到网络上，然后看一下是否可以构建一个使用实际音频而不是文本的\u0026quot;CB收音机\u0026rdquo;。\n这里有一些棘手的事情需要解决，例如计算机一次只能播放一个音频流，因此，如果有多个人在讲话，则需要在数学上将多个音频流\u0026quot;混合\u0026quot;为一个，然后才能播放。不过一旦你了解了音频采样的工作原理，这些工作就可以全部通过软件完成。该音频应用程序使我致力于MBONE的开发，并最终通过\u0026quot;nv\u0026quot;实现了到视频的转换。\n协议中遗漏了什么你原本希望添加的东西吗？有没有哪些让你后悔加入的内容？ #  我不觉得有什么后悔的，不过最终人们对RTP抱怨最多的其中一点就是RTCP实现的复杂性，RTCP是与RTP主数据流量并行运行的控制协议。我认为，RTP并未得到更广泛采用的主要原因就是太过复杂，尤其是在单播情况下，对RTCP的某些功能的需求不再那么大。由于网络带宽变得不再那么稀缺，而拥塞也不再是一个大问题，许多人最终只是通过纯TCP（以及后来的HTTP）流式传输音频和视频，一般来说，这就已经\u0026quot;足够好\u0026quot;了，以至于没有必要再去与RTP打交道。\n不幸的是，使用TCP或HTTP意味着多方音频和视频应用程序必须通过网络多次向需要接收数据的每个对等方发送相同的数据，从而从带宽的角度来看，效率被大大降低。有时，我希望我们之前能更加努力地推动IP多点广播的应用，使其不仅限于研究领域。我认为，如果我们这么做了的话，可能我们早就可以看到有线电视和广播电视过渡到基于Internet的音频和视频。\n有什么东西是你曾经想过使用RTP构建的呢？是不是有一些很酷的RTP项目/想法随时间流逝了呢？ #  我构建的其中一个有趣的项目是一个使用IP多播的经典游戏\u0026quot;Spacewar\u0026quot;版本。在没有任何类型的中央服务器的情况下，多个客户端可以各自运行spacewar的二进制文件，并开始广播其船舶的位置/速度/所面对的方向以及已发射的任何\u0026quot;子弹\u0026quot;的类似信息，所有其他客户端将收集这些信息并将其呈现在本地，从而使所有人都可以看到彼此的飞船和子弹，如果飞船撞向对方或被子弹击中，飞船就会\u0026quot;爆炸\u0026rdquo;。我甚至将爆炸中的\u0026quot;碎片\u0026quot;也做成了可以击毁其他船只的活动物体，有时会引起有趣的连锁反应！\n本着原始游戏的精神，我使用模拟矢量图形对其进行了渲染，因此你可以执行诸如放大和缩小视图之类的操作，并且一切都会按比例放大/缩小。飞船本身是一堆矢量形式的线段，我在PARC的一些同事帮助我进行了设计，因此每个人的飞船都有独特的外观。\n基本上，如果一个东西需要实时数据流，又无需数据按照精确的时序传输，那么它就可以从RTP中受益。因此，除了音频和视频，我们还可以构建共享白板之类的东西。甚至使用RTP进行文件传输，尤其是与IP多播结合使用时。\n这就像BitTorrent，但是你不需要在对等方之间点对点地传输所有数据。原始的做种者可以立即将多播流发送到所有接收者，并且通过成功接收数据的任何对等方的重发，就可以快速解决传输中数据包丢失的问题。接收者甚至可以确定重传请求的范围，以便附近的一些对等方能够传递数据的副本，重传请求也可以被多播到该区域中的其他节点，因为网络中间的数据包丢失往往意味着下游有很多客户端错过了相同的数据。\n为什么你必须实现自己的视频压缩协议？当时没有其他可用的东西了吗？ #  在我开始构建\u0026quot;nv\u0026quot;时，我所知道的唯一进行视频会议的系统是非常昂贵的专用硬件。例如，Steve Casner可以从BBN访问一个名为\u0026quot;DVC\u0026rdquo;（后来商品化为\u0026quot;PictureWindow\u0026rdquo;）的系统。压缩需要专用硬件，但是解压缩可以通过软件完成。\u0026ldquo;nv\u0026quot;之所以与众不同，是因为压缩和解压缩都是在软件中完成的，唯一的硬件要求是对输入的模拟视频信号进行数字化处理。\n当时，有关如何压缩视频的许多基本概念已经存在了，诸如MPEG-1标准之类的东西大约在\u0026quot;nv\u0026quot;出现的同时出现，但在当时绝对不可能使用MPEG-1进行实时编码。我所做的更改都是关于吸收这些基本概念并使用更便宜的算法对其进行近似模拟，其中我避免了余弦变换和浮点之类的事情，甚至避免了整数乘法，因为在SPARC-stations上这些运算速度非常慢。我尽量只进行加/减法、位屏蔽和移位，这样可以使速度足够快，并使结果看起来仍像是视频。\n在\u0026quot;nv\u0026quot;发布的一两年之内，不仅是在MBONE网络上，还有其他地方（如Mac上的CU-SeeMe工具），都出现了许多不同的音视频工具可供选择。很明显的，实时视频的时机成熟了。事实上，我最终使\u0026quot;nv\u0026quot;与许多这些工具互操作，还有某些工具甚至采用了\u0026quot;nv\u0026quot;编解码器，以便在使用压缩方案时它们可以互操作。\nWebRTC #  WebRTC需要的标准化工作使得本章中描述的所有其他工作都相形见绌。它需要两个不同的标准机构（IETF 和 W3C），以及来自许多公司和国家的数以百计的人员合作。Serge Lachapelle会跟我们谈谈实现WebRTC的初始动机，以及在开发过程中所付出的巨大的努力。\nSerge是Google的产品经理，目前担任Google Workspace的产品经理。下面是我总结后的采访内容。\n什么促使你参与 WebRTC ？ #  从大学开始，我就一直热衷于构建通信软件。在90年代，像nv这样的技术开始出现，但很难使用。我创建了一个项目，它允许你可以直接从浏览器加入视频通话。我也将它移植到了Windows。\n我把这段经历带到了我共同创立的公司Marratech。我们构建了用于群组视频会议的软件。从技术上来讲，当时的愿景与现在大不相同。当时的视频通信的前沿方向是使用多播网络。用户可以依靠网络将视频数据包传送给通话中的每一个人。这意味着我们的服务器可以非常简单。但这种做法存在一个巨大的缺点，必须设计网络以适配多播模式。后来，这个行业从多播转向了数据重组（packet shufflers），也就是现在大家都知道的SFU。\nMarratech于2007年被Google收购。然后我得以继续这个后来成为WebRTC的项目。\n在Google的第一个项目 #  WebRTC前身团队（后来才有WebRTC项目）参与的第一个项目是Gmail语音和视频聊天。将音频和视频导入浏览器并不容易。我们需要从各个公司获得特定功能模块的许可。音频模块由GIP授权，视频模块由Vidyo授权，网络模块由libjingle授权。然后，我们要像变魔术一般让这些组件一起工作。\n每个子系统都有完全不同的API，而且它们都是为了解决不同的问题而设计的。为了让它们协同工作，你需要同时具备多个领域的专业知识，例如：网络、密码学、媒体等等。 Justin Uberti是这项工作的负责人。他将这些组件组合在一起，开发了一个可用的产品。\n在浏览器中做实时渲染也非常困难。我们不得不使用NPAPI（Netscape Plugin API），并做了很多创新性的工作，才使其最终得以实现。 从这个项目中，我们学到了很多经验教训，这极大地影响了WebRTC。\nChrome #  与此同时，Chrome项目在Google内部启动。Chrome在项目之初就拥有远大的格局，带来了很多令人兴奋的东西，简单举几个例子，比如WebGL、离线应用、数据库功能、游戏低延迟输入等等。\n是否摒弃NPAPI是当时的一个争论焦点。它是一个强大的API，但也引入了诸多的安全性问题。Chrome使用沙盒设计来确保用户安全。潜在的不安全操作被隔离在不同进程中运行。即使出现一些问题，攻击者也无法访问用户数据。\nWebRTC 诞生 #  我的个人理解是，多方面的因素和诉求，最终促成了WebRTC的诞生。\n构建实时通信软件不应该如此艰难。开发者们耗费了大量的精力来重新实现相同的东西。我们应该一次性解决这些令人沮丧的集成问题，然后就可以专注于其他事情。\n人际沟通应该是畅通无阻的，应该是开放的。为什么文本和HTML可以在浏览器里打开，而我的实时音视频却不能呢？\n安全是重中之重。使用NPAPI对用户来说并不是最好的。因此这也是一个机会，让我们可以创建一个默认就很安全的协议。\n为了实现WebRTC，Google收购并开源了很多我们用到过的组件，包括On2的视频技术和 Global IP Solution的RTC技术。我负责了其中GIPS的收购工作。我们必须将这些结合起来，让他们在浏览器内外都能够简单易用。\n标准化 #  WebRTC的标准化是我们非常想要去做的一件事情，但我之前没有做过，当时的团队中也没有人有任何经验。这一点上，我们很幸运得到了Google的Harald Alvestrand的加盟。他此前已经在IETF做过很多工作，并且启动了WebRTC的标准化进程。\n2010年的夏天，在Maastricht举办了一次非正式的午餐会。许多公司的开发人员们齐聚一堂，讨论WebRTC应该是什么样子的。餐桌上有来自 Google、Cisco、Ericsson、Skype、Mozilla、Linden Labs等公司的工程师。你可以在rtc-web.alvestrand.com找到完整的出席人员和演示的幻灯片。\nSkype当时已经在IETF完成了Opus的标准化工作，他们也提供了一些很好的指导意见。\n站在巨人的肩膀上 #  在IETF的工作实际是对过去人们工作的进一步扩展。 对WebRTC而言，我们非常幸运，因为已经有很多现有的技术可以使用。我们不需要负责所有的问题，因为很多问题（在现有的技术下）已经解决了。但如果你不喜欢现有的技术，这就可能成为一个麻烦的问题。我们一般不会选择重新造轮子，除非有特别必要的理由。\n我们也有意识地避免对某些东西重新标准化，比如信令（signaling）。信令的标准化已经通过SIP和其他非IETF组织的努力得到了解决，如果重新对它标准化，最终可能会演变成为政治问题。还有最本质的原因是，我们觉得（对其重新标准化）并不会创造什么有价值的贡献。\n我没有像Justin和Harald那样全程参与了标准化工作，不过我很享受参与其中的这段时光。当然，回来重新为用户创造产品是让我更兴奋的事。\n未来 #  WebRTC如今正处于一个很好的位置。创新迭代在这个领域不断发生，而且这些创新并没有局限于我们曾经做过的一切。\n我最兴奋的是云计算将会如何影响通信技术。使用高级算法，我们可以从通话中去除背景噪音，这让我们在一些以前无法沟通的场景下通信成为可能。我们还看到WebRTC也不再局限于通信……谁能想到它已经被应用于云游戏9年之久了呢？如果没有WebRTC作为基础，这一切都是不可能实现的。\n"});index.add({'id':10,'href':'/zh/docs/11-faq/','title':"常见问题",'section':"Docs",'content':"常见问题 #  为什么WebRTC使用UDP？ NAT穿透需要UDP。没有NAT穿透，就无法建立P2P连接。UDP不像TCP那样\u0026quot;保证送达\u0026rdquo;，因此WebRTC在用户级别提供这一特性。\n要了解更多信息，请参考 连接 章节。\n  数据通道最多可以有几个？ 因为流标识符有16位，所以最多有65534个通道。你可以随时关闭再创建一个新的。   WebRTC是否有带宽限制？ 数据通道和RTP都使用拥塞控制。这意味着WebRTC会主动测量你的带宽并尝试使用最佳数值。这是一种平衡措施，这样可以尽量发送数据，而不会使网络连接过载。   我可以发送二进制数据吗？ 是的，你可以通过数据通道发送文本和二进制数据。   WebRTC延迟怎么样？ 对于未作调整的媒体，估计不到500毫秒。如果你愿意为延迟调整或牺牲音质/画质，有开发人员将延迟降到了100ms以下。\n数据通道支持\u0026quot;部分可靠性\u0026quot;选项，该选项可以减少由于有损连接上的数据重传而引起的延迟。如果配置正确的话，速度可以超过TCP TLS连接。\n  什么情况下我会需要无序交付的数据通道？ 有时，新的信息会淘汰旧的信息（例如对象的位置信息）；或者，每个消息都是彼此独立的，并且你需要避免行头阻塞延迟。   我可以通过数据通道发送音频或视频吗？ 是的，你可以通过数据通道发送任何数据。如果是在浏览器中这样使用，你就需要自行对数据进行解码，然后将其传递给媒体播放器进行渲染；在使用媒体通道时，这部分是自动完成的。   "});index.add({'id':11,'href':'/zh/docs/12-glossary/','title':"Glossary",'section':"Docs",'content':"术语 #   ACK: Acknowledgment (确认报文) AVP: Audio and Video profile (音频视频描述) B-Frame: Bi-directional Predicted Frame. A partial picture, is a modification of previous and future pictures. (双向预测帧，存储图片的部分信息，存储的是相对前一张图片和后一张图片的差异信息) DCEP: Data Channel Establishment Protocol defined in RFC 8832 (DataChannel建立协议) DeMux: Demultiplexer (解复用器) DLSR: delay since last sender report (从最近一个Sender Report开始的时间延迟) DTLS: Datagram Transport Layer Security defined in RFC 6347 E2E: end-to-end FEC: Forward Error Correction (前向纠错) FIR: Full INTRA-frame Request (完整I帧请求) G.711: A narrowband audio codec (一个窄带音频编码器) H.264: Advanced video coding for generic audiovisual services (面向通用视听服务的高级视频编码) H.265: Conformance specification for ITU-T H.265 high efficiency video coding. (ITU-T H.265高效视频编码的一致性规范) HEVC: High Efficiency Video Coding (高效视频编码) HTTP: Hypertext Transfer Protocol (超文本传输协议) HTTPS: HTTP Over TLS defined in RFC 2818 (基于TLS的HTTP) I-Frame: Intra-coded Frame. A complete picture, can be decoded without anything else. (内部编码帧，保存完整图片信息，自解码，不依赖外部数据) ICE: Interactive Connectivity Establishment defined in RFC 8445 (交互式连接建立协议) INIT: Initiate (初始化) IoT: Internet of Things (物联网) IPv4: Internet Protocol, Version 4 (第四代因特网协议) IPv6: Internet Protocol, Version 6 (第六代因特网协议) ITU-T: International Telecommunication Union Telecommunication Standardization Sector (国际电信联盟电信标准分局) JSEP: JavaScript Session Establishment Protocol defined in RFC 8829 (JavaScript会话建立协议) MCU: Multi-point Conferencing Unit (多点会话单元) mDNS: Multicast DNS defined in RFC 6762 (组播 DNS) MITM: Man-In-The-Middle MTU: Maximum Transmission Unit (最大传输单元) MUX: Multiplexing (复用，一般指把不同格式的数据合并存储或传输) NACK: Negative Acknowledgment (逆确认报文，ACK反馈收到报文,NACK反馈未收到报文 ) NAT: Network Address Translation defined in RFC 4787 (网络地址转换，域名地址转换成IP地址) Opus: A totally open, royalty-free, highly versatile audio codec (一个完全开放、免版税、高度通用的音频编解码器) P-Frame: Predicted Frame. A partial picture, containing only changes from the previous picture. (前向预测帧，只保存相对于上一帧的差异信息) P2P: peer-to-peer PLI: Picture Loss Indication (图片丢失指示) PPID: Payload Protocol Identifier (Payload协议标识) REMB: Receiver Estimated Maximum Bitrate (接收端估计的最大比特率) RFC: Request for Comments (征求意见) RMCAT: RTP Media Congestion Avoidance Techniques (RTP媒体拥塞避免技术) RR: Receiver Report (RCTP接收者报告) RTCP: RTP Control Protocol defined in RFC 3550 (RTP控制协议) RTP: Real-time transport protocol defined in RFC 3550 (实施传输协议) RTT: Round-trip time (往返时间) SACK: Selective Acknowledgment (选择性确认) SCTP: Stream Control Transmission Protocol defined in RFC 4960 (流控传输协议) SDP: Session Description Protocol defined in RFC 8866 (会话描述协议) SFU: Selective Forwarding Unit (选择性转发单元) SR: Sender Report (RCTP发送者报告) SRTP: Secure Real-time Transport Protocol defined in RFC 3711 (安全的RTP) SSRC: Synchronization Source (同步源) STUN: Session Traversal Utilities for NAT defined in RFC 5389 (NAT会话穿透) TCP: Transmission Control Protocol (传输控制协议) TLS: The Transport Layer Security defined in RFC 8446 (传输层安全) TMMBN: Temporary Maximum Media Stream Bit Rate Notification (临时最大媒体流比特率通知) TMMBR: Temporary Maximum Media Stream Bit Rate Request (临时最大媒体流比特率请求) TSN: Transmission Sequence Number (传输序列号) TURN: Traversal Using Relays around NAT defined in RFC 5766 (基于转发的NAT穿透) TWCC: Transport Wide Congestion Control (传输拥塞控制) UDP: User Datagram Protocol (数据报协议) VP8, VP9: Highly-efficient video compression technologies (video \u0026ldquo;codecs\u0026rdquo;) developed by the WebM Project. Anyone may use these codecs royalty-free. (WebM项目开发的高效视频压缩技术(视频编解码)，完全免费) WebM: An open media file format designed for the web. (一个开放的Web媒体文件格式) WebRTC: Web Real-Time Communications. W3C WebRTC 1.0: Real-Time Communication Between Browsers (Web实时通信)  "});})();