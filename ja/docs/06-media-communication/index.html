<!doctype html><html lang=ja dir=ltr><head><meta name=generator content="Hugo 0.74.3"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="WebRTCのメディア通信では何ができるのですか？ #  WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。
WebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。
また、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。
どのような仕組みになっているのですか？ #  WebRTCは、RFC 3550で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。
RTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。
RTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。
レイテンシー vs クオリティ #  リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。
現実の制約 #  これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。
ビデオは複雑 #  動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。
ビデオ101 #  ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。
非可逆圧縮と可逆圧縮 #  動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。
イントラフレームとインターフレームの圧縮 #  動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。
2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。
フレーム間の種類 #  フレームには3つの種類があります。
 I-Frame - 完全な画像で、何もなくてもデコードできます。 P-Frame - 部分的な画像で、前の画像を修正したもの。 B-Frame - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。  3つのフレームタイプを視覚化すると以下のようになります。
動画はデリケート #  動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。
RTP #  パケットフォーマット #  すべてのRTPパケットは、以下のような構造になっています。"><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="メディア・コミュニケーション"><meta property="og:description" content="WebRTCのメディア通信では何ができるのですか？ #  WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。
WebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。
また、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。
どのような仕組みになっているのですか？ #  WebRTCは、RFC 3550で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。
RTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。
RTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。
レイテンシー vs クオリティ #  リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。
現実の制約 #  これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。
ビデオは複雑 #  動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。
ビデオ101 #  ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。
非可逆圧縮と可逆圧縮 #  動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。
イントラフレームとインターフレームの圧縮 #  動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。
2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。
フレーム間の種類 #  フレームには3つの種類があります。
 I-Frame - 完全な画像で、何もなくてもデコードできます。 P-Frame - 部分的な画像で、前の画像を修正したもの。 B-Frame - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。  3つのフレームタイプを視覚化すると以下のようになります。
動画はデリケート #  動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。
RTP #  パケットフォーマット #  すべてのRTPパケットは、以下のような構造になっています。"><meta property="og:type" content="article"><meta property="og:url" content="https://webrtcforthecurious.com/ja/docs/06-media-communication/"><meta property="article:modified_time" content="2021-05-21T10:24:46-07:00"><meta property="og:site_name" content="好奇心旺盛な人のためのWebRTC"><title>メディア・コミュニケーション | 好奇心旺盛な人のためのWebRTC</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=alternate hreflang=en href=https://webrtcforthecurious.com/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=sv href=https://webrtcforthecurious.com/sv/docs/06-media-communication/ title=Mediakommunikation><link rel=alternate hreflang=zh href=https://webrtcforthecurious.com/zh/docs/06-media-communication/ title=媒体通信><link rel=stylesheet href=/book.min.6c7c6446dfdee7c8c933e9bbc6e80ee3ed6c913b2a59519f2092c3c6a9d63e55.css integrity="sha256-bHxkRt/e58jJM+m7xugO4+1skTsqWVGfIJLDxqnWPlU="><script defer src=/ja.search.min.6d516bd53c78b674b55296bfcd007640584d113480068f7c4ac2d33a161d03a1.js integrity="sha256-bVFr1Tx4tnS1Upa/zQB2QFhNETSABo98SsLTOhYdA6E="></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a href=/ja><span>好奇心旺盛な人のためのWebRTC</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=検索 aria-label=検索 maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=https://webrtcforthecurious.com/ja/docs/01-what-why-and-how/>何を、なぜ、どのように</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/02-signaling/>シグナリング</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/03-connecting/>接続</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/04-securing/>セキュリティ対策</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/05-real-time-networking/>リアルタイム・ネットワーキング</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/06-media-communication/ class=active>メディア・コミュニケーション</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/07-data-communication/>データ・コミュニケーション</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/08-applied-webrtc/>応用WebRTC</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/09-debugging/>デバッグ</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/10-history-of-webrtc/>歴史</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/11-faq/>FAQ</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>メディア・コミュニケーション</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#どのような仕組みになっているのですか>どのような仕組みになっているのですか？</a></li><li><a href=#レイテンシー-vs-クオリティ>レイテンシー vs クオリティ</a><ul><li><a href=#現実の制約>現実の制約</a></li><li><a href=#ビデオは複雑>ビデオは複雑</a></li></ul></li><li><a href=#ビデオ101>ビデオ101</a><ul><li><a href=#非可逆圧縮と可逆圧縮>非可逆圧縮と可逆圧縮</a></li><li><a href=#イントラフレームとインターフレームの圧縮>イントラフレームとインターフレームの圧縮</a></li><li><a href=#フレーム間の種類>フレーム間の種類</a></li><li><a href=#動画はデリケート>動画はデリケート</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#パケットフォーマット>パケットフォーマット</a></li><li><a href=#拡張機能>拡張機能</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#full-intra-frame-request-firとpicture-loss-indication-pli>Full INTRA-frame Request (FIR)とPicture Loss Indication (PLI)</a></li><li><a href=#negative-acknowledgements>Negative ACKnowledgements</a></li><li><a href=#送信者受信者レポート>送信者/受信者レポート</a></li></ul></li><li><a href=#rtprtcpが共に問題を解決する方法>RTP/RTCPが共に問題を解決する方法</a><ul><li><a href=#negative-acknowledgment>Negative Acknowledgment</a></li><li><a href=#前方誤り訂正-forward-error-correction>前方誤り訂正 (Forward Error Correction)</a></li><li><a href=#適応型ビットレートと帯域幅の推定-adaptive-bitrate-and-bandwidth-estimation>適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation)</a></li></ul></li><li><a href=#ネットワークの状態を伝える>ネットワークの状態を伝える</a><ul><li><a href=#受信者レポート-receiver-reports>受信者レポート (Receiver Reports)</a></li><li><a href=#tmmbr-tmmbn-remb>TMMBR, TMMBN, REMB</a></li><li><a href=#トランスポートワイド輻輳制御-transport-wide-congestion-control>トランスポートワイド輻輳制御 (Transport Wide Congestion Control)</a></li></ul></li><li><a href=#帯域幅の推定値の生成>帯域幅の推定値の生成</a></li></ul></nav></aside></header><article class=markdown><h1 id=webrtcのメディア通信では何ができるのですか>WebRTCのメディア通信では何ができるのですか？
<a class=anchor href=#webrtc%e3%81%ae%e3%83%a1%e3%83%87%e3%82%a3%e3%82%a2%e9%80%9a%e4%bf%a1%e3%81%a7%e3%81%af%e4%bd%95%e3%81%8c%e3%81%a7%e3%81%8d%e3%82%8b%e3%81%ae%e3%81%a7%e3%81%99%e3%81%8b>#</a></h1><p>WebRTCでは、オーディオやビデオのストリームを無制限に送受信できます。これらのストリームは、通話中にいつでも追加・削除できます。これらのストリームはすべて独立していることもあれば、まとめて送信することもできます。例えば、自分のデスクトップのビデオフィードを送信し、ウェブカムからのオーディオ／ビデオを含めることができます。</p><p>WebRTCプロトコルは、コーデックに依存しません。基礎となるトランスポートは、まだ存在しないものも含めて、すべてをサポートしています。ただし、通信相手であるWebRTCエージェントが、それを受け入れるために必要なツールを持っていない場合もあります。</p><p>また、WebRTCは、動的なネットワーク状況に対応できるように設計されています。通話中に帯域が増えたり減ったりすることがあります。また、突然パケットロスが多発することもあります。WebRTCはこのような状況にも対応できるように設計されています。WebRTCはネットワークの状態に対応し、利用可能なリソースで最高の体験を提供しようとします。</p><h2 id=どのような仕組みになっているのですか>どのような仕組みになっているのですか？
<a class=anchor href=#%e3%81%a9%e3%81%ae%e3%82%88%e3%81%86%e3%81%aa%e4%bb%95%e7%b5%84%e3%81%bf%e3%81%ab%e3%81%aa%e3%81%a3%e3%81%a6%e3%81%84%e3%82%8b%e3%81%ae%e3%81%a7%e3%81%99%e3%81%8b>#</a></h2><p>WebRTCは、<a href=https://tools.ietf.org/html/rfc3550#section-6.4>RFC 3550</a>で定義されている2つの既存のプロトコルRTPとRTCPを使用しています。</p><p>RTP（Real-time Transport Protocol）は、メディアを伝送するプロトコルです。動画をリアルタイムに配信することを目的に設計されています。遅延や信頼性に関するルールは規定されていませんが、それらを実装するためのツールが提供されています。RTPはストリームを提供し、1つの接続で複数のメディアフィードを実行できます。また、メディアパイプラインに供給するために必要な、タイミングや順序の情報も提供します。</p><p>RTCP（RTP Control Protocol）は、コールに関するメタデータを通信するためのプロトコルです。このフォーマットは非常に柔軟で、必要なメタデータを追加できます。通話に関する統計情報を通信するために使用されます。また、パケットロスの処理や輻輳制御の実装にも使用されます。これにより、変化するネットワークの状況に対応するために必要な双方向の通信が可能になります。</p><h2 id=レイテンシー-vs-クオリティ>レイテンシー vs クオリティ
<a class=anchor href=#%e3%83%ac%e3%82%a4%e3%83%86%e3%83%b3%e3%82%b7%e3%83%bc-vs-%e3%82%af%e3%82%aa%e3%83%aa%e3%83%86%e3%82%a3>#</a></h2><p>リアルタイムメディアは、遅延と品質のトレードオフの関係にあります。遅延を許容すればするほど、高品質な映像が期待できます。</p><h3 id=現実の制約>現実の制約
<a class=anchor href=#%e7%8f%be%e5%ae%9f%e3%81%ae%e5%88%b6%e7%b4%84>#</a></h3><p>これらの制約は、すべて現実世界の制約に起因するもので、お客様が克服しなければならないネットワークの特性です。</p><h3 id=ビデオは複雑>ビデオは複雑
<a class=anchor href=#%e3%83%93%e3%83%87%e3%82%aa%e3%81%af%e8%a4%87%e9%9b%91>#</a></h3><p>動画の転送は簡単ではありません。30分の非圧縮720 8bitビデオを保存するには、約110Gb必要です。この数字では、4人での電話会議は不可能です。もっと小さくする方法が必要ですが、その答えは映像の圧縮です。しかし、これにはデメリットもあります。</p><h2 id=ビデオ101>ビデオ101
<a class=anchor href=#%e3%83%93%e3%83%87%e3%82%aa101>#</a></h2><p>ここでは、動画圧縮について詳しく説明しませんが、RTPがなぜこのように設計されているのかを理解するには十分です。動画圧縮とは、動画を新しいフォーマットにエンコードすることで、同じ動画をより少ないビット数で表現することです。</p><h3 id=非可逆圧縮と可逆圧縮>非可逆圧縮と可逆圧縮
<a class=anchor href=#%e9%9d%9e%e5%8f%af%e9%80%86%e5%9c%a7%e7%b8%ae%e3%81%a8%e5%8f%af%e9%80%86%e5%9c%a7%e7%b8%ae>#</a></h3><p>動画のエンコードは、ロスレス（情報が失われない）とロッシー（情報が失われる可能性がある）の2種類があります。ロスレス圧縮の場合、相手に送るデータ量が多くなり、ストリームの遅延が大きくなったり、パケットの損失が多くなるため、RTPでは映像の品質が悪くなってもロッシー圧縮を行うのが一般的です。</p><h3 id=イントラフレームとインターフレームの圧縮>イントラフレームとインターフレームの圧縮
<a class=anchor href=#%e3%82%a4%e3%83%b3%e3%83%88%e3%83%a9%e3%83%95%e3%83%ac%e3%83%bc%e3%83%a0%e3%81%a8%e3%82%a4%e3%83%b3%e3%82%bf%e3%83%bc%e3%83%95%e3%83%ac%e3%83%bc%e3%83%a0%e3%81%ae%e5%9c%a7%e7%b8%ae>#</a></h3><p>動画の圧縮には2種類あります。1つ目はイントラフレームです。フレーム内圧縮では、1つのビデオフレームを記述するためのビットを削減します。静止画の圧縮にも同じ手法が使われており、JPEG圧縮法などがあります。</p><p>2つ目は、フレーム間圧縮です。動画は多くの画像で構成されているので、同じ情報を2度送らない方法を考えます。</p><h3 id=フレーム間の種類>フレーム間の種類
<a class=anchor href=#%e3%83%95%e3%83%ac%e3%83%bc%e3%83%a0%e9%96%93%e3%81%ae%e7%a8%ae%e9%a1%9e>#</a></h3><p>フレームには3つの種類があります。</p><ul><li><strong>I-Frame</strong> - 完全な画像で、何もなくてもデコードできます。</li><li><strong>P-Frame</strong> - 部分的な画像で、前の画像を修正したもの。</li><li><strong>B-Frame</strong> - 部分的な画像で、以前の画像と未来の画像を組み合わせたもの。</li></ul><p>3つのフレームタイプを視覚化すると以下のようになります。</p><p><img src=../../images/06-frame-types.png alt="Frame types" title="Frame types"></p><h3 id=動画はデリケート>動画はデリケート
<a class=anchor href=#%e5%8b%95%e7%94%bb%e3%81%af%e3%83%87%e3%83%aa%e3%82%b1%e3%83%bc%e3%83%88>#</a></h3><p>動画の圧縮は非常にステートフルであり、インターネットでの転送は困難です。I-Frameの一部が失われるとどうなるのか？P-Frameはどうやって修正すべき箇所を知るのでしょうか？映像圧縮がより複雑になるにつれ、この問題はさらに深刻になっています。幸いなことに、RTPとRTCPには解決策があります。</p><h2 id=rtp>RTP
<a class=anchor href=#rtp>#</a></h2><h3 id=パケットフォーマット>パケットフォーマット
<a class=anchor href=#%e3%83%91%e3%82%b1%e3%83%83%e3%83%88%e3%83%95%e3%82%a9%e3%83%bc%e3%83%9e%e3%83%83%e3%83%88>#</a></h3><p>すべてのRTPパケットは、以下のような構造になっています。</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|X|  CC   |M|     PT      |       Sequence Number         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                           Timestamp                           |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Synchronization Source (SSRC) identifier            |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|            Contributing Source (CSRC) identifiers             |
|                             ....                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=バージョン-v>バージョン (V)
<a class=anchor href=#%e3%83%90%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3-v>#</a></h4><p><code>バージョン</code> は常に <code>2</code> です。</p><h4 id=パディング-p>パディング (P)
<a class=anchor href=#%e3%83%91%e3%83%87%e3%82%a3%e3%83%b3%e3%82%b0-p>#</a></h4><p><code>パディング</code> はペイロードにパディングがあるかどうかを制御する bool です。</p><p>ペイロードの最後のバイトには、何バイトのパディングが追加されたかのカウントが入っています。</p><h4 id=拡張-x>拡張 (X)
<a class=anchor href=#%e6%8b%a1%e5%bc%b5-x>#</a></h4><p>セットされている場合、RTPヘッダーは拡張機能を持つことになります。これについては、以下で詳しく説明します。</p><h4 id=csrc-数-cc>CSRC 数 (CC)
<a class=anchor href=#csrc-%e6%95%b0-cc>#</a></h4><p><code>SSRC</code>の後、ペイロードの前に続く<code>CSRC</code>の識別子の数です。</p><h4 id=マーカー-m>マーカー (M)
<a class=anchor href=#%e3%83%9e%e3%83%bc%e3%82%ab%e3%83%bc-m>#</a></h4><p>マーカービットには事前に設定された意味はなく、ユーザーが好きなように使うことができます。</p><p>場合によっては、ユーザーが話しているときに設定されることもあります。また、キーフレームのマークとしてもよく使われます。</p><h4 id=ペイロードタイプ-pt>ペイロードタイプ (PT)
<a class=anchor href=#%e3%83%9a%e3%82%a4%e3%83%ad%e3%83%bc%e3%83%89%e3%82%bf%e3%82%a4%e3%83%97-pt>#</a></h4><p><code>ペイロードタイプ</code> は、このパケットで伝送されるコーデックを示す一意の識別子です。</p><p>WebRTCでは、<code>ペイロードタイプ</code>は動的なものです。ある通話での VP8 は、別の通話では異なる可能性があります。通話中の提供者は、<code>Session Description</code> の中で<code>ペイロードタイプ</code>とコーデックのマッピングを決定します。</p><h4 id=シーケンス番号>シーケンス番号
<a class=anchor href=#%e3%82%b7%e3%83%bc%e3%82%b1%e3%83%b3%e3%82%b9%e7%95%aa%e5%8f%b7>#</a></h4><p><code>シーケンス番号</code>は、ストリームのパケットの順序付けに使用されます。パケットが送信されるたびに、<code>シーケンス番号</code>は1ずつ増加します。</p><p>RTPは、損失の多いネットワーク上で役立つように設計されています。これにより、受信者はパケットが失われたことを検出できます。</p><h4 id=タイムスタンプ>タイムスタンプ
<a class=anchor href=#%e3%82%bf%e3%82%a4%e3%83%a0%e3%82%b9%e3%82%bf%e3%83%b3%e3%83%97>#</a></h4><p>このパケットのサンプリングの瞬間です。これはグローバルクロックではなく、メディアストリームの中でどれだけの時間が経過したかを示すものです。</p><h4 id=同期ソース-ssrc>同期ソース (SSRC)
<a class=anchor href=#%e5%90%8c%e6%9c%9f%e3%82%bd%e3%83%bc%e3%82%b9-ssrc>#</a></h4><p><code>SSRC</code>は、このストリームの一意の識別子です。これにより、複数のメディアストリームを1つのストリーム上で実行できます。</p><h4 id=コントリビューションソースcsrc>コントリビューションソース(CSRC)
<a class=anchor href=#%e3%82%b3%e3%83%b3%e3%83%88%e3%83%aa%e3%83%93%e3%83%a5%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e3%82%bd%e3%83%bc%e3%82%b9csrc>#</a></h4><p>どの <code>SSRC</code> がこのパケットに貢献したかを伝えるリストです。</p><p>これは一般的にトーキングインジケーターに使用されます。例えば、サーバー側で複数のオーディオフィードを1つのRTPストリームにまとめたとします。このフィールドを使用して、「入力ストリームAとCがこの瞬間に話していた」と言うことができます。</p><h4 id=ペイロード>ペイロード
<a class=anchor href=#%e3%83%9a%e3%82%a4%e3%83%ad%e3%83%bc%e3%83%89>#</a></h4><p>実際のペイロードデータです。パディングフラグが設定されている場合は、何バイトのパディングが追加されたかが最後に表示されます。</p><h3 id=拡張機能>拡張機能
<a class=anchor href=#%e6%8b%a1%e5%bc%b5%e6%a9%9f%e8%83%bd>#</a></h3><h2 id=rtcp>RTCP
<a class=anchor href=#rtcp>#</a></h2><h3 id=packet-format>Packet Format
<a class=anchor href=#packet-format>#</a></h3><p>RTCPのパケットは、以下のような構造になっています。</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|    RC   |       PT      |             length            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=バージョン-v-1>バージョン (V)
<a class=anchor href=#%e3%83%90%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3-v-1>#</a></h4><p><code>バージョン</code> は常に <code>2</code> です。</p><h4 id=パディング-p-1>パディング (P)
<a class=anchor href=#%e3%83%91%e3%83%87%e3%82%a3%e3%83%b3%e3%82%b0-p-1>#</a></h4><p><code>パディング</code> は bool で、ペイロードにパディングがあるかどうかを制御します。</p><p>ペイロードの最後のバイトには、何バイトのパディングが追加されたかのカウントが含まれています。</p><h4 id=受信レポート数-rc>受信レポート数 (RC)
<a class=anchor href=#%e5%8f%97%e4%bf%a1%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88%e6%95%b0-rc>#</a></h4><p>このパケットに含まれるレポートの数です。1つのRTCPパケットに複数のイベントを含めることができます。</p><h4 id=パケットタイプ-pt>パケットタイプ (PT)
<a class=anchor href=#%e3%83%91%e3%82%b1%e3%83%83%e3%83%88%e3%82%bf%e3%82%a4%e3%83%97-pt>#</a></h4><p>この RTCP パケットがどのタイプであるかを示す一意の識別子です。WebRTCエージェントは、これらのタイプをすべてサポートする必要はなく、エージェントによってサポートが異なる場合があります。しかし、一般的に目にするのはこれらのタイプです。</p><ul><li>Full INTRA-frame Request (FIR) - <code>192</code></li><li>Negative ACKnowledgements (NACK) - <code>193</code></li><li>Sender Report - <code>200</code></li><li>Receiver Report - <code>201</code></li><li>Generic RTP Feedback - <code>205</code></li><li>Payload Specific Feedback - <code>206</code></li></ul><p>これらのパケットタイプの意義については、以下で詳しく説明します。</p><h3 id=full-intra-frame-request-firとpicture-loss-indication-pli>Full INTRA-frame Request (FIR)とPicture Loss Indication (PLI)
<a class=anchor href=#full-intra-frame-request-fir%e3%81%a8picture-loss-indication-pli>#</a></h3><p>FIRとPLIの目的は似ています。これらのメッセージは、送信者にフルキーフレームを要求します。
PLIは、デコーダにパーシャルフレームが到着し、デコードできない場合に使用します。
これは、パケットロスが多い場合や、デコーダがクラッシュした場合などに起こります。</p><p><a href=https://tools.ietf.org/html/rfc5104#section-4.3.1.2>RFC5104</a>によると、パケットやフレームが失われたときには <code>FIR</code> を使用してはならないとされており、それは <code>PLI</code> の仕事です。<code>FIR</code> はパケットロス以外の理由でキーフレームを要求します。例えば、ビデオ会議に新しいメンバーが入ってきたときなどです。FIRはビデオストリームのデコードを開始するために完全なキーフレームを必要とし、デコーダはキーフレームが到着するまでフレームを破棄します。</p><p>これにより、接続してからユーザーの画面に画像が表示されるまでの遅延を最小限に抑えることができます。</p><p><code>PLI</code> パケットは、Payload Specific Feedback メッセージの一部です。</p><p>実際には、<code>PLI</code> パケットと <code>FIR</code> パケットの両方を扱うことができるソフトウェアは、どちらの場合も同じように動作します。
エンコーダーに信号を送り、新しいフルキーフレームを生成します。</p><h3 id=negative-acknowledgements>Negative ACKnowledgements
<a class=anchor href=#negative-acknowledgements>#</a></h3><p>NACKは、送信者に1つのRTPパケットの再送を要求するものです。これは通常、RTP パケットが失われたときに発生しますが、遅延した場合にも発生します。</p><p>NACKは、フレーム全体の再送信を要求するよりも、はるかに帯域幅を効率的に利用できます。RTPはパケットを非常に小さなチャンクに分割するので、実際には1つの小さな欠落部分を要求しているに過ぎません。</p><h3 id=送信者受信者レポート>送信者/受信者レポート
<a class=anchor href=#%e9%80%81%e4%bf%a1%e8%80%85%e5%8f%97%e4%bf%a1%e8%80%85%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88>#</a></h3><p>これらのレポートは、エージェント間で統計情報を送信するために使用します。このレポートでは、実際に受信したパケット量やジッターを伝えます。</p><p>このレポートは、診断や輻輳制御に利用できます。</p><h2 id=rtprtcpが共に問題を解決する方法>RTP/RTCPが共に問題を解決する方法
<a class=anchor href=#rtprtcp%e3%81%8c%e5%85%b1%e3%81%ab%e5%95%8f%e9%a1%8c%e3%82%92%e8%a7%a3%e6%b1%ba%e3%81%99%e3%82%8b%e6%96%b9%e6%b3%95>#</a></h2><p>このように、RTPとRTCPが連携することで、ネットワークに起因するあらゆる問題を解決できます。これらの技術は今でも常に変化しています。</p><h3 id=negative-acknowledgment>Negative Acknowledgment
<a class=anchor href=#negative-acknowledgment>#</a></h3><p>NACKとも呼ばれます。これは、RTPのパケットロスに対処する方法のひとつです。</p><p>NACKは、再送信を要求するために送信者に送り返されるRTCPメッセージです。受信者は、SSRCとシーケンス番号を含むRTCPメッセージを作ります。送信者は、再送信可能なこのRTPパケットを持っていない場合、そのメッセージを無視します。</p><h3 id=前方誤り訂正-forward-error-correction>前方誤り訂正 (Forward Error Correction)
<a class=anchor href=#%e5%89%8d%e6%96%b9%e8%aa%a4%e3%82%8a%e8%a8%82%e6%ad%a3-forward-error-correction>#</a></h3><p>FECとも呼ばれます。パケットロスに対処するもう一つの方法です。FEC は、同じデータを要求されてもいないのに複数回送信することです。これは、RTP レベルで行われ、さらに下位のコーデックでも行われます。</p><p>通話中のパケットロスが安定している場合、FECはNACKよりもはるかに低遅延のソリューションです。NACKの場合は、パケットを要求してから再送信するまでの往復時間が大きくなります。</p><h3 id=適応型ビットレートと帯域幅の推定-adaptive-bitrate-and-bandwidth-estimation>適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation)
<a class=anchor href=#%e9%81%a9%e5%bf%9c%e5%9e%8b%e3%83%93%e3%83%83%e3%83%88%e3%83%ac%e3%83%bc%e3%83%88%e3%81%a8%e5%b8%af%e5%9f%9f%e5%b9%85%e3%81%ae%e6%8e%a8%e5%ae%9a-adaptive-bitrate-and-bandwidth-estimation>#</a></h3><p><a href=../05-real-time-networking/>リアルタイムネットワーキング</a>で説明したように、ネットワークは予測不可能で信頼性がありません。帯域幅の利用可能性は、セッション中に何度も変化する可能性があります。
利用可能な帯域幅が1秒以内に劇的に（桁違いに）変化することも珍しくありません。</p><p>主なアイデアは、予測される、現在および将来の利用可能なネットワーク帯域幅に基づいて、エンコーディングのビットレートを調整することです。
これにより、可能な限り最高の品質の映像・音声信号を伝送し、ネットワークの輻輳によって接続が切断されることがないようにします。
ネットワークの挙動をモデル化し、それを予測するヒューリスティックな手法を「帯域推定」といいます。</p><p>これには様々なニュアンスがありますので、詳しくご紹介しましょう。</p><h2 id=ネットワークの状態を伝える>ネットワークの状態を伝える
<a class=anchor href=#%e3%83%8d%e3%83%83%e3%83%88%e3%83%af%e3%83%bc%e3%82%af%e3%81%ae%e7%8a%b6%e6%85%8b%e3%82%92%e4%bc%9d%e3%81%88%e3%82%8b>#</a></h2><p>輻輳制御を実装する上での最初の障害は、UDPとRTPがネットワークの状態を通信しないことです。送信者としては、自分のパケットがいつ到着したのか、あるいは到着しているのかどうか、まったくわかりません。</p><p>RTP/RTCPには、この問題に対する3つの異なるソリューションがあります。それぞれに長所と短所があります。どのソリューションを使用するかは、どのようなクライアントを使用するかによります。トポロジーはどうなっているのか。あるいは、どれだけの開発時間を確保できるかによっても異なります。</p><h3 id=受信者レポート-receiver-reports>受信者レポート (Receiver Reports)
<a class=anchor href=#%e5%8f%97%e4%bf%a1%e8%80%85%e3%83%ac%e3%83%9d%e3%83%bc%e3%83%88-receiver-reports>#</a></h3><p>受信者レポートはRTCPメッセージであり、ネットワークステータスを伝達するための元の方法です。 それらは<a href=https://tools.ietf.org/html/rfc3550#section-6.4>RFC3350</a>で見つけることができます。 これらは各SSRCのスケジュールで送信され、次のフィールドが含まれています。</p><ul><li><strong>Fraction Lost</strong> &ndash; 前回のReceiver Report以降、何パーセントのパケットが失われたか。</li><li><strong>Cumulative Number of Packets Lost</strong> &ndash; 通話全体で失われたパケット数。</li><li><strong>Extended Highest Sequence Number Received</strong> &ndash; 最後に受信したシーケンス番号と、それが何回ロールオーバーしたかを示しています。</li><li><strong>Interarrival Jitter</strong> &ndash; 通話全体のローリングジッターです。</li><li><strong>Last Sender Report Timestamp</strong> &ndash; ラウンドトリップタイムの計算に使用される、送信者の最後の既知の時間。</li></ul><p>送信者と受信者のレポート（SRとRR）は協力してラウンドトリップタイムを計算します。</p><p>送信者は自分のローカルタイムである <code>sendertime1</code> をSRに含めます。
受信者は、SRパケットを受け取ると、RRを送り返します。
RRには、送信者から受け取ったばかりの <code>sendertime1</code> などが含まれています。
SRを受信してからRRを送信するまでには遅延が発生します。そのため、RRには「前回の送信者レポートからの遅延時間」- <code>DLSR</code> も含まれています。
<code>DLSR</code> は後のプロセスでラウンドトリップタイムの推定値を調整するために使用されます。
送信者がRRを受信すると、現在時刻の <code>sendertime2</code> から <code>sendertime1</code> と <code>DLSR</code> を差し引きます。
この時間差をラウンドトリッププロパゲーションディレイまたはラウンドトリップタイムと呼びます。</p><p><code>rtt = sendertime2 - sendertime1 - DLSR</code></p><p>往復の時間をわかりやすく解説:</p><ul><li>私があなたにメッセージを送るとき、私の時計の現在の表示は「午後4時20分、42秒と420ミリ秒」です。</li><li>あなたはこの同じタイムスタンプを私に送り返します。</li><li>あなたはまた、私のメッセージを読んでからメッセージを送り返すまでの経過時間、例えば5ミリ秒を入れます。</li><li>このタイムスタンプを受け取った私は、再び時計を見ます。</li><li>今、私の時計は午後4時20分、42秒690ミリ秒と表示されています。</li><li>つまり、あなたに届いてから私に戻ってくるまでに265ミリ秒（690 - 420 - 5）かかったことになります。</li><li>したがって、往復の時間は265ミリ秒です。</li></ul><p><img src=../../images/06-rtt.png alt=RTT title=RTT></p><h3 id=tmmbr-tmmbn-remb>TMMBR, TMMBN, REMB
<a class=anchor href=#tmmbr-tmmbn-remb>#</a></h3><p>次世代のネットワーク・ステータス・メッセージでは、すべての受信者がRTCPを介して送信者に明示的なビットレート要求をメッセージします。</p><ul><li><strong>Temporary Maximum Media Stream Bit Rate Request</strong> - 1つのSSRCに対する要求ビットレートの仮数/指数です。</li><li><strong>Temporary Maximum Media Stream Bit Rate Notification</strong> - TMMBRを受信したことを通知するメッセージです。</li><li><strong>Receiver Estimated Maximum Bitrate</strong> - セッション全体に対して要求されたビットレートの仮数/指数です。</li></ul><p>TMMBRとTMMBNが先に登場し、<a href=https://tools.ietf.org/html/rfc5104>RFC 5104</a>で定義されています。REMBは後に登場し、<a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-remb-03>draft-alvestrand-rmcat-remb</a>でドラフトが提出されましたが、標準化されませんでした。</p><p>REMBを使用したセッションは以下のようになります。</p><p><img src=../../images/06-remb.png alt=REMB title=REMB></p><p>ブラウザでは、受信帯域幅の推定に簡単な経験則を用いています。</p><ol><li>現在のパケットロスが2%未満の場合、ビットレートを上げるようにエンコーダに指示する。</li><li>パケットロスが10%以上の場合、現在のパケットロス率の半分だけビットレートを下げる。</li></ol><pre><code>if (packetLoss &lt; 2%) video_bitrate *= 1.08
if (packetLoss &gt; 10%) video_bitrate *= (1 - 0.5*lossRate)
</code></pre><p>この方法は、理論的にはとてもうまくいきます。送信側は受信側から推定値を受け取り、エンコーダのビットレートを受け取った値に設定します。なんということでしょう！これでネットワークの状況に合わせた調整ができました。</p><p>しかし実際には、REMB 方式には複数の欠点があります。</p><p>エンコーダの非効率性もその一つで、エンコーダにビットレートを設定しても、必ずしも要求した通りのビットレートで出力されるとは限りません。エンコーダーの設定やエンコードされるフレームによって、ビット数が少なくなったり多くなったりすることがあります。</p><p>たとえば、tune=zerolatency で x264 エンコーダーを使用すると、指定したターゲットビットレートから大きく外れることがあります。以下に考えられるシナリオを示します。</p><ul><li>まず、ビットレートを 1000kbps に設定したとします。</li><li>エンコーダーは 700kbps しか出力しない。（別名 - 壁を見つめる）。</li><li>また、受信機がパケットロスゼロで 700kbps の映像を受信した場合、REMB ルール 1 を適用して受信ビットレートを8％増加させたとします。</li><li>受信機は 756kbps の提案(700kbps * 1.08)をした REMB パケットを送信機に送ります。</li><li>送信者は、エンコーダのビットレートを 756kbps に設定します。</li><li>エンコーダーはさらに低いビットレートを出力します。</li><li>これを繰り返して、ビットレートを極限まで下げていきます。</li></ul><p>これでは、エンコーダのパラメータ調整が大変になってしまい、素晴らしい接続環境であっても、ユーザーが見られない映像になってしまうことがわかります。</p><h3 id=トランスポートワイド輻輳制御-transport-wide-congestion-control>トランスポートワイド輻輳制御 (Transport Wide Congestion Control)
<a class=anchor href=#%e3%83%88%e3%83%a9%e3%83%b3%e3%82%b9%e3%83%9d%e3%83%bc%e3%83%88%e3%83%af%e3%82%a4%e3%83%89%e8%bc%bb%e8%bc%b3%e5%88%b6%e5%be%a1-transport-wide-congestion-control>#</a></h3><p>トランスポートワイド輻輳制御は、RTCPのネットワークステータス通信の最新の開発です。</p><p>TWCCは非常にシンプルな原理を使用しています。</p><p><img src=../../images/06-twcc-idea.png alt=TWCC title=TWCC></p><p>REMBとは異なり、TWCC受信機は自分の受信ビットレートを推定しようとはしません。TWCC受信機は、どのパケットがいつ受信されたかを送信者に知らせるだけです。送信者は、これらのレポートに基づいて、ネットワークで何が起こっているかを最新の状態で把握できます。</p><ul><li>送信者は、パケットシーケンス番号のリストを含む、特別なTWCCヘッダー拡張を持つRTPパケットを作成します。</li><li>受信者は、各パケットがいつ受信されたかを送信者に知らせる特別なRTCPフィードバックメッセージで応答します。</li></ul><p>送信者は、送信したパケット、そのシーケンス番号、サイズ、タイムスタンプを記録します。
送信者は、受信者からRTCPメッセージを受信すると、送信側のパケット間遅延と受信側の遅延を比較します。
受信遅延が増加した場合は、ネットワークの輻輳が発生していることを意味し、送信者はそれに対処する必要があります。</p><p>下の図では、インターパケット遅延の増加の中央値は+20ミリ秒で、ネットワークの輻輳が起きていることを明確に示しています。</p><p><img src=../../images/06-twcc.png alt="TWCC with delay" title="TWCC with delay"></p><p>TWCCは生のデータを提供し、ネットワークの状態をリアルタイムに把握できます:</p><ul><li>パケットロスの統計情報をほぼ瞬時に確認でき、ロスの割合だけでなく、ロスした正確なパケットも確認できます。</li><li>正確な送信ビットレート。</li><li>正確な受信ビットレート</li><li>ジッターの推定値。</li><li>送信パケットと受信パケットの遅延時間の違い。</li></ul><p>送信側から受信側への受信ビットレートを推定するための些細な輻輳制御アルゴリズムは、受信したパケットサイズを合計し、それを経過したリモートタイムで割ることです。</p><h2 id=帯域幅の推定値の生成>帯域幅の推定値の生成
<a class=anchor href=#%e5%b8%af%e5%9f%9f%e5%b9%85%e3%81%ae%e6%8e%a8%e5%ae%9a%e5%80%a4%e3%81%ae%e7%94%9f%e6%88%90>#</a></h2><p>ネットワークの状態に関する情報が得られたので、利用可能な帯域幅を推定できます。2012年、IETFはRMCAT（RTP Media Congestion Avoidance Techniques）ワーキンググループを立ち上げました。
このワーキンググループには、輻輳制御アルゴリズムに関する複数の規格が提出されています。それ以前は、すべての輻輳制御アルゴリズムは独自のものでした。</p><p>最も導入されているのは、<a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-congestion-02>draft-alvestrand-rmcat-congestion</a>で定義されている「A Google Congestion Control Algorithm for Real-Time Communication」です。
このアルゴリズムは、2つのパスで実行されます。まず、受信機レポートのみを使用する「損失ベース」のパス。TWCCが利用可能な場合は、その追加データも考慮されます。
また、<a href=https://en.wikipedia.org/wiki/Kalman_filter>カルマンフィルター</a>を使用して、現在および将来のネットワーク帯域幅を予測します。</p><p>GCCに代わるものとしては、<a href=https://tools.ietf.org/html/draft-zhu-rmcat-nada-04>NADA: A Unified Congestion Control Scheme for Real-Time Media</a>や<a href=https://tools.ietf.org/html/draft-johansson-rmcat-scream-cc-05>SCReAM - Self-Clocked Rate Adaptation for Multimedia</a>などがあります。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div class=book-languages tabindex=0 aria-haspopup=true><ul><li class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
日本語</li></ul><ul class=book-languages-list><li><a href=https://webrtcforthecurious.com/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
English</a></li><li><a href=https://webrtcforthecurious.com/sv/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
Svenska</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
简体中文</a></li><li class=active><a href=https://webrtcforthecurious.com/ja/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
日本語</a></li></ul></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/1a70667159cd5b163978675a035fe32eadacca0b title="最終更新者 Claes Mogren | May 21, 2021" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>May 21, 2021</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content.ja/docs/06-media-communication.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>このページを編集する</span></a></div></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#どのような仕組みになっているのですか>どのような仕組みになっているのですか？</a></li><li><a href=#レイテンシー-vs-クオリティ>レイテンシー vs クオリティ</a><ul><li><a href=#現実の制約>現実の制約</a></li><li><a href=#ビデオは複雑>ビデオは複雑</a></li></ul></li><li><a href=#ビデオ101>ビデオ101</a><ul><li><a href=#非可逆圧縮と可逆圧縮>非可逆圧縮と可逆圧縮</a></li><li><a href=#イントラフレームとインターフレームの圧縮>イントラフレームとインターフレームの圧縮</a></li><li><a href=#フレーム間の種類>フレーム間の種類</a></li><li><a href=#動画はデリケート>動画はデリケート</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#パケットフォーマット>パケットフォーマット</a></li><li><a href=#拡張機能>拡張機能</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#full-intra-frame-request-firとpicture-loss-indication-pli>Full INTRA-frame Request (FIR)とPicture Loss Indication (PLI)</a></li><li><a href=#negative-acknowledgements>Negative ACKnowledgements</a></li><li><a href=#送信者受信者レポート>送信者/受信者レポート</a></li></ul></li><li><a href=#rtprtcpが共に問題を解決する方法>RTP/RTCPが共に問題を解決する方法</a><ul><li><a href=#negative-acknowledgment>Negative Acknowledgment</a></li><li><a href=#前方誤り訂正-forward-error-correction>前方誤り訂正 (Forward Error Correction)</a></li><li><a href=#適応型ビットレートと帯域幅の推定-adaptive-bitrate-and-bandwidth-estimation>適応型ビットレートと帯域幅の推定 (Adaptive Bitrate and Bandwidth Estimation)</a></li></ul></li><li><a href=#ネットワークの状態を伝える>ネットワークの状態を伝える</a><ul><li><a href=#受信者レポート-receiver-reports>受信者レポート (Receiver Reports)</a></li><li><a href=#tmmbr-tmmbn-remb>TMMBR, TMMBN, REMB</a></li><li><a href=#トランスポートワイド輻輳制御-transport-wide-congestion-control>トランスポートワイド輻輳制御 (Transport Wide Congestion Control)</a></li></ul></li><li><a href=#帯域幅の推定値の生成>帯域幅の推定値の生成</a></li></ul></nav></div></aside></main></body></html>