<!doctype html><html lang=zh dir=ltr><head><meta name=generator content="Hugo 0.74.3"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="我可以从WebRTC的媒体通信中得到什么？ #  WebRTC允许您发送和接收无限多条音频和视频流。您可以在通话期间随时添加和删除这些流。这些流可以全部独立，也可以捆绑在一起！您甚至可以将网络摄像头的音频/视频放到您桌面的视频流中，然后将此视频流以feed的形式发送出去。
WebRTC协议与编解码器无关。底层传输支持所有格式的内容，即使是还不存在的格式！ 但是，您正与之通信的WebRTC代理可能没有必要的工具来接受它。
WebRTC针对动态网络状况也有对应的处理方案。在通话过程中，带宽可能会增加或减少。甚至可能突然间大量丢包。该协议对所有这类问题的处理都做了相应的设计。WebRTC根据网络状况作出响应，并尝试利用可用资源为您提供最佳体验。
它是如何工作的？ #  WebRTC使用RFC 1889中定义的两个既有协议RTP和RTCP。
RTP（实时传输协议/Real-time Transport Protocol）是承载媒体的协议。它为视频的实时传输而设计。它没有规定有关延迟或可靠性的任何规则，但是为您提供了实现这些规则的工具。RTP提供了流的设计，因此您可以通过一个连接发布多个媒体源。它还为您提供了完善媒体传递途径所需的计时和排序信息。
RTCP（RTP控制协议/RTP Control Protocol）是用于传达有关呼叫的元数据的协议。其格式非常灵活，并允许您可以添加所需的任何元数据。这点被用来传达有关呼叫的统计信息。也是处理分组丢失和实现拥塞控制的必备特性。它为您提供了响应变化的网络状况所必需的双向通信能力。
延迟与质量 #  实时媒体就是要在延迟和质量之间进行权衡。您愿意忍受的延迟时间越长，可以预期的视频质量就越高。
现实世界的局限性 #  下面这些限制都是由现实世界的局限性引起的。它们都是您需要考虑的网络特性。
视频是复杂的 #  传输视频并不容易。要存储30分钟未压缩的720p的8-bit视频，您需要~110Gb。按照这个数据，4人电话会议就开不成了。我们需要一种缩小尺寸的方法，而答案就是视频压缩。但是，这并非没有缺点。
视频101 #  我们不会深入介绍视频压缩，只需要让大家足以理解为什么RTP是这么设计的。视频压缩会将视频编码为一种新格式，这样可以需要较少的bit数来表示同一视频。
有损和无损压缩 #  您可以将视频编码为无损（无信息丢失）或有损（信息可能丢失）压缩。由于无损编码需要将更多的数据发送到对端，这样会导致更高的流延迟和更多的丢包，因此RTP通常使用有损压缩，即使这样可能会导致视频质量不佳。
帧内和帧间压缩 #  视频压缩有两种类型。首先是帧内压缩。帧内压缩减少了用于描述单个视频帧的bit数。相同的技术被用来压缩静态图片，例如JPEG压缩方法。
第二种类型是帧间压缩。由于视频是由许多图片组成的，因此我们需要寻找无需将相同信息发送两次的方式。
帧间压缩 #  帧有三种类型
 I帧 - 一张完整的图片，无需任何其他内容即可解码 P帧 - 一张图片的一部分，包含对之前图片的修改 B帧 - 一张图片的一部分，包含对之前图片和将来图片的修改  以下是对这三种类型帧的图解。
视频很脆弱 #  压缩后的视频是有状态的，（视频解码）非常依赖其上下文，这使得视频很难通过Internet进行传输。想像一下，如果I帧的一部分丢失了会怎样？这样P帧如何知道要修改的内容？ 随着视频压缩变得越来越复杂，这成为一个更大的问题。幸运的是，RTP和RTCP对此都有解决方案。
RTP #  Packet Format（包格式） #  每个RTP数据包都具有以下结构："><meta name=theme-color content="#FFFFFF"><meta property="og:title" content="媒体通信"><meta property="og:description" content="我可以从WebRTC的媒体通信中得到什么？ #  WebRTC允许您发送和接收无限多条音频和视频流。您可以在通话期间随时添加和删除这些流。这些流可以全部独立，也可以捆绑在一起！您甚至可以将网络摄像头的音频/视频放到您桌面的视频流中，然后将此视频流以feed的形式发送出去。
WebRTC协议与编解码器无关。底层传输支持所有格式的内容，即使是还不存在的格式！ 但是，您正与之通信的WebRTC代理可能没有必要的工具来接受它。
WebRTC针对动态网络状况也有对应的处理方案。在通话过程中，带宽可能会增加或减少。甚至可能突然间大量丢包。该协议对所有这类问题的处理都做了相应的设计。WebRTC根据网络状况作出响应，并尝试利用可用资源为您提供最佳体验。
它是如何工作的？ #  WebRTC使用RFC 1889中定义的两个既有协议RTP和RTCP。
RTP（实时传输协议/Real-time Transport Protocol）是承载媒体的协议。它为视频的实时传输而设计。它没有规定有关延迟或可靠性的任何规则，但是为您提供了实现这些规则的工具。RTP提供了流的设计，因此您可以通过一个连接发布多个媒体源。它还为您提供了完善媒体传递途径所需的计时和排序信息。
RTCP（RTP控制协议/RTP Control Protocol）是用于传达有关呼叫的元数据的协议。其格式非常灵活，并允许您可以添加所需的任何元数据。这点被用来传达有关呼叫的统计信息。也是处理分组丢失和实现拥塞控制的必备特性。它为您提供了响应变化的网络状况所必需的双向通信能力。
延迟与质量 #  实时媒体就是要在延迟和质量之间进行权衡。您愿意忍受的延迟时间越长，可以预期的视频质量就越高。
现实世界的局限性 #  下面这些限制都是由现实世界的局限性引起的。它们都是您需要考虑的网络特性。
视频是复杂的 #  传输视频并不容易。要存储30分钟未压缩的720p的8-bit视频，您需要~110Gb。按照这个数据，4人电话会议就开不成了。我们需要一种缩小尺寸的方法，而答案就是视频压缩。但是，这并非没有缺点。
视频101 #  我们不会深入介绍视频压缩，只需要让大家足以理解为什么RTP是这么设计的。视频压缩会将视频编码为一种新格式，这样可以需要较少的bit数来表示同一视频。
有损和无损压缩 #  您可以将视频编码为无损（无信息丢失）或有损（信息可能丢失）压缩。由于无损编码需要将更多的数据发送到对端，这样会导致更高的流延迟和更多的丢包，因此RTP通常使用有损压缩，即使这样可能会导致视频质量不佳。
帧内和帧间压缩 #  视频压缩有两种类型。首先是帧内压缩。帧内压缩减少了用于描述单个视频帧的bit数。相同的技术被用来压缩静态图片，例如JPEG压缩方法。
第二种类型是帧间压缩。由于视频是由许多图片组成的，因此我们需要寻找无需将相同信息发送两次的方式。
帧间压缩 #  帧有三种类型
 I帧 - 一张完整的图片，无需任何其他内容即可解码 P帧 - 一张图片的一部分，包含对之前图片的修改 B帧 - 一张图片的一部分，包含对之前图片和将来图片的修改  以下是对这三种类型帧的图解。
视频很脆弱 #  压缩后的视频是有状态的，（视频解码）非常依赖其上下文，这使得视频很难通过Internet进行传输。想像一下，如果I帧的一部分丢失了会怎样？这样P帧如何知道要修改的内容？ 随着视频压缩变得越来越复杂，这成为一个更大的问题。幸运的是，RTP和RTCP对此都有解决方案。
RTP #  Packet Format（包格式） #  每个RTP数据包都具有以下结构："><meta property="og:type" content="article"><meta property="og:url" content="https://webrtcforthecurious.com/zh/docs/06-media-communication/"><meta property="article:modified_time" content="2021-05-21T10:24:46-07:00"><meta property="og:site_name" content="给好奇者的WebRTC"><title>媒体通信 | 给好奇者的WebRTC</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=alternate hreflang=en href=https://webrtcforthecurious.com/docs/06-media-communication/ title="Media Communication"><link rel=alternate hreflang=ja href=https://webrtcforthecurious.com/ja/docs/06-media-communication/ title=メディア・コミュニケーション><link rel=stylesheet href=/book.min.6c7c6446dfdee7c8c933e9bbc6e80ee3ed6c913b2a59519f2092c3c6a9d63e55.css integrity="sha256-bHxkRt/e58jJM+m7xugO4+1skTsqWVGfIJLDxqnWPlU="><script defer src=/zh.search.min.430d24100ad5992b0889a6bb88fa75e081d878721846b633f8bbe2f9cb16b1dd.js integrity="sha256-Qw0kEArVmSsIiaa7iPp14IHYeHIYRrYz+Lvi+csWsd0="></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a href=/zh><span>给好奇者的WebRTC</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=搜索 aria-label=搜索 maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=https://webrtcforthecurious.com/zh/docs/01-what-why-and-how/>是什么，为什么，如何使用</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/02-signaling/>信令</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/03-connecting/>连接</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/04-securing/>安全性</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/05-real-time-networking/>搭建实时网络</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/06-media-communication/ class=active>媒体通信</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/07-data-communication/>数据通信</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/08-applied-webrtc/>WebRTC应用场景</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/09-debugging/>调试</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/10-history-of-webrtc/>历史</a></li><li><a href=https://webrtcforthecurious.com/zh/docs/11-faq/>常见问题</a></li></ul></nav><script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>媒体通信</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#它是如何工作的>它是如何工作的？</a></li><li><a href=#延迟与质量>延迟与质量</a><ul><li><a href=#现实世界的局限性>现实世界的局限性</a></li><li><a href=#视频是复杂的>视频是复杂的</a></li></ul></li><li><a href=#视频101>视频101</a><ul><li><a href=#有损和无损压缩>有损和无损压缩</a></li><li><a href=#帧内和帧间压缩>帧内和帧间压缩</a></li><li><a href=#帧间压缩>帧间压缩</a></li><li><a href=#视频很脆弱>视频很脆弱</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#packet-format包格式>Packet Format（包格式）</a></li><li><a href=#extensions扩展>Extensions（扩展）</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#完整的帧内请求fir和图片丢失指示pli>完整的帧内请求（FIR）和图片丢失指示（PLI）</a></li><li><a href=#negative-acknowledgements否定确认>Negative ACKnowledgements（否定确认）</a></li><li><a href=#senderreceiver-reports发送方接收方报告>Sender/Receiver Reports（发送方/接收方报告）</a></li></ul></li><li><a href=#rtprtcp是如何协作解决问题的>RTP/RTCP是如何协作解决问题的</a><ul><li><a href=#negative-acknowledgment否定确认>Negative Acknowledgment（否定确认）</a></li><li><a href=#forward-error-correction前向纠错>Forward Error Correction（前向纠错）</a></li><li><a href=#自适应比特率和带宽估计>自适应比特率和带宽估计</a></li></ul></li><li><a href=#传递网络状态>传递网络状态</a><ul><li><a href=#接收方报告>接收方报告</a></li><li><a href=#tmmbrtmmbn和remb>TMMBR，TMMBN和REMB</a></li><li><a href=#传输范围内的拥塞控制twcc>传输范围内的拥塞控制（TWCC）</a></li></ul></li><li><a href=#生成带宽估计值>生成带宽估计值</a></li></ul></nav></aside></header><article class=markdown><h1 id=我可以从webrtc的媒体通信中得到什么>我可以从WebRTC的媒体通信中得到什么？
<a class=anchor href=#%e6%88%91%e5%8f%af%e4%bb%a5%e4%bb%8ewebrtc%e7%9a%84%e5%aa%92%e4%bd%93%e9%80%9a%e4%bf%a1%e4%b8%ad%e5%be%97%e5%88%b0%e4%bb%80%e4%b9%88>#</a></h1><p>WebRTC允许您发送和接收无限多条音频和视频流。您可以在通话期间随时添加和删除这些流。这些流可以全部独立，也可以捆绑在一起！您甚至可以将网络摄像头的音频/视频放到您桌面的视频流中，然后将此视频流以feed的形式发送出去。</p><p>WebRTC协议与编解码器无关。底层传输支持所有格式的内容，即使是还不存在的格式！ 但是，您正与之通信的WebRTC代理可能没有必要的工具来接受它。</p><p>WebRTC针对动态网络状况也有对应的处理方案。在通话过程中，带宽可能会增加或减少。甚至可能突然间大量丢包。该协议对所有这类问题的处理都做了相应的设计。WebRTC根据网络状况作出响应，并尝试利用可用资源为您提供最佳体验。</p><h2 id=它是如何工作的>它是如何工作的？
<a class=anchor href=#%e5%ae%83%e6%98%af%e5%a6%82%e4%bd%95%e5%b7%a5%e4%bd%9c%e7%9a%84>#</a></h2><p>WebRTC使用<a href=https://tools.ietf.org/html/rfc1889>RFC 1889</a>中定义的两个既有协议RTP和RTCP。</p><p>RTP（实时传输协议/Real-time Transport Protocol）是承载媒体的协议。它为视频的实时传输而设计。它没有规定有关延迟或可靠性的任何规则，但是为您提供了实现这些规则的工具。RTP提供了流的设计，因此您可以通过一个连接发布多个媒体源。它还为您提供了完善媒体传递途径所需的计时和排序信息。</p><p>RTCP（RTP控制协议/RTP Control Protocol）是用于传达有关呼叫的元数据的协议。其格式非常灵活，并允许您可以添加所需的任何元数据。这点被用来传达有关呼叫的统计信息。也是处理分组丢失和实现拥塞控制的必备特性。它为您提供了响应变化的网络状况所必需的双向通信能力。</p><h2 id=延迟与质量>延迟与质量
<a class=anchor href=#%e5%bb%b6%e8%bf%9f%e4%b8%8e%e8%b4%a8%e9%87%8f>#</a></h2><p>实时媒体就是要在延迟和质量之间进行权衡。您愿意忍受的延迟时间越长，可以预期的视频质量就越高。</p><h3 id=现实世界的局限性>现实世界的局限性
<a class=anchor href=#%e7%8e%b0%e5%ae%9e%e4%b8%96%e7%95%8c%e7%9a%84%e5%b1%80%e9%99%90%e6%80%a7>#</a></h3><p>下面这些限制都是由现实世界的局限性引起的。它们都是您需要考虑的网络特性。</p><h3 id=视频是复杂的>视频是复杂的
<a class=anchor href=#%e8%a7%86%e9%a2%91%e6%98%af%e5%a4%8d%e6%9d%82%e7%9a%84>#</a></h3><p>传输视频并不容易。要存储30分钟未压缩的720p的8-bit视频，您需要~110Gb。按照这个数据，4人电话会议就开不成了。我们需要一种缩小尺寸的方法，而答案就是视频压缩。但是，这并非没有缺点。</p><h2 id=视频101>视频101
<a class=anchor href=#%e8%a7%86%e9%a2%91101>#</a></h2><p>我们不会深入介绍视频压缩，只需要让大家足以理解为什么RTP是这么设计的。视频压缩会将视频编码为一种新格式，这样可以需要较少的bit数来表示同一视频。</p><h3 id=有损和无损压缩>有损和无损压缩
<a class=anchor href=#%e6%9c%89%e6%8d%9f%e5%92%8c%e6%97%a0%e6%8d%9f%e5%8e%8b%e7%bc%a9>#</a></h3><p>您可以将视频编码为无损（无信息丢失）或有损（信息可能丢失）压缩。由于无损编码需要将更多的数据发送到对端，这样会导致更高的流延迟和更多的丢包，因此RTP通常使用有损压缩，即使这样可能会导致视频质量不佳。</p><h3 id=帧内和帧间压缩>帧内和帧间压缩
<a class=anchor href=#%e5%b8%a7%e5%86%85%e5%92%8c%e5%b8%a7%e9%97%b4%e5%8e%8b%e7%bc%a9>#</a></h3><p>视频压缩有两种类型。首先是帧内压缩。帧内压缩减少了用于描述单个视频帧的bit数。相同的技术被用来压缩静态图片，例如JPEG压缩方法。</p><p>第二种类型是帧间压缩。由于视频是由许多图片组成的，因此我们需要寻找无需将相同信息发送两次的方式。</p><h3 id=帧间压缩>帧间压缩
<a class=anchor href=#%e5%b8%a7%e9%97%b4%e5%8e%8b%e7%bc%a9>#</a></h3><p>帧有三种类型</p><ul><li><strong>I帧</strong> - 一张完整的图片，无需任何其他内容即可解码</li><li><strong>P帧</strong> - 一张图片的一部分，包含对之前图片的修改</li><li><strong>B帧</strong> - 一张图片的一部分，包含对之前图片和将来图片的修改</li></ul><p>以下是对这三种类型帧的图解。</p><p><img src=../../images/06-frame-types.png alt=帧类型 title=帧类型></p><h3 id=视频很脆弱>视频很脆弱
<a class=anchor href=#%e8%a7%86%e9%a2%91%e5%be%88%e8%84%86%e5%bc%b1>#</a></h3><p>压缩后的视频是有状态的，（视频解码）非常依赖其上下文，这使得视频很难通过Internet进行传输。想像一下，如果I帧的一部分丢失了会怎样？这样P帧如何知道要修改的内容？ 随着视频压缩变得越来越复杂，这成为一个更大的问题。幸运的是，RTP和RTCP对此都有解决方案。</p><h2 id=rtp>RTP
<a class=anchor href=#rtp>#</a></h2><h3 id=packet-format包格式>Packet Format（包格式）
<a class=anchor href=#packet-format%e5%8c%85%e6%a0%bc%e5%bc%8f>#</a></h3><p>每个RTP数据包都具有以下结构：</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|X|  CC   |M|     PT      |       Sequence Number         |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                           Timestamp                           |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|           Synchronization Source (SSRC) identifier            |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|            Contributing Source (CSRC) identifiers             |
|                             ....                              |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=version-v>Version (V)
<a class=anchor href=#version-v>#</a></h4><p><code>Version</code>总是<code>2</code>。</p><h4 id=padding-p>Padding (P)
<a class=anchor href=#padding-p>#</a></h4><p><code>Padding</code>是控制有效载荷是否具有填充值的布尔值。</p><p>有效负载的最后一个字节包含添加了多少填充字节的计数。</p><h4 id=extension-x>Extension (X)
<a class=anchor href=#extension-x>#</a></h4><p>如果设置的话，RTP报头将有扩展段（可选）。这点将在下面更详细地描述。</p><h4 id=csrc-count-cc>CSRC count (CC)
<a class=anchor href=#csrc-count-cc>#</a></h4><p>在<code>SSRC</code>之后，有效负载之前的<code>CSRC</code>标识符的数量。</p><h4 id=marker-m>Marker (M)
<a class=anchor href=#marker-m>#</a></h4><p>标记位没有预设含义，用户可以根据自己的需求随意使用它。</p><p>在某些情况下，它是在用户讲话时设置的。它还通常用于标记关键帧。</p><h4 id=payload-type-pt>Payload Type (PT)
<a class=anchor href=#payload-type-pt>#</a></h4><p><code>Payload Type</code>（负载类型）是此数据包所承载的编解码器的一个唯一标识符。</p><p>对于WebRTC，<code>Payload Type</code>是动态的。一个呼叫中的VP8的PT可能与另一个呼叫中的不同。呼叫中的Offerer确定<code>Payload Type</code>到<code>Session Description</code>（会话描述符）中的编解码器的映射。</p><h4 id=sequence-number>Sequence Number
<a class=anchor href=#sequence-number>#</a></h4><p><code>Sequence Number</code>（序列号）用于对流中的数据包进行排序。每次发送数据包时，<code>Sequence Number</code>都会增加1。</p><p>RTP被设计为可以在有损网络上使用。这为接收器提供了一种检测数据包何时丢失的方法。</p><h4 id=timestamp>Timestamp
<a class=anchor href=#timestamp>#</a></h4><p>此数据包的采样时刻。这不是全局时钟，而是在当前媒体流中所经过的时间。</p><h4 id=synchronization-source-ssrc>Synchronization Source (SSRC)
<a class=anchor href=#synchronization-source-ssrc>#</a></h4><p><code>SSRC</code>是此流的唯一标识符。 这使您可以在单个流上传输多个媒体流。</p><h4 id=contributing-source-csrc>Contributing Source (CSRC)
<a class=anchor href=#contributing-source-csrc>#</a></h4><p>一个列表，用于表示哪些<code>SSRC</code>参与到了这个数据包中。</p><p>这通常用于语音指示器。假设在服务器端，您将多个音频源组合到一个单独的RTP流中。然后，您可以在此字段中表示<code>输入流A和C此时正在讲话</code>。</p><h4 id=payload>Payload
<a class=anchor href=#payload>#</a></h4><p>实际有效负载数据。如果设置了填充（padding）标记，则可能以添加的填充字节数结尾。</p><h3 id=extensions扩展>Extensions（扩展）
<a class=anchor href=#extensions%e6%89%a9%e5%b1%95>#</a></h3><h2 id=rtcp>RTCP
<a class=anchor href=#rtcp>#</a></h2><h3 id=packet-format>Packet Format
<a class=anchor href=#packet-format>#</a></h3><p>每个RTCP数据包都具有以下结构：</p><pre><code> 0                   1                   2                   3
 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|V=2|P|    RC   |       PT      |             length            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
|                            Payload                            |
+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
</code></pre><h4 id=version-v-1>Version (V)
<a class=anchor href=#version-v-1>#</a></h4><p><code>Version</code>总是<code>2</code>。</p><h4 id=padding-p-1>Padding (P)
<a class=anchor href=#padding-p-1>#</a></h4><p><code>Padding</code>是控制有效载荷是否具有填充值的布尔值。</p><p>有效负载的最后一个字节包含添加了多少填充字节的计数。</p><h4 id=reception-report-count-rc>Reception Report Count (RC)
<a class=anchor href=#reception-report-count-rc>#</a></h4><p>此数据包中的报告数。单个RTCP数据包可以包含多个事件。</p><h4 id=packet-type-pt>Packet Type (PT)
<a class=anchor href=#packet-type-pt>#</a></h4><p>指示RTCP数据包类型的唯一标识符。WebRTC代理不需要支持所有这些类型，并且代理之间的支持能力可以是不同的。下面这些是您可能经常看到的类型。</p><ul><li>完整的帧内请求（FIR）-<code>192</code></li><li>否定确认（NACK）-<code>193</code></li><li>发送方报告-<code>200</code></li><li>接收方报告-<code>201</code></li><li>通用RTP反馈-<code>205</code></li><li>有效负载特定反馈-<code>206</code></li></ul><p>这些分组类型的意义将在下面更详细地描述。</p><h3 id=完整的帧内请求fir和图片丢失指示pli>完整的帧内请求（FIR）和图片丢失指示（PLI）
<a class=anchor href=#%e5%ae%8c%e6%95%b4%e7%9a%84%e5%b8%a7%e5%86%85%e8%af%b7%e6%b1%82fir%e5%92%8c%e5%9b%be%e7%89%87%e4%b8%a2%e5%a4%b1%e6%8c%87%e7%a4%bapli>#</a></h3><p>FIR和PLI消息的目的是类似的。这些消息都是向发送方请求一个完整的关键帧。
<code>PLI</code>用于部分帧到达了解码器，并且无法对它们进行解码的情况。
之所以会发生这种情况，是因为您有很多数据包丢失，或者解码器崩溃了。</p><p>根据<a href=https://tools.ietf.org/html/rfc5104#section-4.3.1.2>RFC5104</a>，当数据包或帧丢失时，不应使用<code>FIR</code>，这是<code>PLI</code>的任务。用<code>FIR</code>请求关键帧适用于丢包以外的其他原因（例如，当新成员进入视频会议时）。他们需要一个完整的关键帧才能开始对视频流进行解码，解码器将丢弃一些帧，直到关键帧到达为止。</p><p>对于接收方来说，在连接建立后立即请求一个完整的关键帧是个好主意，这可以最大程度地减少连接建立和在用户屏幕上显示图像之间的延迟。</p><p><code>PLI</code>数据包是"有效负载特定反馈"消息的组成部分。</p><p>在实践中，能够同时处理<code>PLI</code>和<code>FIR</code>数据包的软件在两种场景下的行为是相同的。它会向编码器发送信号以产生新的完整关键帧。</p><h3 id=negative-acknowledgements否定确认>Negative ACKnowledgements（否定确认）
<a class=anchor href=#negative-acknowledgements%e5%90%a6%e5%ae%9a%e7%a1%ae%e8%ae%a4>#</a></h3><p>NACK请求发送方重新发送单个RTP数据包。这通常是由于RTP数据包丢失而引起的，但是也可能由于延迟而发生。</p><p>与请求重新发送整个帧相比，NACK的带宽效率要高得多。由于RTP将数据包分解成很小的块，因此您实际上只是在请求丢失的一个很小的部分。</p><h3 id=senderreceiver-reports发送方接收方报告>Sender/Receiver Reports（发送方/接收方报告）
<a class=anchor href=#senderreceiver-reports%e5%8f%91%e9%80%81%e6%96%b9%e6%8e%a5%e6%94%b6%e6%96%b9%e6%8a%a5%e5%91%8a>#</a></h3><p>这些报告用于在代理之间发送统计信息。它传达了实际接收到的和抖动的数据包数量。</p><p>这些报告可用于诊断以及控制拥塞。</p><h2 id=rtprtcp是如何协作解决问题的>RTP/RTCP是如何协作解决问题的
<a class=anchor href=#rtprtcp%e6%98%af%e5%a6%82%e4%bd%95%e5%8d%8f%e4%bd%9c%e8%a7%a3%e5%86%b3%e9%97%ae%e9%a2%98%e7%9a%84>#</a></h2><p>RTP和RTCP需要协同解决网络引起的所有问题。这些技术仍在不断进化中！</p><h3 id=negative-acknowledgment否定确认>Negative Acknowledgment（否定确认）
<a class=anchor href=#negative-acknowledgment%e5%90%a6%e5%ae%9a%e7%a1%ae%e8%ae%a4>#</a></h3><p>也称为NACK。这是使用RTP处理数据包丢失的一种方法。</p><p>NACK是回给发送方以请求重发的RTCP消息。接收方使用SSRC和序列号制作RTCP消息。如果发送方没有可用于重新发送的RTP数据包，则忽略该消息。</p><h3 id=forward-error-correction前向纠错>Forward Error Correction（前向纠错）
<a class=anchor href=#forward-error-correction%e5%89%8d%e5%90%91%e7%ba%a0%e9%94%99>#</a></h3><p>简称为FEC。处理丢包的另一种方法。FEC指的是发送方多次重复发送相同的数据，甚至是在接收方没有要求的情况下发送。这是在RTP协议层级完成的，甚至也可以在编解码器以下的层级完成。</p><p>在呼叫的数据丢包率比较稳定的情况下，作为延迟处理方案，FEC比NACK好的多。对于NACK，必须先请求，然后重新传输数据包，数据往返的时间对性能的影响可能是很明显的。</p><h3 id=自适应比特率和带宽估计>自适应比特率和带宽估计
<a class=anchor href=#%e8%87%aa%e9%80%82%e5%ba%94%e6%af%94%e7%89%b9%e7%8e%87%e5%92%8c%e5%b8%a6%e5%ae%bd%e4%bc%b0%e8%ae%a1>#</a></h3><p>正如<a href=../05-real-time-networking/>搭建实时网络</a>中讨论的那样，网络是不可预测且不可靠的。带宽的可用性在整个会话中可能会多次变化。
在一秒钟之内看到可用的带宽急剧变化（差别达到数量级），这样的情况并不少见。</p><p>这里的主要思路是根据预测的，当前的和将来的可用网络带宽来调整编码比特率。
这样可以确保传输质量最佳的视频/音频信号，并且不会因为网络拥塞而断开连接。
对网络行为建模并尝试对其进行预测的启发式方法称为带宽估计。</p><p>这里有很多细微的差别，因此，让我们来探索一下更多细节。</p><h2 id=传递网络状态>传递网络状态
<a class=anchor href=#%e4%bc%a0%e9%80%92%e7%bd%91%e7%bb%9c%e7%8a%b6%e6%80%81>#</a></h2><p>实施拥塞控制的第一个障碍是UDP和RTP不会传递网络状态。作为发送方，我不知道我的数据包在什么时候到达，甚至根本不知道它们到达了没有！</p><p>针对此问题，RTP/RTCP有3种不同的解决方案。每种都有自己的优点和缺点。使用什么方案取决于您面向的客户类型、使用的网络拓扑、甚至是您有多少开发时间。</p><h3 id=接收方报告>接收方报告
<a class=anchor href=#%e6%8e%a5%e6%94%b6%e6%96%b9%e6%8a%a5%e5%91%8a>#</a></h3><p>接收方报告是一些RTCP消息，这是传递网络状态的最原始的方法。您可以在<a href=https://tools.ietf.org/html/rfc3550#section-6.4>RFC 3550</a>中找到它们。按照时间计划，它们会被发送给每个SSRC，并包含以下字段：</p><ul><li><strong>丢包率</strong> &ndash; 自上次接收者报告以来丢失了数据包的百分比。</li><li><strong>累计丢包数</strong> &ndash; 在整个通话过程中丢了多少包。</li><li><strong>接收到的最高序列号扩展</strong> &ndash; 接收到的最后一个序列号，以及它滚动的次数。</li><li><strong>到达间隔抖动（Interarrival Jitter）</strong> &ndash; 整个通话过程中的抖动滚动。（译注：RTP数据包到达时间的统计方差的估计值，以时间戳为单位进行度量，并表示为无符号整数。）</li><li><strong>上次发送方报告时间戳（Last Sender Report Timestamp）</strong> &ndash; 已知的最后一次的发送方报告的时间戳，用于往返时间的计算。</li></ul><p>发送方和接收方报告（SR和RR）配合，可以计算往返时间。</p><p>发送方在SR中包含其本地时间<code>sendertime1</code>。
当接收方获得SR数据包时，发回RR。
除了其他一些信息，RR还要包括刚从发送方接收到的<code>sendertime1</code>。
在接收SR和发送RR之间，会有一个延迟。因此，RR还包括"自上次发送方报告以来的延迟"时间 - <code>DLSR</code>（delay since last sender report）。
<code>DLSR</code>用于在该过程的稍后阶段调整往返时间的估计。
一旦发送者接收到RR，它就从当前时间<code>sendertime2</code>中减去<code>sendertime1</code>和<code>DLSR</code>。
该时间差称为往返传播延迟或往返时间。</p><p><code>rtt（往返时间） = sendertime2 - sendertime1 - DLSR</code></p><p>换个简单的说法来解释，就是这样：</p><ul><li>我看了看表，向您发送了一条消息，说这是下午4点20分42秒420毫秒。</li><li>您再将相同的时间戳发回给我。</li><li>（返回的消息中）还包括了从阅读我的消息到发回消息所花费的时间，例如5毫秒。</li><li>收到时间后，我会再次看时钟。</li><li>现在我的表是下午4点20分42秒690毫秒。</li><li>这意味着消息需要265毫秒（690-420-5）才能到达您，并返回到我。</li><li>因此，往返时间为265毫秒。</li></ul><p><img src=../../images/06-rtt.png alt=往返时间 title=往返时间></p><h3 id=tmmbrtmmbn和remb>TMMBR，TMMBN和REMB
<a class=anchor href=#tmmbrtmmbn%e5%92%8cremb>#</a></h3><p>下一代的网络状态消息都是接收方通过带有显式比特率请求的RTCP消息传递给发送方。</p><ul><li><strong>TMMBR（临时最大媒体码率请求）</strong> - 单个SSRC请求码率的尾数/指数。（译注：接收端当前带宽受限，告诉发送端控制码率。）</li><li><strong>TMMBN（临时最大媒体码率通知）</strong> - （发送端）通知（接收端）已经收到TMMBR的消息。</li><li><strong>REMB（接收方估计的最大码率）</strong> - 整个会话中请求码率的尾数/指数。</li></ul><p>TMMBR和TMMBN是先出现的，它们在<a href=https://tools.ietf.org/html/rfc5104>RFC 5104</a>中定义。REMB是后来出现的，是在<a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-remb-03>draft-alvestrand-rmcat-remb</a>中提交的一个草案，但从未被标准化。</p><p>使用REMB的会话如下图所示：</p><p><img src=../../images/06-remb.png alt=REMB title=REMB></p><p>浏览器使用简单的经验法则来估计传入带宽：</p><ol><li>如果当前丢包小于2％，则告知编码器去提高比特率。</li><li>如果丢包高于10％，则降低比特率，减少的值为当前丢包率的一半。</li></ol><pre><code>if (packetLoss &lt; 2%) video_bitrate *= 1.08
if (packetLoss &gt; 10%) video_bitrate *= (1 - 0.5*lossRate)
</code></pre><p>这个方法在纸面上看起来效果很好。发送方从接收方接收估计值，然后将编码器比特率设置为接收到的值。啊哈！我们已经根据网络条件作出了调节。</p><p>然而，在实践中，REMB方法有几个缺点。</p><p>其中一个缺点是编码器的能力限制，当您为编码器设置比特率时，它不一定能准确的按照您要求的比特率进行输出。根据编码器的设置和正在被编码的帧的情况，它的输出可能会更少或更多。</p><p>举例来说，x264编码器，配置为tune=zerolatency，跟指定的目标比特率相比，其输出可能会产生明显的偏离。下面是一种可能的场景：</p><ul><li>假设我们一开始将比特率设置为1000kbps。</li><li>由于没有很多高频特征值需要编码，编码器只能输出700kbps。（亦称为：&ldquo;凝视一堵墙&rdquo;。）</li><li>我们再假设接收方获得了700kbps的视频，没有发生数据包丢失，它将应用REMB的规则1，把输入比特率提升8％。</li><li>接收方向发送方发送了一个REMB包，建议将输入比特率提高到756kbps（700kbps * 1.08）。</li><li>发送方将编码器的比特率设置为756kbps。</li><li>编码器输出更低的比特率。</li><li>这个过程会继续重复进行，这样，比特率会被降低到绝对最小值。</li></ul><p>您可以看到，这会导致多次编码器参数调整；同时用户会惊讶的发现，虽然连接状况良好，但视频质量看起来却让人难以接受。</p><h3 id=传输范围内的拥塞控制twcc>传输范围内的拥塞控制（TWCC）
<a class=anchor href=#%e4%bc%a0%e8%be%93%e8%8c%83%e5%9b%b4%e5%86%85%e7%9a%84%e6%8b%a5%e5%a1%9e%e6%8e%a7%e5%88%b6twcc>#</a></h3><p>传输范围内的拥塞控制是RTCP网络状态通信技术的最新进展。</p><p>TWCC使用一个非常简单的原则：</p><p><img src=../../images/06-twcc-idea.png alt=TWCC title=TWCC></p><p>与REMB不同，TWCC的接收方不会尝试估计自己的传入比特率。它只是让发送方知道哪些包被收到了，是在什么时间收到的。基于这些报告，发送方可以了解网络的最新的状况。</p><ul><li>发送方创建带有特殊的TWCC标头扩展的RTP数据包，其中包含一个数据包序列号的列表。</li><li>接收方以特殊的RTCP反馈消息进行响应，以使发送方知道每个数据包是否以及何时被接收。</li></ul><p>发送方跟踪已发送的数据包，包括它们的序列号，大小和时间戳。
当发送方从接收方收到RTCP消息时，它将发送数据包间的延迟与接收延迟进行比较。
如果接收延迟增加，则意味着网络正在发生拥塞，发送者必须对此采取行动。</p><p>在下图中，数据包间延迟的中位数增长了+20毫秒，这清楚地表明网络正在发生拥塞。</p><p><img src=../../images/06-twcc.png alt=有延迟的TWCC title=有延迟的TWCC></p><p>TWCC提供了原始数据和实时网络状况的绝佳视图：</p><ul><li>几乎是即时的丢包统计信息，不仅包括丢失的百分比，还包括丢失的确切数据包。</li><li>准确的发送比特率。</li><li>准确的接收比特率。</li><li>抖动估计。</li><li>发送和接收数据包延迟之间的差异。</li></ul><p>一种简单的，用于估计从发送方到接收方的传输比特率的拥塞控制算法是，将接收到的数据包大小相加，然后将其除以接收方一端经过的时间。</p><h2 id=生成带宽估计值>生成带宽估计值
<a class=anchor href=#%e7%94%9f%e6%88%90%e5%b8%a6%e5%ae%bd%e4%bc%b0%e8%ae%a1%e5%80%bc>#</a></h2><p>现在，我们掌握了有关网络状态的信息，可以针对可用带宽进行估算了。IETF在2012年成立了RMCAT（RTP媒体拥塞避免技术）工作组。
该工作组包含了已提交的多个拥塞控制算法的标准。在此之前，所有的拥塞控制算法都是专有的。</p><p>部署最多的实现是&rsquo;用于实时通信的Google拥塞控制算法（GCC）'，定义于<a href=https://tools.ietf.org/html/draft-alvestrand-rmcat-congestion-02>draft-alvestrand-rmcat-congestion</a>。
它可以分两次运行。第一次运行是&rsquo;基于损失&rsquo;的，仅使用接收方报告。如果TWCC是可用的，它也会将其数据加入。
它通过使用<a href=https://en.wikipedia.org/wiki/Kalman_filter>Kalman过滤器</a>预测当前和将来的网络带宽。</p><p>还有几种GCC的替代品，例如：<a href=https://tools.ietf.org/html/draft-zhu-rmcat-nada-04>NADA：一种实时媒体的统一拥塞控制方案</a> 和 <a href=https://tools.ietf.org/html/draft-johansson-rmcat-scream-cc-05>SCReAM- 多媒体的自时钟速率自适应</a>。</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div class=book-languages tabindex=0 aria-haspopup=true><ul><li class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
简体中文</li></ul><ul class=book-languages-list><li><a href=https://webrtcforthecurious.com/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
English</a></li><li><a href=https://webrtcforthecurious.com/sv/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
Svenska</a></li><li class=active><a href=https://webrtcforthecurious.com/zh/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
简体中文</a></li><li><a href=https://webrtcforthecurious.com/ja/docs/06-media-communication/ class="flex align-center"><img src=/svg/translate.svg class=book-icon alt=Languages>
日本語</a></li></ul></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/commit/1a70667159cd5b163978675a035fe32eadacca0b title="最后修改者 Claes Mogren | May 21, 2021" target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>May 21, 2021</span></a></div><div><a class="flex align-center" href=https://github.com/webrtc-for-the-curious/webrtc-for-the-curious/edit/master/content.zh-cn/docs/06-media-communication.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>编辑本页</span></a></div></div></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#它是如何工作的>它是如何工作的？</a></li><li><a href=#延迟与质量>延迟与质量</a><ul><li><a href=#现实世界的局限性>现实世界的局限性</a></li><li><a href=#视频是复杂的>视频是复杂的</a></li></ul></li><li><a href=#视频101>视频101</a><ul><li><a href=#有损和无损压缩>有损和无损压缩</a></li><li><a href=#帧内和帧间压缩>帧内和帧间压缩</a></li><li><a href=#帧间压缩>帧间压缩</a></li><li><a href=#视频很脆弱>视频很脆弱</a></li></ul></li><li><a href=#rtp>RTP</a><ul><li><a href=#packet-format包格式>Packet Format（包格式）</a></li><li><a href=#extensions扩展>Extensions（扩展）</a></li></ul></li><li><a href=#rtcp>RTCP</a><ul><li><a href=#packet-format>Packet Format</a></li><li><a href=#完整的帧内请求fir和图片丢失指示pli>完整的帧内请求（FIR）和图片丢失指示（PLI）</a></li><li><a href=#negative-acknowledgements否定确认>Negative ACKnowledgements（否定确认）</a></li><li><a href=#senderreceiver-reports发送方接收方报告>Sender/Receiver Reports（发送方/接收方报告）</a></li></ul></li><li><a href=#rtprtcp是如何协作解决问题的>RTP/RTCP是如何协作解决问题的</a><ul><li><a href=#negative-acknowledgment否定确认>Negative Acknowledgment（否定确认）</a></li><li><a href=#forward-error-correction前向纠错>Forward Error Correction（前向纠错）</a></li><li><a href=#自适应比特率和带宽估计>自适应比特率和带宽估计</a></li></ul></li><li><a href=#传递网络状态>传递网络状态</a><ul><li><a href=#接收方报告>接收方报告</a></li><li><a href=#tmmbrtmmbn和remb>TMMBR，TMMBN和REMB</a></li><li><a href=#传输范围内的拥塞控制twcc>传输范围内的拥塞控制（TWCC）</a></li></ul></li><li><a href=#生成带宽估计值>生成带宽估计值</a></li></ul></nav></div></aside></main></body></html>